{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install polars pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import scipy.stats as stats\n",
    "from tqdm import tqdm\n",
    "\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lower bound entropy of the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"../data/variations_wc/6switches_3values_min1_max20_10K\")\n",
    "lower_bound_complexity = []\n",
    "\n",
    "# フォルダ名からgrammar_namesを取得\n",
    "grammar_names = [d.name for d in data_dir.iterdir() if d.is_dir()]\n",
    "print(len(grammar_names))\n",
    "valid_grammar = 0\n",
    "for grammar_name in grammar_names:\n",
    "    if not (\n",
    "        data_dir / grammar_name / \"true_prob\" / \"lower_bound_entropy.value\"\n",
    "    ).exists():\n",
    "        if not (\n",
    "            data_dir / grammar_name / \"true_prob\" / \"probability_split_1_of_1.csv.gz\"\n",
    "        ).exists():\n",
    "            print(f\"{grammar_name} is not valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"../data/variations_wc/6switches_3values_min1_max20_10K\")\n",
    "lower_bound_complexity = []\n",
    "\n",
    "# フォルダ名からgrammar_namesを取得\n",
    "grammar_names = [d.name for d in data_dir.iterdir() if d.is_dir()]\n",
    "\n",
    "for grammar_name in grammar_names:\n",
    "    true_prob_dir = data_dir / grammar_name / \"true_prob\"\n",
    "\n",
    "    try:\n",
    "        # entropyとperplexityの値を読み込む\n",
    "        with open(true_prob_dir / \"lower_bound_entropy.value\") as f:\n",
    "            entropy = float(f.read().strip())\n",
    "\n",
    "        with open(true_prob_dir / \"lower_bound_perplexity.value\") as f:\n",
    "            perplexity = float(f.read().strip())\n",
    "\n",
    "        lower_bound_complexity.append(\n",
    "            {\n",
    "                \"grammar_name\": grammar_name,\n",
    "                \"lower_bound_entropy\": entropy,\n",
    "                \"lower_bound_perplexity\": perplexity,\n",
    "            }\n",
    "        )\n",
    "    except:\n",
    "        print(f\"Can't find {true_prob_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 理論下限のプロット\n",
    "fig, ax = plt.subplots(figsize=(25, 8))\n",
    "\n",
    "# DataFrameに変換して扱いやすくする\n",
    "lower_bound_df = pd.DataFrame(lower_bound_complexity)\n",
    "\n",
    "# '2'の数が少ない順にソート\n",
    "lower_bound_df[\"num_twos\"] = lower_bound_df[\"grammar_name\"].apply(\n",
    "    lambda x: x.count(\"2\")\n",
    ")\n",
    "lower_bound_df = lower_bound_df.sort_values(by=\"num_twos\").drop(columns=\"num_twos\")\n",
    "\n",
    "\n",
    "# プロット\n",
    "ax.bar(\n",
    "    lower_bound_df[\"grammar_name\"],\n",
    "    lower_bound_df[\"lower_bound_perplexity\"],\n",
    "    color=\"skyblue\",\n",
    ")\n",
    "\n",
    "# 見やすさの調整\n",
    "ax.set_xticks(range(len(list(lower_bound_df[\"grammar_name\"].values))))\n",
    "ax.set_xticklabels(\n",
    "    list(lower_bound_df[\"grammar_name\"].values), rotation=45, fontsize=10\n",
    ")\n",
    "ax.set_xlabel(\"Grammar\")\n",
    "ax.set_ylabel(\"Lower Bound Perplexity\")\n",
    "ax.set_title(\"Lower Bound of Perplexity by Grammar\")\n",
    "\n",
    "\n",
    "# グリッドと余白の調整\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25, 8))\n",
    "\n",
    "# プロット\n",
    "ax.bar(\n",
    "    lower_bound_df[\"grammar_name\"],\n",
    "    lower_bound_df[\"lower_bound_entropy\"],  # Changed from lower_bound_perplexity\n",
    "    color=\"skyblue\",\n",
    ")\n",
    "\n",
    "# 見やすさの調整\n",
    "ax.set_xticks(range(len(list(lower_bound_df[\"grammar_name\"].values))))\n",
    "ax.set_xticklabels(list(lower_bound_df[\"grammar_name\"].values), rotation=45)\n",
    "ax.set_xlabel(\"Grammar\")\n",
    "ax.set_ylabel(\"Lower Bound Entropy\")  # Updated ylabel\n",
    "ax.set_title(\"Lower Bound of Entropy by Grammar\")  # Updated title\n",
    "\n",
    "# グリッドと余白の調整\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lower bound entropy of testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from src.length_sampling.sampler import construct_pcfg_sampler\n",
    "from src.length_sampling.grammars.pcfg import Grammar\n",
    "from src.length_sampling.grammars.cfg import Nonterminal\n",
    "from src.length_sampling.lower_bound_perplexity import (\n",
    "    parts_to_perplexity,\n",
    "    Parts,\n",
    ")\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "import gzip\n",
    "import math\n",
    "import pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_length = 1\n",
    "max_length = 20\n",
    "data_dir = Path(\"../data/variations_wc/6switches_3values_min1_max20_10K\")\n",
    "fairseq_data_dir = Path(\"../data/fairseq_train/6switches_3values_min1_max20_10K\")\n",
    "grammar_dir = Path(\"../data/grammars/variations/6switches_3values\")\n",
    "\n",
    "lower_bound_complexity = []\n",
    "\n",
    "\n",
    "grammar_names = lower_bound_df[\"grammar_name\"].values\n",
    "print(f\"Processing {len(grammar_names)} grammars\")\n",
    "\n",
    "for grammar_name in grammar_names:\n",
    "    # grammarの読み込みとsamplerの構築\n",
    "    grammar_file = grammar_dir / f\"{grammar_name}.gr\"\n",
    "    grammar = Grammar.from_file(grammar_file, Nonterminal(\"S\"), normalize=True)\n",
    "    sampler = construct_pcfg_sampler(grammar)\n",
    "\n",
    "    true_prob_dir = data_dir / grammar_name / \"true_prob\"\n",
    "\n",
    "    # テストデータの文を読み込む\n",
    "    test_file = fairseq_data_dir / grammar_name / \"test.txt\"\n",
    "    with open(test_file) as f:\n",
    "        test_sentences = [line.strip() for line in f]\n",
    "\n",
    "    # true_probデータを読み込む\n",
    "    dfs = []\n",
    "    for file in true_prob_dir.glob(\"*.csv.gz\"):\n",
    "        with gzip.open(file, \"rt\") as f:\n",
    "            df = pl.read_csv(\n",
    "                f, new_columns=[\"sentence\", \"count\", \"true_log_prob\", \"true_prob\"]\n",
    "            )\n",
    "            dfs.append(df)\n",
    "    if dfs:\n",
    "        df = pl.concat(dfs).filter(pl.col(\"count\").is_not_null())\n",
    "\n",
    "        # test_sentencesをDataFrameに変換\n",
    "        test_df = pd.DataFrame(test_sentences, columns=[\"sentence\"])\n",
    "\n",
    "        # true_log_probをtest_dfにマージ\n",
    "        test_df = test_df.merge(\n",
    "            df.to_pandas()[[\"sentence\", \"true_log_prob\"]], on=\"sentence\", how=\"left\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Grammar {grammar_name}, len: {len(test_df)}, unique: {test_df['sentence'].nunique()}\"\n",
    "        )\n",
    "\n",
    "        # 統計量の計算\n",
    "        total_neg_log_prob = -1.0 * test_df[\"true_log_prob\"].sum()\n",
    "        test_df[\"sent_len\"] = test_df[\"sentence\"].map(\n",
    "            lambda x: len(x.split()) + 1\n",
    "        )  # +1 for EOS\n",
    "        total_len = test_df[\"sent_len\"].sum()\n",
    "        num_samples = len(test_df)\n",
    "\n",
    "        valid_lengths = sampler.valid_lengths(min_length=1, max_length=20)\n",
    "\n",
    "        # Partsを使ってパープレキシティを計算\n",
    "        parts = Parts(total_neg_log_prob, total_len, num_samples)\n",
    "        perplexity = parts_to_perplexity(parts, len(valid_lengths))\n",
    "        entropy = math.log(perplexity)\n",
    "\n",
    "        lower_bound_complexity.append(\n",
    "            {\n",
    "                \"grammar_name\": grammar_name,\n",
    "                \"lower_bound_entropy\": entropy,\n",
    "                \"lower_bound_perplexity\": perplexity,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 理論下限のプロット\n",
    "fig, ax = plt.subplots(figsize=(25, 8))\n",
    "\n",
    "# DataFrameに変換して扱いやすくする\n",
    "lower_bound_df = pd.DataFrame(lower_bound_complexity)\n",
    "\n",
    "# '2'の数が少ない順にソート\n",
    "lower_bound_df[\"num_twos\"] = lower_bound_df[\"grammar_name\"].apply(\n",
    "    lambda x: x.count(\"2\")\n",
    ")\n",
    "lower_bound_df = lower_bound_df.sort_values(by=\"num_twos\").drop(columns=\"num_twos\")\n",
    "\n",
    "\n",
    "# プロット\n",
    "ax.bar(\n",
    "    lower_bound_df[\"grammar_name\"],\n",
    "    lower_bound_df[\"lower_bound_perplexity\"],\n",
    "    color=\"skyblue\",\n",
    ")\n",
    "\n",
    "# 見やすさの調整\n",
    "ax.set_xticks(range(len(list(lower_bound_df[\"grammar_name\"].values))))\n",
    "ax.set_xticklabels(list(lower_bound_df[\"grammar_name\"].values), rotation=45)\n",
    "ax.set_xlabel(\"Grammar\")\n",
    "ax.set_ylabel(\"Lower Bound Perplexity of Test Data (nats)\")\n",
    "ax.set_title(\"Empirical Lower Bound of Perplexity of Test Data by Grammar\")\n",
    "\n",
    "\n",
    "# グリッドと余白の調整\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "exp_name = \"local_entropy\"\n",
    "\n",
    "data_dir = Path(f\"../data/fairseq_train/{exp_name}\")\n",
    "grammar_names = [d.name for d in data_dir.iterdir() if d.is_dir()]\n",
    "\n",
    "num_seeds = 5\n",
    "# model_names = [\"transformer\", \"lstm\", \"transformer_tiny\"]\n",
    "model_names = [\"lstm\", \"transformer_4layer\"]\n",
    "\n",
    "results_dir = Path(\"../results\").resolve()\n",
    "\n",
    "result_list = []\n",
    "for grammar_name in tqdm(grammar_names):\n",
    "    split_data_file = data_dir / grammar_name / \"test.txt\"\n",
    "    with open(split_data_file) as f:\n",
    "        total_syms = sum(\n",
    "            len(line.strip().split()) + 1 for line in f\n",
    "        )  # add 1 for EOS token\n",
    "    for model_name in model_names:\n",
    "        model_result_dir = results_dir / f\"{model_name}_results\" / exp_name\n",
    "        grammar_result_dir = model_result_dir / f\"{grammar_name}\"\n",
    "        seed_stats = []\n",
    "        for seed_i in range(num_seeds):\n",
    "            split_result_file = grammar_result_dir / f\"seed{seed_i}\" / \"test.scores.txt\"\n",
    "            with open(split_result_file) as f:\n",
    "                scores = [float(line.strip()) for line in f]\n",
    "            total_sents = len(scores)\n",
    "            neg_log_probs = [-1.0 * score for score in scores]\n",
    "            sym_cross_entropy = (sum(neg_log_probs) / total_syms) / math.log(2)\n",
    "            sym_perplexity = math.exp(sym_cross_entropy)\n",
    "            sent_cross_entropy = (sum(neg_log_probs) / total_sents) / math.log(2)\n",
    "            sent_perplexity = math.exp(sent_cross_entropy)\n",
    "            # seed_stats.append(\n",
    "            #     {\n",
    "            #         \"sym_cross_entropy\": sym_cross_entropy,\n",
    "            #         \"sym_perplexity\": sym_perplexity,\n",
    "            #         \"sent_cross_entropy\": sent_cross_entropy,\n",
    "            #         \"sent_perplexity\": sent_perplexity,\n",
    "            #     }\n",
    "            # )\n",
    "\n",
    "            # sym_entropies = [s[\"sym_cross_entropy\"] for s in seed_stats]\n",
    "            # sym_perplexities = [s[\"sym_perplexity\"] for s in seed_stats]\n",
    "            # sent_entropies = [s[\"sent_cross_entropy\"] for s in seed_stats]\n",
    "            # sent_perplexities = [s[\"sent_perplexity\"] for s in seed_stats]\n",
    "\n",
    "            result_list.append(\n",
    "                {\n",
    "                    \"model_name\": model_name,\n",
    "                    \"seed\": seed_i,\n",
    "                    \"grammar_name\": grammar_name,\n",
    "                    \"sym_cross_entropy\": sym_cross_entropy,\n",
    "                    \"sym_perplexity\": sym_perplexity,\n",
    "                    \"sent_cross_entropy\": sent_cross_entropy,\n",
    "                    \"sent_perplexity\": sent_perplexity,\n",
    "                }\n",
    "            )\n",
    "    print(total_syms, total_sents, total_syms / total_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>seed</th>\n",
       "      <th>grammar_name</th>\n",
       "      <th>sym_cross_entropy</th>\n",
       "      <th>sym_perplexity</th>\n",
       "      <th>sent_cross_entropy</th>\n",
       "      <th>sent_perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm</td>\n",
       "      <td>0</td>\n",
       "      <td>Q16_S16_s10180</td>\n",
       "      <td>1.039505</td>\n",
       "      <td>2.827818</td>\n",
       "      <td>36.184035</td>\n",
       "      <td>5.182350e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lstm</td>\n",
       "      <td>1</td>\n",
       "      <td>Q16_S16_s10180</td>\n",
       "      <td>1.037321</td>\n",
       "      <td>2.821648</td>\n",
       "      <td>36.108003</td>\n",
       "      <td>4.802932e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstm</td>\n",
       "      <td>2</td>\n",
       "      <td>Q16_S16_s10180</td>\n",
       "      <td>1.042292</td>\n",
       "      <td>2.835708</td>\n",
       "      <td>36.281020</td>\n",
       "      <td>5.710143e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lstm</td>\n",
       "      <td>3</td>\n",
       "      <td>Q16_S16_s10180</td>\n",
       "      <td>1.044746</td>\n",
       "      <td>2.842677</td>\n",
       "      <td>36.366457</td>\n",
       "      <td>6.219442e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lstm</td>\n",
       "      <td>4</td>\n",
       "      <td>Q16_S16_s10180</td>\n",
       "      <td>1.037053</td>\n",
       "      <td>2.820891</td>\n",
       "      <td>36.098661</td>\n",
       "      <td>4.758273e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>transformer_4layer</td>\n",
       "      <td>0</td>\n",
       "      <td>Q32_S8_s8247</td>\n",
       "      <td>0.823107</td>\n",
       "      <td>2.277565</td>\n",
       "      <td>8.748644</td>\n",
       "      <td>6.302134e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>transformer_4layer</td>\n",
       "      <td>1</td>\n",
       "      <td>Q32_S8_s8247</td>\n",
       "      <td>0.822775</td>\n",
       "      <td>2.276810</td>\n",
       "      <td>8.745122</td>\n",
       "      <td>6.279979e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>transformer_4layer</td>\n",
       "      <td>2</td>\n",
       "      <td>Q32_S8_s8247</td>\n",
       "      <td>0.819156</td>\n",
       "      <td>2.268585</td>\n",
       "      <td>8.706654</td>\n",
       "      <td>6.042989e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>transformer_4layer</td>\n",
       "      <td>3</td>\n",
       "      <td>Q32_S8_s8247</td>\n",
       "      <td>0.831020</td>\n",
       "      <td>2.295660</td>\n",
       "      <td>8.832754</td>\n",
       "      <td>6.855142e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>transformer_4layer</td>\n",
       "      <td>4</td>\n",
       "      <td>Q32_S8_s8247</td>\n",
       "      <td>0.833238</td>\n",
       "      <td>2.300756</td>\n",
       "      <td>8.856322</td>\n",
       "      <td>7.018622e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             model_name  seed    grammar_name  sym_cross_entropy  \\\n",
       "0                  lstm     0  Q16_S16_s10180           1.039505   \n",
       "1                  lstm     1  Q16_S16_s10180           1.037321   \n",
       "2                  lstm     2  Q16_S16_s10180           1.042292   \n",
       "3                  lstm     3  Q16_S16_s10180           1.044746   \n",
       "4                  lstm     4  Q16_S16_s10180           1.037053   \n",
       "..                  ...   ...             ...                ...   \n",
       "355  transformer_4layer     0    Q32_S8_s8247           0.823107   \n",
       "356  transformer_4layer     1    Q32_S8_s8247           0.822775   \n",
       "357  transformer_4layer     2    Q32_S8_s8247           0.819156   \n",
       "358  transformer_4layer     3    Q32_S8_s8247           0.831020   \n",
       "359  transformer_4layer     4    Q32_S8_s8247           0.833238   \n",
       "\n",
       "     sym_perplexity  sent_cross_entropy  sent_perplexity  \n",
       "0          2.827818           36.184035     5.182350e+15  \n",
       "1          2.821648           36.108003     4.802932e+15  \n",
       "2          2.835708           36.281020     5.710143e+15  \n",
       "3          2.842677           36.366457     6.219442e+15  \n",
       "4          2.820891           36.098661     4.758273e+15  \n",
       "..              ...                 ...              ...  \n",
       "355        2.277565            8.748644     6.302134e+03  \n",
       "356        2.276810            8.745122     6.279979e+03  \n",
       "357        2.268585            8.706654     6.042989e+03  \n",
       "358        2.295660            8.832754     6.855142e+03  \n",
       "359        2.300756            8.856322     7.018622e+03  \n",
       "\n",
       "[360 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "result_df = (\n",
    "    pd.DataFrame(result_list)\n",
    "    .sort_values([\"model_name\", \"grammar_name\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "result_df.to_csv(results_dir / f\"length_sampling_{exp_name}_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
