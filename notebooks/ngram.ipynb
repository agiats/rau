{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "#############################\n",
    "# 1) Real Semiring\n",
    "#############################\n",
    "\n",
    "import numpy as np\n",
    "from math import isclose\n",
    "from __future__ import annotations\n",
    "\n",
    "import copy\n",
    "from collections import Counter\n",
    "from collections import defaultdict as dd\n",
    "from collections import deque\n",
    "from itertools import product\n",
    "from typing import Callable, Dict, Generator, List, Optional, Sequence, Set, Tuple, Type, Union\n",
    "\n",
    "import numpy as np\n",
    "from frozendict import frozendict\n",
    "\n",
    "import rayuela\n",
    "from rayuela.base.semiring import Boolean, ProductSemiring, Real, Semiring\n",
    "from rayuela.base.state import PairState, State\n",
    "from rayuela.base.symbol import Expr, Sym, ε, ε_1, ε_2, φ\n",
    "from rayuela.cfg.nonterminal import NT, S\n",
    "from rayuela.fsa.pathsum import Pathsum, Strategy\n",
    "from rayuela.fsa.fsa import FSA\n",
    "\n",
    "def build_ngram_wfsa(ngram_model, n, alphabet, bos='[BOS]', eos='[EOS]'):\n",
    "    \"\"\"\n",
    "    Build a Weighted FSA (Real semiring) capturing the distribution\n",
    "    of an n-gram model, one-symbol-per-transition style.\n",
    "\n",
    "    ngram_model: dict => ngram_model[context][symbol] = probability\n",
    "    n: the 'n' in n-gram\n",
    "    alphabet: list of symbols\n",
    "    bos, eos: special tokens\n",
    "    \"\"\"\n",
    "    fsa = FSA(R=Real)\n",
    "\n",
    "    # define final \"absorbing\" state for after EOS\n",
    "    q_final = State(\"<<FINAL>>\")\n",
    "    fsa.add_state(q_final)\n",
    "    fsa.set_F(q_final, Real.one)\n",
    "\n",
    "    # gather contexts\n",
    "    contexts = list(ngram_model.keys())  # each is (n-1)-tuple or () if n=1\n",
    "    context2state = {}\n",
    "    for ctx in contexts:\n",
    "        ctxName = str(ctx) if ctx else \"()\"\n",
    "        q = State(ctxName)\n",
    "        context2state[ctx] = q\n",
    "        fsa.add_state(q)\n",
    "\n",
    "    # start context\n",
    "    if n>1:\n",
    "        start_ctx = tuple([bos]*(n-1))\n",
    "    else:\n",
    "        start_ctx = ()\n",
    "\n",
    "    if start_ctx not in context2state:\n",
    "        qstart = State(str(start_ctx))\n",
    "        context2state[start_ctx] = qstart\n",
    "        fsa.add_state(qstart)\n",
    "    else:\n",
    "        qstart = context2state[start_ctx]\n",
    "    fsa.set_I(qstart, Real.one)\n",
    "\n",
    "    # define transitions\n",
    "    for ctx in contexts:\n",
    "        s_from = context2state[ctx]\n",
    "        dist_dict = ngram_model[ctx]\n",
    "        for symbol, prob in dist_dict.items():\n",
    "            if prob <= 1e-15:\n",
    "                continue\n",
    "            w = Real(prob)\n",
    "            if symbol == eos:\n",
    "                # go to final\n",
    "                fsa.add_arc(s_from, Sym(symbol), q_final, w)\n",
    "            else:\n",
    "                # next context\n",
    "                if n>1:\n",
    "                    new_ctx = tuple(list(ctx[1:]) + [symbol]) if len(ctx)==(n-1) else (symbol,)\n",
    "                else:\n",
    "                    new_ctx = ()\n",
    "                if new_ctx not in context2state:\n",
    "                    qq = State(str(new_ctx))\n",
    "                    context2state[new_ctx] = qq\n",
    "                    fsa.add_state(qq)\n",
    "                s_to = context2state[new_ctx]\n",
    "                fsa.add_arc(s_from, Sym(symbol), s_to, w)\n",
    "\n",
    "    return fsa\n",
    "\n",
    "#############################\n",
    "# 4) build_kshuffle_ngram_wfsa\n",
    "#############################\n",
    "\n",
    "def build_kshuffle_ngram_wfsa(ngram_model, n, k, alphabet, permute_block, bos='[BOS]', eos='[EOS]'):\n",
    "    \"\"\"\n",
    "    Merge an n-gram model with a k-local deterministic shuffle in a single WFSA,\n",
    "    using a buffer of size k and a 'phase' to read tokens or emit them.\n",
    "\n",
    "    One-symbol-per-transition approach.\n",
    "\n",
    "    ngram_model: dict => ngram_model[context][symbol] = probability\n",
    "    n: order of n-gram\n",
    "    k: block size\n",
    "    alphabet: list of symbols\n",
    "    permute_block: function that permutes a list of length k => new list\n",
    "    bos, eos: special tokens\n",
    "    \"\"\"\n",
    "    fsa = FSA(R=Real)\n",
    "\n",
    "    # final absorbing state\n",
    "    q_final = State(\"<FINAL>\")\n",
    "    fsa.add_state(q_final)\n",
    "    fsa.set_F(q_final, Real(1.0))\n",
    "\n",
    "    # gather contexts\n",
    "    contexts = list(ngram_model.keys())\n",
    "    # create a map for states: (ctx, phase, buf) => State\n",
    "    state_map = {}\n",
    "\n",
    "    def ensure_state(ctx, phase, buf):\n",
    "        key = (ctx, phase, buf)\n",
    "        if key not in state_map:\n",
    "            st_name = f\"{ctx}|ph={phase}|{buf}\"\n",
    "            st = State(st_name)\n",
    "            state_map[key] = st\n",
    "            fsa.add_state(st)\n",
    "        return state_map[key]\n",
    "\n",
    "    # start context\n",
    "    if n>1:\n",
    "        start_ctx = tuple([bos]*(n-1))\n",
    "    else:\n",
    "        start_ctx = ()\n",
    "\n",
    "    # ensure start state\n",
    "    s0 = ensure_state(start_ctx, 0, ())\n",
    "    fsa.set_I(s0, Real(1.0))\n",
    "\n",
    "    # We'll do BFS-like expansion of states\n",
    "    queue = deque()\n",
    "    visited = set()\n",
    "\n",
    "    init_key = (start_ctx, 0, ())\n",
    "    queue.append(init_key)\n",
    "    visited.add(init_key)\n",
    "\n",
    "    max_phase = 2*k\n",
    "\n",
    "    def get_dist(ctx):\n",
    "        return ngram_model.get(ctx, {})\n",
    "\n",
    "    while queue:\n",
    "        (ctx, phase, buf) = queue.popleft()\n",
    "        s_from = ensure_state(ctx, phase, buf)\n",
    "\n",
    "        if phase < k:\n",
    "            # reading\n",
    "            dist_dict = get_dist(ctx)\n",
    "            for symbol, prob in dist_dict.items():\n",
    "                if prob <= 1e-15:\n",
    "                    continue\n",
    "                w = Real(prob)\n",
    "                if symbol == eos:\n",
    "                    # transition to final\n",
    "                    fsa.add_arc(s_from, Sym(symbol), q_final, w)\n",
    "                else:\n",
    "                    # next context\n",
    "                    if n>1:\n",
    "                        if len(ctx)==(n-1):\n",
    "                            new_ctx = tuple(list(ctx[1:]) + [symbol])\n",
    "                        else:\n",
    "                            new_ctx = (symbol,)\n",
    "                    else:\n",
    "                        new_ctx = ()\n",
    "                    new_buf = tuple(list(buf) + [symbol])\n",
    "                    new_phase = phase+1\n",
    "                    to_key = (new_ctx, new_phase, new_buf)\n",
    "                    if to_key not in visited:\n",
    "                        visited.add(to_key)\n",
    "                        queue.append(to_key)\n",
    "                    s_to = ensure_state(new_ctx, new_phase, new_buf)\n",
    "                    # emit no symbol => we can treat as epsilon\n",
    "                    fsa.add_arc(s_from, Sym(''), s_to, w)\n",
    "\n",
    "        elif phase < 2*k:\n",
    "            # emission\n",
    "            idx = phase - k\n",
    "            if len(buf) == k:\n",
    "                pblock = permute_block(list(buf))\n",
    "                if idx < k:\n",
    "                    emit_symbol = pblock[idx]\n",
    "                    w = Real(1.0)\n",
    "                    new_phase = phase+1\n",
    "                    to_key = (ctx, new_phase, buf)\n",
    "                    if new_phase == 2*k:\n",
    "                        # We'll handle resetting after we actually do a transition\n",
    "                        pass\n",
    "                    if to_key not in visited:\n",
    "                        visited.add(to_key)\n",
    "                        queue.append(to_key)\n",
    "                    s_to = ensure_state(ctx, new_phase, buf)\n",
    "                    fsa.add_arc(s_from, Sym(emit_symbol), s_to, w)\n",
    "\n",
    "        else:\n",
    "            # phase == 2k => done emitting => reset\n",
    "            to_key = (ctx, 0, ())\n",
    "            if to_key not in visited:\n",
    "                visited.add(to_key)\n",
    "                queue.append(to_key)\n",
    "            s_to = ensure_state(ctx, 0, ())\n",
    "            fsa.add_arc(s_from, Sym(''), s_to, Real(1.0))\n",
    "\n",
    "    return fsa\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-gram FSA states: 4\n",
      "k-shuffle FSA states: 18\n",
      "N-gram FSA approximate entropy: 7.92733\n",
      "k-shuffle FSA approximate entropy: 7.92733\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Example usage:\n",
    "    We'll define a small n-gram model, build an n-gram WFSA, then\n",
    "    build a (k=2)-shuffle version, and do some minimal checks.\n",
    "\"\"\"\n",
    "\n",
    "# Let's define a toy 2-gram model: (context=1 token) => { next_token: probability }\n",
    "# Suppose we have an alphabet: [BOS], [EOS], 'a', 'b'\n",
    "n = 2\n",
    "bos, eos = '[BOS]', '[EOS]'\n",
    "alphabet = [bos, eos, 'a', 'b']\n",
    "\n",
    "# ngram_model:\n",
    "#   context is (bos,) => { 'a':0.6, 'b':0.4 }\n",
    "#   context is ('a',) => { 'a':0.3, 'b':0.2, eos:0.5 }\n",
    "#   context is ('b',) => { 'a':0.1, 'b':0.1, eos:0.8 }\n",
    "my_ngram_model = {\n",
    "    (bos,): {'a':0.6, 'b':0.4},\n",
    "    ('a',): {'a':0.3, 'b':0.2, eos:0.5},\n",
    "    ('b',): {'a':0.1, 'b':0.1, eos:0.8},\n",
    "}\n",
    "\n",
    "# 1) Build the plain n-gram WFSA\n",
    "fsa_ng = build_ngram_wfsa(my_ngram_model, n, alphabet, bos, eos)\n",
    "print(\"N-gram FSA states:\", len(fsa_ng.Q))\n",
    "\n",
    "# 2) Define a block permutation for k=2 => swap\n",
    "def swap2(block):\n",
    "    if len(block)<2: return block\n",
    "    return [block[1], block[0]]\n",
    "\n",
    "# 3) Build k=2 shuffle WFSA\n",
    "k=2\n",
    "fsa_kshuffle = build_kshuffle_ngram_wfsa(my_ngram_model, n, k, alphabet, swap2, bos, eos)\n",
    "print(\"k-shuffle FSA states:\", len(fsa_kshuffle.Q))\n",
    "\n",
    "# 4) We can do a naive 'entropy' check\n",
    "# (Recall the placeholder pathsum => 0.0 in this minimal version.)\n",
    "print(\"N-gram FSA approximate entropy:\", fsa_ng.entropy())\n",
    "print(\"k-shuffle FSA approximate entropy:\", fsa_kshuffle.entropy())\n",
    "\n",
    "# The real rayuela library has advanced pathsum & entropies if the FSA is acyclic\n",
    "# or if you do a correct lifting to the entropy semiring, etc.\n",
    "# But structurally, these two FSAs demonstrate the n-gram and n-gram+k-shuffle logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rayuela.fsa.sampler import Sampler\n",
    "\n",
    "fsa_ng_sampler = Sampler(fsa_ng)\n",
    "fsa_kshuffle_sampler = Sampler(fsa_kshuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1048.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a [EOS]',\n",
       " 'b [EOS]',\n",
       " 'b [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a a b [EOS]',\n",
       " 'a [EOS]',\n",
       " 'b [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a b [EOS]',\n",
       " 'b [EOS]']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fsa_ng_sampler.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 855.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' [EOS]',\n",
       " ' [EOS]',\n",
       " ' [EOS]',\n",
       " ' [EOS]',\n",
       " ' [EOS]',\n",
       " '  a a   [EOS]',\n",
       " '  a a    b a    b b  [EOS]',\n",
       " ' [EOS]',\n",
       " ' [EOS]',\n",
       " ' [EOS]']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fsa_kshuffle_sampler.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import isclose\n",
    "from itertools import product\n",
    "from collections import defaultdict, deque\n",
    "from rayuela.fsa.fsa import FSA\n",
    "\n",
    "\n",
    "\n",
    "class RandomNGramModel:\n",
    "    \"\"\"\n",
    "    Builds a random n-gram model as a Weighted FSA over the Real semiring.\n",
    "    Example usage:\n",
    "       model = RandomNGramModel(n=3, alpha=1.0, bos='[BOS]', eos='[EOS]')\n",
    "       # Then model.fsa is your random n-gram FSA\n",
    "       # You can also call model.build_kshuffle_fsa(...) to get a k-local shuffle version.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alphabet: list[str], n=2, alpha=1.0, bos='[BOS]', eos='[EOS]'):\n",
    "        \"\"\"\n",
    "        alphabet: list of symbols\n",
    "        n: n-gram order\n",
    "        alpha: Dirichlet concentration parameter\n",
    "        bos, eos: special boundary tokens\n",
    "        \"\"\"\n",
    "        self.alphabet = alphabet\n",
    "        self.n = n\n",
    "        self.alpha = alpha\n",
    "        self.bos = bos\n",
    "        self.eos = eos\n",
    "\n",
    "\n",
    "        # We'll store the random n-gram distribution as an FSA in self.fsa\n",
    "        self.fsa = FSA(R=Real)\n",
    "\n",
    "        self.__build_model()\n",
    "\n",
    "    def __build_model(self):\n",
    "        \"\"\"\n",
    "        Internally builds the random n-gram WFSA.\n",
    "        We do the following:\n",
    "          1) define contexts (n-1)-tuples from (alphabet + [BOS]) but not [EOS] in context\n",
    "          2) For each context, sample a random distribution over (alphabet + [EOS]) with Dirichlet\n",
    "          3) Add arcs to next context or final state\n",
    "        \"\"\"\n",
    "        # Create a final absorbing state\n",
    "        q_final = State(\"<FINAL>\")\n",
    "        self.fsa.add_state(q_final)\n",
    "        self.fsa.set_F(q_final, Real.one)\n",
    "\n",
    "        # If n=1, context = ()\n",
    "        # Otherwise context = (bos, bos, ..., bos) for start\n",
    "        if self.n <= 1:\n",
    "            all_contexts = [()]\n",
    "        else:\n",
    "            # We'll allow up to (n-1)-length combos from [BOS] + alphabet\n",
    "            # but exclude [EOS] from context\n",
    "            possible_symbols = [self.bos] + self.alphabet  # no eos\n",
    "            # enumerates all (n-1)-tuples\n",
    "            all_contexts = list(product(possible_symbols, repeat=self.n-1))\n",
    "\n",
    "        # We'll store them in a dict for convenience\n",
    "        self.context2state = {}\n",
    "        for ctx in all_contexts:\n",
    "            sname = str(ctx) if ctx else \"()\"\n",
    "            st = State(sname)\n",
    "            self.fsa.add_state(st)\n",
    "            self.context2state[ctx] = st\n",
    "\n",
    "        # Start context = (bos, bos, ..., bos) if n>1, else ()\n",
    "        if self.n>1:\n",
    "            start_ctx = tuple([self.bos]*(self.n-1))\n",
    "        else:\n",
    "            start_ctx = ()\n",
    "        s0 = self.context2state.get(start_ctx, None)\n",
    "        if not s0:\n",
    "            # create one if missing\n",
    "            s0 = State(str(start_ctx))\n",
    "            self.context2state[start_ctx] = s0\n",
    "            self.fsa.add_state(s0)\n",
    "        self.fsa.set_I(s0, Real.one)\n",
    "\n",
    "        # For each context, we'll sample a distribution over (alphabet + eos)\n",
    "        # using Dirichlet\n",
    "        import numpy as np\n",
    "        from numpy.random import dirichlet\n",
    "\n",
    "        out_alphabet = self.alphabet + [self.eos]\n",
    "\n",
    "        for ctx in all_contexts:\n",
    "            alpha_vec = [self.alpha]*len(out_alphabet)\n",
    "            probs = dirichlet(alpha_vec)\n",
    "            # For each symbol, define a transition\n",
    "            s_from = self.context2state[ctx]\n",
    "            for sym_idx, pval in enumerate(probs):\n",
    "                sym = out_alphabet[sym_idx]\n",
    "                if pval < 1e-15:\n",
    "                    continue\n",
    "                w = Real(pval)\n",
    "\n",
    "                if sym == self.eos:\n",
    "                    # transition to final\n",
    "                    self.fsa.add_arc(s_from, Sym(sym), q_final, w)\n",
    "                else:\n",
    "                    # next context: shift left + sym\n",
    "                    if self.n>1:\n",
    "                        new_ctx = tuple(list(ctx[1:]) + [sym]) if len(ctx)==(self.n-1) else (sym,)\n",
    "                    else:\n",
    "                        new_ctx = ()\n",
    "                    if new_ctx not in self.context2state:\n",
    "                        # create it on the fly if missing\n",
    "                        stx = State(str(new_ctx))\n",
    "                        self.fsa.add_state(stx)\n",
    "                        self.context2state[new_ctx] = stx\n",
    "                    s_to = self.context2state[new_ctx]\n",
    "                    self.fsa.add_arc(s_from, Sym(sym), s_to, w)\n",
    "\n",
    "    def build_kshuffle_fsa(self, k, permute_block) -> FSA:\n",
    "        \"\"\"\n",
    "        Builds a single FSA that merges:\n",
    "          - this random n-gram FSA\n",
    "          - a k-local shuffle (block-based) in a single symbol-per-transition approach.\n",
    "\n",
    "        The code is similar to the \"buffer\" approach: states = (context, phase, buffer).\n",
    "        For demonstration, partial blocks not carefully handled.\n",
    "        \"\"\"\n",
    "        fsa_k = FSA(R=Real)\n",
    "\n",
    "        # We'll reuse self.fsa's transitions and states as \"the base model\",\n",
    "        # but we embed them in a bigger state machine that does the shuffle.\n",
    "\n",
    "        # final absorbing\n",
    "        q_final = State(\"<FINAL-KSHUFFLE>\")\n",
    "        fsa_k.add_state(q_final)\n",
    "        fsa_k.set_F(q_final, Real.one)\n",
    "\n",
    "        # We'll do BFS expansions. We store states as (ctx, phase, buf_tuple).\n",
    "        from collections import deque\n",
    "        visited = set()\n",
    "        queue = deque()\n",
    "\n",
    "        # define a helper for creating states\n",
    "        def ensure_state(ctx, phase, buf):\n",
    "            st_name = f\"{ctx}|ph={phase}|{buf}\"\n",
    "            st = State(st_name)\n",
    "            fsa_k.add_state(st)\n",
    "            return st\n",
    "\n",
    "        # Start with (start_ctx, 0, ())\n",
    "        if self.n>1:\n",
    "            start_ctx = tuple([self.bos]*(self.n-1))\n",
    "        else:\n",
    "            start_ctx = ()\n",
    "        s0 = ensure_state(start_ctx, 0, ())\n",
    "        fsa_k.set_I(s0, Real.one)\n",
    "        queue.append( (start_ctx, 0, ()) )\n",
    "        visited.add( (start_ctx, 0, ()) )\n",
    "\n",
    "        max_phase = 2*k\n",
    "\n",
    "        # We'll need to look up transitions from the old self.fsa (the n-gram model).\n",
    "        # Let's store them in a dict for easy reference:\n",
    "        # base_arcs[ctx] = list of (symbol, next_ctx, prob).\n",
    "        # We can discover it by scanning self.fsa, but we also have context2state for states.\n",
    "        base_arcs = dict()\n",
    "\n",
    "        # We'll also identify the 'q_final' in the old FSA if it has a final state\n",
    "        old_final_states = set()\n",
    "        for q, w in self.fsa.F:\n",
    "            if w != Real.zero:\n",
    "                old_final_states.add(q)\n",
    "\n",
    "        # gather transitions from the old FSA\n",
    "        inv_map = {v:k for k,v in self.context2state.items()}  # state->context\n",
    "        for ctx, st in self.context2state.items():\n",
    "            arcs_list = []\n",
    "            for a, j, w in self.fsa.arcs(st):\n",
    "                arcs_list.append((a, j, w))\n",
    "            base_arcs[ctx] = arcs_list\n",
    "\n",
    "        while queue:\n",
    "            (ctx, phase, buf) = queue.popleft()\n",
    "            s_from = ensure_state(ctx, phase, buf)\n",
    "\n",
    "            # Check if the old FSA state is final => the old context leads to final?\n",
    "            st_old = self.context2state.get(ctx)\n",
    "            if st_old in old_final_states:\n",
    "                # we interpret that if the base model can end, we also have a transition to the new final\n",
    "                # with weight 1 if we want. Or you can keep partial block logic. We'll do a direct approach:\n",
    "                # If phase < k, we can skip, or we add an arc to new final:\n",
    "                fsa_k.add_arc(s_from, Sym(self.eos), q_final, Real(1.0))\n",
    "\n",
    "            if phase < k:\n",
    "                # reading from base model\n",
    "                arcs_list = base_arcs.get(ctx, [])\n",
    "                for (a, j, w) in arcs_list:\n",
    "                    if w == Real.zero:\n",
    "                        continue\n",
    "                    sym = str(a)\n",
    "                    if sym == self.eos:\n",
    "                        # go to final in the new FSA\n",
    "                        # weigh by w\n",
    "                        fsa_k.add_arc(s_from, a, q_final, w)\n",
    "                    else:\n",
    "                        # next context\n",
    "                        # find j's context\n",
    "                        new_c = inv_map.get(j, None)\n",
    "                        new_buf = tuple(list(buf) + [sym])\n",
    "                        new_phase = phase + 1\n",
    "                        to_key = (new_c, new_phase, new_buf)\n",
    "                        if to_key not in visited:\n",
    "                            visited.add(to_key)\n",
    "                            queue.append(to_key)\n",
    "                        s_to = ensure_state(new_c, new_phase, new_buf)\n",
    "                        # emit no symbol => treat as ε\n",
    "                        fsa_k.add_arc(s_from, Sym(''), s_to, w)\n",
    "\n",
    "            elif phase < 2*k:\n",
    "                # emission\n",
    "                idx = phase - k\n",
    "                if len(buf) == k:\n",
    "                    # permute\n",
    "                    pblock = permute_block(list(buf))\n",
    "                    if idx < k:\n",
    "                        out_sym = pblock[idx]\n",
    "                        new_phase = phase+1\n",
    "                        w = Real(1.0)\n",
    "                        to_key = (ctx, new_phase, buf)\n",
    "                        if to_key not in visited:\n",
    "                            visited.add(to_key)\n",
    "                            queue.append(to_key)\n",
    "                        s_to = ensure_state(ctx, new_phase, buf)\n",
    "                        fsa_k.add_arc(s_from, Sym(out_sym), s_to, w)\n",
    "\n",
    "            else:\n",
    "                # phase == 2k => reset\n",
    "                to_key = (ctx, 0, ())\n",
    "                if to_key not in visited:\n",
    "                    visited.add(to_key)\n",
    "                    queue.append(to_key)\n",
    "                s_to = ensure_state(ctx, 0, ())\n",
    "                fsa_k.add_arc(s_from, Sym(''), s_to, Real.one)\n",
    "\n",
    "        return fsa_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Ngram FSA states: 10\n",
      "k-shuffle FSA states: 24\n",
      "Random n-gram FSA 'entropy': 8.04627\n",
      "k-shuffle FSA 'entropy': 8.04627\n"
     ]
    }
   ],
   "source": [
    "rng_model = RandomNGramModel(alphabet=['a','b'], n=3, alpha=0.3, bos='[BOS]', eos='[EOS]')\n",
    "\n",
    "print(\"Random Ngram FSA states:\", rng_model.fsa.num_states)\n",
    "\n",
    "# define a k=2 shuffle function\n",
    "def swap_block(block):\n",
    "    if len(block)<2:\n",
    "        return block\n",
    "    return [block[1], block[0]]\n",
    "\n",
    "# build a k-shuffle version\n",
    "fsa_k = rng_model.build_kshuffle_fsa(k=2, permute_block=swap_block)\n",
    "print(\"k-shuffle FSA states:\", fsa_k.num_states)\n",
    "\n",
    "# Check stubbed entropy:\n",
    "print(\"Random n-gram FSA 'entropy':\", rng_model.fsa.entropy())\n",
    "print(\"k-shuffle FSA 'entropy':\", fsa_k.entropy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_sampler = Sampler(rng_model.fsa)\n",
    "kshuffle_sampler = Sampler(fsa_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 1997.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['b a a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'b a a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'b a a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'b a a a a [EOS]',\n",
       " 'b a a a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'b a a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'b a a [EOS]',\n",
       " 'b [EOS]',\n",
       " 'a [EOS]',\n",
       " 'b a a [EOS]',\n",
       " 'b a a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'b a a [EOS]',\n",
       " 'b a a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'b a a [EOS]',\n",
       " 'b a a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'b b [EOS]',\n",
       " 'b a a [EOS]',\n",
       " 'b a a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'b a a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'b a a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'b a a [EOS]',\n",
       " 'b a a [EOS]',\n",
       " 'b a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'b a a [EOS]',\n",
       " 'b a a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'b a a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'b a a [EOS]',\n",
       " 'b a a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'b a a [EOS]',\n",
       " 'b a a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'b a a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'b a a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'b a a [EOS]',\n",
       " 'b a a a [EOS]',\n",
       " 'b a a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'b a a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'b a a [EOS]',\n",
       " 'b a a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'b a a b a a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'a [EOS]',\n",
       " 'b a a [EOS]',\n",
       " 'b a a [EOS]',\n",
       " 'a [EOS]']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng_sampler.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomNGramModel:\n",
    "    \"\"\"\n",
    "    Builds a random n-gram model as a Weighted FSA (with Real semiring).\n",
    "    Uses _is_valid_context to skip contexts that contain [EOS]\n",
    "    or that have a [BOS] reappearing after normal tokens.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alphabet, n=2, alpha=1.0, bos='[BOS]', eos='[EOS]'):\n",
    "        \"\"\"\n",
    "        alphabet: list[str]\n",
    "        n: n-gram order\n",
    "        alpha: Dirichlet concentration\n",
    "        bos,eos: boundary tokens\n",
    "        \"\"\"\n",
    "        self.alphabet = alphabet\n",
    "        self.n = n\n",
    "        self.alpha = alpha\n",
    "        self.bos = bos\n",
    "        self.eos = eos\n",
    "\n",
    "        self.fsa = FSA(R=Real)\n",
    "        self._build_ngram_fsa()\n",
    "\n",
    "    def _is_valid_context(self, ctx):\n",
    "        \"\"\"\n",
    "        Rules:\n",
    "        - EOS cannot be in context\n",
    "        - BOS must appear continuously from the left edge, followed by normal characters only\n",
    "        \"\"\"\n",
    "        if self.eos in ctx:\n",
    "            return False\n",
    "        saw_normal = False\n",
    "        for token in ctx:\n",
    "            if token == self.bos:\n",
    "                if saw_normal:\n",
    "                    return False\n",
    "            else:\n",
    "                saw_normal = True\n",
    "        return True\n",
    "\n",
    "    def _build_ngram_fsa(self):\n",
    "        \"\"\"\n",
    "        1) create final absorbing state\n",
    "        2) define contexts (n-1)-tuples from [BOS]+alphabet, excluding [EOS] in context,\n",
    "           only keep them if _is_valid_context(ctx) => True\n",
    "        3) for each context, sample distribution over (alphabet + [EOS]) => arcs\n",
    "        \"\"\"\n",
    "        # final absorbing\n",
    "        q_final = State(\"<FINAL>\")\n",
    "        self.fsa.add_state(q_final)\n",
    "        self.fsa.set_F(q_final, Real.one)\n",
    "\n",
    "        # gather contexts\n",
    "        if self.n <= 1:\n",
    "            all_contexts = [()]\n",
    "        else:\n",
    "            # exclude [EOS] from contexts\n",
    "            context_alphabet = [a for a in self.alphabet if a != self.eos]\n",
    "            # enumerates all (n-1)-tuples\n",
    "            raw_contexts = product(context_alphabet, repeat=self.n-1)\n",
    "            # filter them with _is_valid_context\n",
    "            all_contexts = [ctx for ctx in raw_contexts if self._is_valid_context(ctx)]\n",
    "\n",
    "        self.context2state = {}\n",
    "        for ctx in all_contexts:\n",
    "            sname = str(ctx) if ctx else \"()\"\n",
    "            st = State(sname)\n",
    "            self.fsa.add_state(st)\n",
    "            self.context2state[ctx] = st\n",
    "\n",
    "        # define start context\n",
    "        if self.n>1:\n",
    "            start_ctx = tuple([self.bos]*(self.n-1))\n",
    "        else:\n",
    "            start_ctx = ()\n",
    "        if start_ctx not in self.context2state and self._is_valid_context(start_ctx):\n",
    "            st0 = State(str(start_ctx))\n",
    "            self.fsa.add_state(st0)\n",
    "            self.context2state[start_ctx] = st0\n",
    "\n",
    "        s0 = self.context2state.get(start_ctx, None)\n",
    "        if s0 is None:\n",
    "            # fallback if start_ctx isn't valid => no arcs from start\n",
    "            s0 = State(\"<NoValidStart>\")\n",
    "            self.fsa.add_state(s0)\n",
    "        self.fsa.set_I(s0, Real.one)\n",
    "\n",
    "        # We'll sample distributions for each context\n",
    "        out_alphabet = self.alphabet + [self.eos]\n",
    "        from numpy.random import dirichlet\n",
    "\n",
    "        for ctx in all_contexts:\n",
    "            dist = dirichlet([self.alpha]*len(out_alphabet))\n",
    "            s_from = self.context2state[ctx]\n",
    "            for i, pval in enumerate(dist):\n",
    "                if pval < 1e-15:\n",
    "                    continue\n",
    "                sym = out_alphabet[i]\n",
    "                w = Real(pval)\n",
    "                if sym == self.eos:\n",
    "                    # arc to final\n",
    "                    self.fsa.add_arc(s_from, Sym(sym), q_final, w)\n",
    "                else:\n",
    "                    # shift context\n",
    "                    if self.n>1:\n",
    "                        new_ctx = tuple(list(ctx[1:]) + [sym]) if len(ctx)==(self.n-1) else (sym,)\n",
    "                    else:\n",
    "                        new_ctx = ()\n",
    "                    # must also check if new_ctx is valid => if not, skip\n",
    "                    if self._is_valid_context(new_ctx):\n",
    "                        # ensure state\n",
    "                        if new_ctx not in self.context2state:\n",
    "                            stN = State(str(new_ctx))\n",
    "                            self.fsa.add_state(stN)\n",
    "                            self.context2state[new_ctx] = stN\n",
    "                        s_to = self.context2state[new_ctx]\n",
    "                        self.fsa.add_arc(s_from, Sym(sym), s_to, w)\n",
    "\n",
    "class KShuffleNgram:\n",
    "    \"\"\"\n",
    "    A separate class that merges:\n",
    "      - A RandomNGramModel's FSA\n",
    "      - A k-local block shuffle, via a single symbol-per-transition approach.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ngram_model: RandomNGramModel, k: int, perturbation_fnc):\n",
    "        \"\"\"\n",
    "        ngram_model: a RandomNGramModel\n",
    "        k: block size\n",
    "        perturbation_fnc: function that rearranges a full block\n",
    "        \"\"\"\n",
    "        self.ngram_model = ngram_model\n",
    "        self.k = k\n",
    "        self.perturbation_fnc = perturbation_fnc\n",
    "        self.R = Real\n",
    "\n",
    "        self.fsa = FSA(R=self.R)\n",
    "        self._build_kshuffle()\n",
    "\n",
    "    def _build_kshuffle(self):\n",
    "        # final\n",
    "        q_final = State(\"<KSHUFFLE_FINAL>\")\n",
    "        self.fsa.add_state(q_final)\n",
    "        self.fsa.set_F(q_final, Real.one)\n",
    "\n",
    "        # base_fsa\n",
    "        base_fsa = self.ngram_model.fsa\n",
    "\n",
    "        # We'll track states as (context, buffer_tuple)\n",
    "        # BFS approach\n",
    "        visited = set()\n",
    "        queue = deque()\n",
    "\n",
    "        # define start context\n",
    "        if self.ngram_model.n>1:\n",
    "            start_ctx = tuple([self.ngram_model.bos]*(self.ngram_model.n-1))\n",
    "        else:\n",
    "            start_ctx = ()\n",
    "        def ensure_state(ctx, buf):\n",
    "            st_name = f\"{ctx}|{buf}\"\n",
    "            st = State(st_name)\n",
    "            self.fsa.add_state(st)\n",
    "            return st\n",
    "\n",
    "        s0 = ensure_state(start_ctx, ())\n",
    "        self.fsa.set_I(s0, Real.one)\n",
    "        queue.append((start_ctx, ()))\n",
    "        visited.add((start_ctx, ()))\n",
    "\n",
    "        # find base_fsa final states:\n",
    "        base_final_states = set()\n",
    "        for q, w in base_fsa.F:\n",
    "            if w != self.R.zero:\n",
    "                base_final_states.add(q)\n",
    "\n",
    "        # We'll need a reverse map for base_fsa context -> state\n",
    "        # But we have ngram_model.context2state\n",
    "        inv_map = {v: k for k, v in self.ngram_model.context2state.items()}\n",
    "\n",
    "        def get_arcs_for_context(ctx):\n",
    "            \"\"\"\n",
    "            Return arcs from the base_fsa for the state that represents ctx.\n",
    "            Using base_fsa.arcs(...).\n",
    "            \"\"\"\n",
    "            st_base = self.ngram_model.context2state.get(ctx, None)\n",
    "            if not st_base:\n",
    "                return []\n",
    "            results = []\n",
    "            for (a, j, w) in base_fsa.arcs(st_base, nozero=True, no_eps=True, reverse=False):\n",
    "                results.append((a, j, w))\n",
    "            return results\n",
    "\n",
    "        while queue:\n",
    "            (ctx, buf) = queue.popleft()\n",
    "            s_from = ensure_state(ctx, buf)\n",
    "\n",
    "            # if base context is final => flush leftover, go final\n",
    "            st_base = self.ngram_model.context2state.get(ctx, None)\n",
    "            base_is_final = (st_base in base_final_states) if st_base else False\n",
    "            if base_is_final:\n",
    "                # flush leftover\n",
    "                current_st = s_from\n",
    "                for symL in buf:\n",
    "                    st_next = ensure_state(ctx, ())\n",
    "                    self.fsa.add_arc(current_st, Sym(symL), st_next, Real.one)\n",
    "                    current_st = st_next\n",
    "                # then arc to <KSHUFFLE_FINAL>\n",
    "                self.fsa.add_arc(current_st, Sym(self.ngram_model.eos), q_final, Real.one)\n",
    "\n",
    "            # if buffer < k => we can read more from base_fsa\n",
    "            if len(buf) < self.k and not base_is_final:\n",
    "                # arcs from base_fsa\n",
    "                arcs_list = get_arcs_for_context(ctx)\n",
    "                for (a, j, w) in arcs_list:\n",
    "                    if w == self.R.zero:\n",
    "                        continue\n",
    "                    symbol = str(a)\n",
    "                    if symbol == self.ngram_model.eos:\n",
    "                        # end => flush leftover\n",
    "                        # do same approach\n",
    "                        current_st = s_from\n",
    "                        for symL in buf:\n",
    "                            st_next = ensure_state(ctx, ())\n",
    "                            self.fsa.add_arc(current_st, Sym(symL), st_next, Real.one)\n",
    "                            current_st = st_next\n",
    "                        # then go final\n",
    "                        self.fsa.add_arc(current_st, a, q_final, w)\n",
    "                    else:\n",
    "                        # read\n",
    "                        new_ctx = inv_map.get(j, None)\n",
    "                        if new_ctx is None:\n",
    "                            # skip if no known context\n",
    "                            continue\n",
    "                        new_buf = tuple(list(buf) + [symbol])\n",
    "                        to_key = (new_ctx, new_buf)\n",
    "                        if to_key not in visited:\n",
    "                            visited.add(to_key)\n",
    "                            queue.append(to_key)\n",
    "                        s_to = ensure_state(new_ctx, new_buf)\n",
    "                        # emit epsilon\n",
    "                        self.fsa.add_arc(s_from, Sym(''), s_to, w)\n",
    "\n",
    "            # if buffer == k => we output the block in permuted order\n",
    "            if len(buf) == self.k:\n",
    "                # do single-step chain\n",
    "                pblock = self.perturbation_fnc(list(buf))\n",
    "                current_st = s_from\n",
    "                for tok in pblock:\n",
    "                    mid_st = ensure_state(ctx, buf)\n",
    "                    self.fsa.add_arc(current_st, Sym(tok), mid_st, Real.one)\n",
    "                    current_st = mid_st\n",
    "                # after that => empty buffer\n",
    "                final_st = ensure_state(ctx, ())\n",
    "                self.fsa.add_arc(current_st, Sym(''), final_st, Real.one)\n",
    "                # queue next\n",
    "                if (ctx, ()) not in visited:\n",
    "                    visited.add((ctx, ()))\n",
    "                    queue.append((ctx, ()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random N-gram FSA states: 4\n",
      "k-shuffle FSA states: 16\n",
      "Base FSA 'entropy': 24.71265\n",
      "K-shuffle FSA 'entropy': 0.19565\n"
     ]
    }
   ],
   "source": [
    "# Suppose we have an alphabet\n",
    "alphabet = [\"[BOS]\", \"[EOS]\", \"a\", \"b\"]\n",
    "\n",
    "# Build a random 2-gram model\n",
    "rng_model = RandomNGramModel(alphabet=alphabet, n=2, alpha=1.0, bos=\"[BOS]\", eos=\"[EOS]\")\n",
    "print(\"Random N-gram FSA states:\", rng_model.fsa.num_states)\n",
    "\n",
    "# define a simple block-permutation function\n",
    "def swap2(block):\n",
    "    if len(block)==2:\n",
    "        return [block[1], block[0]]\n",
    "    return block\n",
    "\n",
    "# Build KShuffleNgram\n",
    "kshuf = KShuffleNgram(ngram_model=rng_model, k=2, perturbation_fnc=swap2)\n",
    "print(\"k-shuffle FSA states:\", kshuf.fsa.num_states)\n",
    "\n",
    "# Show stub entropies\n",
    "print(\"Base FSA 'entropy':\", rng_model.fsa.entropy())\n",
    "print(\"K-shuffle FSA 'entropy':\", kshuf.fsa.entropy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random NGram FSA states: 4\n",
      "K-shuffle FSA states: 10\n",
      "Base ngram FSA entropy: 18.85219\n",
      "K-shuffle FSA entropy: 0.27923\n"
     ]
    }
   ],
   "source": [
    "class RandomNGramModel:\n",
    "    \"\"\"\n",
    "    Builds a random n-gram model as a Weighted FSA (with Real semiring),\n",
    "    WITHOUT requiring user to pass [BOS] or [EOS] in the 'alphabet'.\n",
    "    We'll define them as internal tokens.\n",
    "    \"\"\"\n",
    "\n",
    "    _BOS = Sym(\"<BOS>\")\n",
    "    _EOS = Sym(\"<EOS>\")\n",
    "\n",
    "    def __init__(self,\n",
    "                 alphabet,         # user-supplied normal symbols (no BOS/EOS)\n",
    "                 n=2,\n",
    "                 alpha=1.0):\n",
    "        \"\"\"\n",
    "        alphabet: list of normal symbols (no boundary tokens)\n",
    "        n: n-gram order\n",
    "        alpha: Dirichlet concentration\n",
    "        \"\"\"\n",
    "        self.alphabet = alphabet  # user symbols only\n",
    "        self.n = n\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.fsa = FSA(R=Real)\n",
    "        self._build_ngram_fsa()\n",
    "\n",
    "    def _is_valid_context(self, ctx):\n",
    "        \"\"\"\n",
    "        Let's define:\n",
    "        - <EOS> cannot be in context\n",
    "        - <BOS> must appear from left to right with no normal tokens before it\n",
    "        (Similar logic to the older snippet)\n",
    "        But if you want simpler logic, you can skip or adjust.\n",
    "        \"\"\"\n",
    "        if self._EOS in ctx:\n",
    "            return False\n",
    "        saw_normal = False\n",
    "        for token in ctx:\n",
    "            if token == self._BOS:\n",
    "                if saw_normal:\n",
    "                    return False\n",
    "            else:\n",
    "                saw_normal = True\n",
    "        return True\n",
    "\n",
    "    def _build_ngram_fsa(self):\n",
    "        \"\"\"\n",
    "        1) define final absorbing state\n",
    "        2) define contexts: (n-1)-tuples from {<BOS>}+alphabet (no <EOS> in context),\n",
    "           filter them with _is_valid_context\n",
    "        3) for each context, sample distribution over alphabet + <EOS>\n",
    "        4) arcs to next context or final\n",
    "        \"\"\"\n",
    "        q_final = State(\"<<FINAL>>\")\n",
    "        self.fsa.add_state(q_final)\n",
    "        self.fsa.set_F(q_final, Real.one)\n",
    "\n",
    "        # define possible for contexts\n",
    "        if self.n <= 1:\n",
    "            all_contexts = [()]\n",
    "        else:\n",
    "            context_syms = [self._BOS] + self.alphabet  # no <EOS> here\n",
    "            raw = product(context_syms, repeat=self.n-1)\n",
    "            all_contexts = [ctx for ctx in raw if self._is_valid_context(ctx)]\n",
    "\n",
    "        # create states for each context\n",
    "        self.context2state = {}\n",
    "        for ctx in all_contexts:\n",
    "            st = State(str(ctx) if ctx else \"()\")\n",
    "            self.fsa.add_state(st)\n",
    "            self.context2state[ctx] = st\n",
    "\n",
    "        # define start context = (<BOS>, ... <BOS>) if n>1 else ()\n",
    "        if self.n>1:\n",
    "            start_ctx = tuple([self._BOS]*(self.n-1))\n",
    "        else:\n",
    "            start_ctx = ()\n",
    "\n",
    "        # if not valid, no arcs from start\n",
    "        if self._is_valid_context(start_ctx):\n",
    "            if start_ctx not in self.context2state:\n",
    "                s0_ = State(str(start_ctx))\n",
    "                self.fsa.add_state(s0_)\n",
    "                self.context2state[start_ctx] = s0_\n",
    "            s0 = self.context2state[start_ctx]\n",
    "        else:\n",
    "            s0 = State(\"<NoValidStart>\")\n",
    "            self.fsa.add_state(s0)\n",
    "\n",
    "        self.fsa.set_I(s0, Real.one)\n",
    "\n",
    "        # for each context, sample distribution over (alphabet + <EOS>)\n",
    "        out_syms = list(self.alphabet) + [self._EOS]\n",
    "        from numpy.random import dirichlet\n",
    "\n",
    "        for ctx in all_contexts:\n",
    "            dist = dirichlet([self.alpha]*len(out_syms))\n",
    "            s_from = self.context2state[ctx]\n",
    "            for i, pval in enumerate(dist):\n",
    "                if pval < 1e-15:\n",
    "                    continue\n",
    "                sym = out_syms[i]\n",
    "                w = Real(pval)\n",
    "                if sym == self._EOS:\n",
    "                    # arc to q_final\n",
    "                    self.fsa.add_arc(s_from, sym, q_final, w)\n",
    "                else:\n",
    "                    # shift context\n",
    "                    if self.n>1:\n",
    "                        new_ctx = tuple(list(ctx[1:]) + [sym]) if len(ctx)==(self.n-1) else (sym,)\n",
    "                    else:\n",
    "                        new_ctx = ()\n",
    "\n",
    "                    if self._is_valid_context(new_ctx):\n",
    "                        if new_ctx not in self.context2state:\n",
    "                            st_new = State(str(new_ctx) if new_ctx else \"()\")\n",
    "                            self.fsa.add_state(st_new)\n",
    "                            self.context2state[new_ctx] = st_new\n",
    "                        s_to = self.context2state[new_ctx]\n",
    "                        self.fsa.add_arc(s_from, sym, s_to, w)\n",
    "\n",
    "###############################################################################\n",
    "# (D) KShuffleNgram for optional k-local block shuffle\n",
    "###############################################################################\n",
    "\n",
    "class KShuffleNgram:\n",
    "    \"\"\"\n",
    "    Takes the ngram_model's FSA and merges in a k-local shuffle approach.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ngram_model: RandomNGramModel, k: int, perturbation_fnc):\n",
    "        self.ngram_model = ngram_model\n",
    "        self.k = k\n",
    "        self.perturbation_fnc = perturbation_fnc\n",
    "        self.R = Real\n",
    "\n",
    "        self.fsa = FSA(R=self.R)\n",
    "        self._build_kshuffle()\n",
    "\n",
    "    def _build_kshuffle(self):\n",
    "        q_final = State(\"<KSHUFFLE_FINAL>\")\n",
    "        self.fsa.add_state(q_final)\n",
    "        self.fsa.set_F(q_final, Real.one)\n",
    "\n",
    "        base_fsa = self.ngram_model.fsa\n",
    "\n",
    "        visited = set()\n",
    "        queue = deque()\n",
    "\n",
    "        # start context: same logic\n",
    "        if self.ngram_model.n>1:\n",
    "            start_ctx = tuple([self.ngram_model._BOS]*(self.ngram_model.n-1))\n",
    "        else:\n",
    "            start_ctx = ()\n",
    "\n",
    "        def ensure_state(ctx, buf):\n",
    "            name = f\"{ctx}|{buf}\"\n",
    "            st = State(name)\n",
    "            self.fsa.add_state(st)\n",
    "            return st\n",
    "\n",
    "        s0 = ensure_state(start_ctx, ())\n",
    "        self.fsa.set_I(s0, Real.one)\n",
    "        visited.add((start_ctx, ()))\n",
    "        queue.append((start_ctx, ()))\n",
    "\n",
    "        base_final_states = set()\n",
    "        for (q, w) in base_fsa.F:\n",
    "            if w != self.R.zero:\n",
    "                base_final_states.add(q)\n",
    "\n",
    "        # We invert the ngram_model's context2state dict for arcs\n",
    "        inv_map = {v: k for (k,v) in self.ngram_model.context2state.items()}\n",
    "\n",
    "        def arcs_for_ctx(ctx):\n",
    "            # Return arcs from base_fsa for the state representing 'ctx'\n",
    "            st_base = self.ngram_model.context2state.get(ctx, None)\n",
    "            if not st_base:\n",
    "                return []\n",
    "            results = []\n",
    "            # gather arcs from st_base\n",
    "            for (a, j, w) in base_fsa.arcs(st_base, nozero=True, no_eps=True):\n",
    "                results.append((a,j,w))\n",
    "            return results\n",
    "\n",
    "        while queue:\n",
    "            (ctx, buf) = queue.popleft()\n",
    "            s_from = ensure_state(ctx, buf)\n",
    "\n",
    "            st_base = self.ngram_model.context2state.get(ctx, None)\n",
    "            base_is_final = (st_base in base_final_states) if st_base else False\n",
    "\n",
    "            if base_is_final:\n",
    "                # flush leftover => final\n",
    "                current_st = s_from\n",
    "                for leftover_tok in buf:\n",
    "                    mid_st = ensure_state(ctx, ())\n",
    "                    self.fsa.add_arc(current_st, Sym(leftover_tok), mid_st, Real.one)\n",
    "                    current_st = mid_st\n",
    "                self.fsa.add_arc(current_st, Sym(self.ngram_model._EOS), q_final, Real.one)\n",
    "\n",
    "            # read if buffer<k\n",
    "            if len(buf)<self.k and not base_is_final:\n",
    "                A = arcs_for_ctx(ctx)\n",
    "                for (a,j,w) in A:\n",
    "                    if w == self.R.zero:\n",
    "                        continue\n",
    "                    symbol = str(a)\n",
    "                    if a == self.ngram_model._EOS:\n",
    "                        # flush leftover => final\n",
    "                        cur_st = s_from\n",
    "                        for tok_ in buf:\n",
    "                            mid_st = ensure_state(ctx, ())\n",
    "                            self.fsa.add_arc(cur_st, Sym(tok_), mid_st, Real.one)\n",
    "                            cur_st = mid_st\n",
    "                        self.fsa.add_arc(cur_st, a, q_final, w)\n",
    "                    else:\n",
    "                        new_ctx = inv_map.get(j, None)\n",
    "                        if new_ctx is not None:\n",
    "                            new_buf = tuple(list(buf) + [symbol])\n",
    "                            if (new_ctx,new_buf) not in visited:\n",
    "                                visited.add((new_ctx,new_buf))\n",
    "                                queue.append((new_ctx,new_buf))\n",
    "                            s_to = ensure_state(new_ctx, new_buf)\n",
    "                            # epsilon\n",
    "                            self.fsa.add_arc(s_from, Sym(''), s_to, w)\n",
    "\n",
    "            # if buffer==k => output block\n",
    "            if len(buf)==self.k:\n",
    "                pblock = self.perturbation_fnc(list(buf))\n",
    "                current_st = s_from\n",
    "                for out_sym in pblock:\n",
    "                    mid_st = ensure_state(ctx, buf)\n",
    "                    self.fsa.add_arc(current_st, Sym(out_sym), mid_st, Real.one)\n",
    "                    current_st = mid_st\n",
    "                # reset buffer\n",
    "                final_st = ensure_state(ctx, ())\n",
    "                self.fsa.add_arc(current_st, Sym(''), final_st, Real.one)\n",
    "                if (ctx,()) not in visited:\n",
    "                    visited.add((ctx,()))\n",
    "                    queue.append((ctx,()))\n",
    "\n",
    "###############################################################################\n",
    "# Example usage\n",
    "###############################################################################\n",
    "if __name__==\"__main__\":\n",
    "    # Suppose the user has an alphabet with no boundary tokens\n",
    "    user_alphabet = ['a','b']\n",
    "\n",
    "    # Build a random 2-gram model\n",
    "    rng_model = RandomNGramModel(alphabet=user_alphabet, n=2, alpha=1.0)\n",
    "    print(\"Random NGram FSA states:\", rng_model.fsa.num_states)\n",
    "\n",
    "    # define a simple block-permutation\n",
    "    def swap2(block):\n",
    "        if len(block)==2:\n",
    "            return [block[1], block[0]]\n",
    "        return block\n",
    "\n",
    "    # build the k-shuffle version\n",
    "    kmodel = KShuffleNgram(rng_model, k=2, perturbation_fnc=swap2)\n",
    "    print(\"K-shuffle FSA states:\", kmodel.fsa.num_states)\n",
    "\n",
    "    # show stubbed entropies\n",
    "    print(\"Base ngram FSA entropy:\", rng_model.fsa.entropy())\n",
    "    print(\"K-shuffle FSA entropy:\", kmodel.fsa.entropy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 656.84it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a a b a a b <EOS>',\n",
       " 'b <EOS>',\n",
       " '<EOS>',\n",
       " 'a b <EOS>',\n",
       " 'a b <EOS>',\n",
       " 'a b a b <EOS>',\n",
       " '<EOS>',\n",
       " 'a b <EOS>',\n",
       " 'c a b <EOS>',\n",
       " 'a a b b c a b b b a a c <EOS>']"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler = Sampler(rng_model.fsa)\n",
    "sampler.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base n-gram FSA states: 14\n",
      "K-shuffle FSA states: 53\n",
      "Base n-gram FSA entropy: 23.57117\n",
      "K-shuffle FSA entropy: 23.57117\n"
     ]
    }
   ],
   "source": [
    "from rayuela.base.symbol import EOS, BOS, ε\n",
    "\n",
    "class RandomNGramModel:\n",
    "    \"\"\"\n",
    "    Builds a random n-gram model as a Weighted FSA (with Real semiring),\n",
    "    with internal BOS, EOS tokens not in the user's alphabet.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 alphabet,  # user-supplied normal symbols\n",
    "                 n=2,\n",
    "                 alpha=1.0):\n",
    "        \"\"\"\n",
    "        alphabet: list of normal symbols (no boundary tokens)\n",
    "        n: n-gram order\n",
    "        alpha: Dirichlet concentration\n",
    "        \"\"\"\n",
    "        self.alphabet = alphabet  # user symbols only\n",
    "        self.n = n\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.fsa = FSA(R=Real)\n",
    "        self.context2state = {}  # to store (n-1)-tuple -> State\n",
    "        self._build_ngram_fsa()\n",
    "\n",
    "    def _is_valid_context(self, ctx):\n",
    "        \"\"\"\n",
    "        If we want to prevent EOS in context\n",
    "        and not have BOS reappear after normal tokens:\n",
    "        \"\"\"\n",
    "        if EOS in ctx:\n",
    "            return False\n",
    "        saw_normal = False\n",
    "        for token in ctx:\n",
    "            if token == BOS:\n",
    "                if saw_normal:\n",
    "                    return False\n",
    "            else:\n",
    "                saw_normal = True\n",
    "        return True\n",
    "\n",
    "    def _build_ngram_fsa(self):\n",
    "        \"\"\"\n",
    "        1) define final absorbing state\n",
    "        2) define contexts: (n-1)-tuples from {BOS}+alphabet, skip EOS in context\n",
    "        3) sample dist over (alphabet + EOS), add arcs\n",
    "        \"\"\"\n",
    "        q_final = State(\"<<FINAL>>\")\n",
    "        self.fsa.add_state(q_final)\n",
    "        self.fsa.set_F(q_final, Real.one)\n",
    "\n",
    "        if self.n <= 1:\n",
    "            all_ctxs = [()]\n",
    "        else:\n",
    "            # possible context symbols\n",
    "            csyms = [BOS] + self.alphabet  # not EOS\n",
    "            raw = product(csyms, repeat=self.n-1)\n",
    "            all_ctxs = [r for r in raw if self._is_valid_context(r)]\n",
    "\n",
    "        # build states\n",
    "        for ctx in all_ctxs:\n",
    "            sname = str(ctx) if ctx else \"()\"\n",
    "            st = State(sname)\n",
    "            self.fsa.add_state(st)\n",
    "            self.context2state[ctx] = st\n",
    "\n",
    "        # start ctx\n",
    "        if self.n>1:\n",
    "            start_ctx = tuple([BOS]*(self.n-1))\n",
    "        else:\n",
    "            start_ctx = ()\n",
    "        if self._is_valid_context(start_ctx) and start_ctx not in self.context2state:\n",
    "            st0_ = State(str(start_ctx) if start_ctx else \"()\")\n",
    "            self.fsa.add_state(st0_)\n",
    "            self.context2state[start_ctx] = st0_\n",
    "\n",
    "        s0 = self.context2state.get(start_ctx, State(\"<INVALIDSTART>\"))\n",
    "        self.fsa.add_state(s0)\n",
    "        self.fsa.set_I(s0, Real.one)\n",
    "\n",
    "        # sample distributions\n",
    "        out_syms = list(self.alphabet) + [EOS]\n",
    "        from numpy.random import dirichlet\n",
    "\n",
    "        for ctx in all_ctxs:\n",
    "            dist = dirichlet([self.alpha]*len(out_syms))\n",
    "            s_from = self.context2state[ctx]\n",
    "            for i, pval in enumerate(dist):\n",
    "                if pval<1e-15:\n",
    "                    continue\n",
    "                sym = out_syms[i]\n",
    "                w = Real(pval)\n",
    "                if sym==EOS:\n",
    "                    # arc to final\n",
    "                    self.fsa.set_arc(s_from, sym, q_final, w)\n",
    "                else:\n",
    "                    if self.n>1:\n",
    "                        new_ctx = tuple(list(ctx[1:]) + [sym]) if len(ctx)==(self.n-1) else (sym,)\n",
    "                    else:\n",
    "                        new_ctx = ()\n",
    "\n",
    "                    if self._is_valid_context(new_ctx):\n",
    "                        if new_ctx not in self.context2state:\n",
    "                            stN = State(str(new_ctx) if new_ctx else \"()\")\n",
    "                            self.fsa.add_state(stN)\n",
    "                            self.context2state[new_ctx] = stN\n",
    "                        s_to = self.context2state[new_ctx]\n",
    "                        self.fsa.set_arc(s_from, sym, s_to, w)\n",
    "\n",
    "class KShuffleNgram:\n",
    "    \"\"\"\n",
    "    BFS-labeled approach: states=(ctx,buf).\n",
    "    When we reach a full block or leftover, we output it symbol-by-symbol to\n",
    "    EXACTLY ONE ephemeral pivot state, then from pivot -> next BFS-labeled.\n",
    "    This ensures we don't do arcs from (ctx,buf) to itself for each symbol.\n",
    "    Also we use set_arc to avoid doubling if BFS hits the same arc multiple times.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ngram_model: RandomNGramModel, k: int, perturbation_fnc):\n",
    "        self.ngram_model = ngram_model\n",
    "        self.k = k\n",
    "        self.perturbation_fnc = perturbation_fnc\n",
    "        self.R = Real\n",
    "\n",
    "        self.fsa = FSA(R=self.R)\n",
    "        self._build_kshuffle()\n",
    "\n",
    "    def _build_kshuffle(self):\n",
    "        base_fsa = self.ngram_model.fsa\n",
    "\n",
    "        q_final = State(\"<KSHUFFLE_FINAL>\")\n",
    "        self.fsa.add_state(q_final)\n",
    "        self.fsa.set_F(q_final)\n",
    "\n",
    "        queue = deque()\n",
    "        visited = set()\n",
    "\n",
    "        if self.ngram_model.n>1:\n",
    "            start_ctx = tuple([BOS]*(self.ngram_model.n-1))\n",
    "        else:\n",
    "            start_ctx = ()\n",
    "\n",
    "        def ensure_state(ctx, buf):\n",
    "            sname = f\"{ctx}|{buf}\"\n",
    "            st = State(sname)\n",
    "            self.fsa.add_state(st)\n",
    "            return st\n",
    "\n",
    "        s0 = ensure_state(start_ctx, ())\n",
    "        self.fsa.set_I(s0)\n",
    "        visited.add((start_ctx, ()))\n",
    "        queue.append((start_ctx, ()))\n",
    "\n",
    "        # final states in base_fsa\n",
    "        base_final = set()\n",
    "        for (qq,ww) in base_fsa.F:\n",
    "            if ww!=self.R.zero:\n",
    "                base_final.add(qq)\n",
    "        inv_map = {v:k for (k,v) in self.ngram_model.context2state.items()}\n",
    "\n",
    "        def arcs_for_ctx(ctx):\n",
    "            st_base = self.ngram_model.context2state.get(ctx,None)\n",
    "            if st_base is None:\n",
    "                return []\n",
    "            results=[]\n",
    "            for (a,j,w) in base_fsa.arcs(st_base, nozero=True, no_eps=True):\n",
    "                results.append((a,j,w))\n",
    "            return results\n",
    "\n",
    "        while queue:\n",
    "            (ctx, buf) = queue.popleft()\n",
    "            s_from = ensure_state(ctx, buf)\n",
    "\n",
    "            st_base = self.ngram_model.context2state.get(ctx,None)\n",
    "            if st_base in base_final or st_base is None:\n",
    "                raise ValueError(\"Base final state reached\")\n",
    "\n",
    "            # 2) If buffer < k => read arcs from base\n",
    "            if len(buf)<self.k:\n",
    "                A = arcs_for_ctx(ctx)\n",
    "                for (a,j,w) in A:\n",
    "                    if w==self.R.zero:\n",
    "                        continue\n",
    "                    if a==EOS:\n",
    "                        # partial leftover\n",
    "                        leftover_list = list(buf)\n",
    "                        pblock = self.perturbation_fnc(leftover_list)\n",
    "                        if pblock:\n",
    "                            comb = \"\".join(pblock)\n",
    "                            pivot = State(f\"PARTIAL_EMIT{ctx}_{buf}\")\n",
    "                            self.fsa.add_state(pivot)\n",
    "                            self.fsa.set_arc(s_from, Sym(comb), pivot, self.R.one)\n",
    "                            self.fsa.set_arc(pivot, Sym(str(a)), q_final, w)\n",
    "                        else:\n",
    "                            self.fsa.set_arc(s_from, Sym(str(a)), q_final, w)\n",
    "                    else:\n",
    "                        symbol = str(a)\n",
    "                        new_ctx = inv_map.get(j,None)\n",
    "                        if new_ctx is None:\n",
    "                            continue\n",
    "                        new_buf = tuple(list(buf)+[symbol])\n",
    "                        if (new_ctx,new_buf) not in visited:\n",
    "                            visited.add((new_ctx,new_buf))\n",
    "                            queue.append((new_ctx,new_buf))\n",
    "                        s_to = ensure_state(new_ctx,new_buf)\n",
    "                        # epsilon\n",
    "                        self.fsa.set_arc(s_from, ε, s_to, w)\n",
    "                continue\n",
    "\n",
    "            # 3) else => buffer==k => full block\n",
    "            if len(buf)==self.k:\n",
    "                pblock = self.perturbation_fnc(list(buf))\n",
    "                comb = \"\".join(pblock)\n",
    "                pivot = State(f\"FULL_EMIT{ctx}_{buf}\")\n",
    "                self.fsa.add_state(pivot)\n",
    "                self.fsa.set_arc(s_from, Sym(comb), pivot, self.R.one)\n",
    "\n",
    "                # now pivot => (ctx,())\n",
    "                final_st = ensure_state(ctx,())\n",
    "                self.fsa.set_arc(pivot, ε, final_st, self.R.one)\n",
    "\n",
    "                if (ctx,()) not in visited:\n",
    "                    visited.add((ctx,()))\n",
    "                    queue.append((ctx,()))\n",
    "                continue\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## working implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base n-gram FSA states: 8\n",
      "K-shuffle FSA states: 62\n",
      "Base n-gram FSA entropy: 34.45959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-shuffle FSA entropy: 34.45959\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import copy\n",
    "from collections import Counter\n",
    "from collections import defaultdict as dd\n",
    "from collections import deque\n",
    "from itertools import product\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "from rayuela.base.semiring import Boolean, ProductSemiring, Real, Semiring\n",
    "from rayuela.base.state import PairState, State\n",
    "from rayuela.base.symbol import Sym, ε\n",
    "from rayuela.fsa.pathsum import Pathsum\n",
    "from rayuela.fsa.fsa import FSA\n",
    "\n",
    "from rayuela.base.symbol import EOS, BOS, ε\n",
    "from rayuela.fsa.sampler import Sampler\n",
    "\n",
    "\n",
    "class RandomNGramModel:\n",
    "    \"\"\"\n",
    "    Builds a random n-gram model as a Weighted FSA (with Real semiring),\n",
    "    with internal BOS, EOS tokens not in the user's alphabet.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 alphabet,  # user-supplied normal symbols\n",
    "                 n=2,\n",
    "                 alpha=1.0):\n",
    "        \"\"\"\n",
    "        alphabet: list of normal symbols (no boundary tokens)\n",
    "        n: n-gram order\n",
    "        alpha: Dirichlet concentration\n",
    "        \"\"\"\n",
    "        self.alphabet = alphabet  # user symbols only\n",
    "        self.n = n\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.fsa = FSA(R=Real)\n",
    "        self.context2state = {}  # to store (n-1)-tuple -> State\n",
    "        self._build_ngram_fsa()\n",
    "\n",
    "    def _is_valid_context(self, ctx):\n",
    "        \"\"\"\n",
    "        If we want to prevent EOS in context\n",
    "        and not have BOS reappear after normal tokens:\n",
    "        \"\"\"\n",
    "        if EOS in ctx:\n",
    "            return False\n",
    "        saw_normal = False\n",
    "        for token in ctx:\n",
    "            if token == BOS:\n",
    "                if saw_normal:\n",
    "                    return False\n",
    "            else:\n",
    "                saw_normal = True\n",
    "        return True\n",
    "\n",
    "    def _build_ngram_fsa(self):\n",
    "        \"\"\"\n",
    "        1) define final absorbing state\n",
    "        2) define contexts: (n-1)-tuples from {BOS}+alphabet, skip EOS in context\n",
    "        3) sample dist over (alphabet + EOS), add arcs\n",
    "        \"\"\"\n",
    "        q_final = State(\"<<FINAL>>\")\n",
    "        self.fsa.add_state(q_final)\n",
    "        self.fsa.set_F(q_final, Real.one)\n",
    "\n",
    "        if self.n <= 1:\n",
    "            all_ctxs = [()]\n",
    "        else:\n",
    "            # possible context symbols\n",
    "            csyms = [BOS] + self.alphabet  # not EOS\n",
    "            raw = product(csyms, repeat=self.n-1)\n",
    "            all_ctxs = [r for r in raw if self._is_valid_context(r)]\n",
    "\n",
    "        # build states\n",
    "        for ctx in all_ctxs:\n",
    "            sname = str(ctx) if ctx else \"()\"\n",
    "            st = State(sname)\n",
    "            self.fsa.add_state(st)\n",
    "            self.context2state[ctx] = st\n",
    "\n",
    "        # start ctx\n",
    "        if self.n>1:\n",
    "            start_ctx = tuple([BOS]*(self.n-1))\n",
    "        else:\n",
    "            start_ctx = ()\n",
    "        if self._is_valid_context(start_ctx) and start_ctx not in self.context2state:\n",
    "            st0_ = State(str(start_ctx) if start_ctx else \"()\")\n",
    "            self.fsa.add_state(st0_)\n",
    "            self.context2state[start_ctx] = st0_\n",
    "\n",
    "        s0 = self.context2state.get(start_ctx, State(\"<INVALIDSTART>\"))\n",
    "        self.fsa.add_state(s0)\n",
    "        self.fsa.set_I(s0, Real.one)\n",
    "\n",
    "        # sample distributions\n",
    "        out_syms = list(self.alphabet) + [EOS]\n",
    "        from numpy.random import dirichlet\n",
    "\n",
    "        for ctx in all_ctxs:\n",
    "            dist = dirichlet([self.alpha]*len(out_syms))\n",
    "            s_from = self.context2state[ctx]\n",
    "            for i, pval in enumerate(dist):\n",
    "                if pval<1e-15:\n",
    "                    continue\n",
    "                sym = out_syms[i]\n",
    "                w = Real(pval)\n",
    "                if sym==EOS:\n",
    "                    # arc to final\n",
    "                    self.fsa.set_arc(s_from, sym, q_final, w)\n",
    "                else:\n",
    "                    if self.n>1:\n",
    "                        new_ctx = tuple(list(ctx[1:]) + [sym]) if len(ctx)==(self.n-1) else (sym,)\n",
    "                    else:\n",
    "                        new_ctx = ()\n",
    "\n",
    "                    if self._is_valid_context(new_ctx):\n",
    "                        if new_ctx not in self.context2state:\n",
    "                            stN = State(str(new_ctx) if new_ctx else \"()\")\n",
    "                            self.fsa.add_state(stN)\n",
    "                            self.context2state[new_ctx] = stN\n",
    "                        s_to = self.context2state[new_ctx]\n",
    "                        self.fsa.set_arc(s_from, sym, s_to, w)\n",
    "\n",
    "\n",
    "class KShuffleNgram:\n",
    "    \"\"\"\n",
    "    Naive approach: states=(ctx,buf).\n",
    "    => We store partially read block in 'buf'.\n",
    "    => If we must emit that block (full or leftover), we create a small chain\n",
    "       of ephemeral states, each responsible for a single symbol output.\n",
    "\n",
    "    That is \"one symbol per transition\" for each flush.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ngram_model: RandomNGramModel, k: int, perturbation_fnc):\n",
    "        self.ngram_model = ngram_model\n",
    "        self.k = k\n",
    "        self.perturbation_fnc = perturbation_fnc\n",
    "        self.R = Real\n",
    "\n",
    "        self.fsa = FSA(R=self.R)\n",
    "        self._build_kshuffle()\n",
    "\n",
    "    def _build_kshuffle(self):\n",
    "        base_fsa = self.ngram_model.fsa\n",
    "\n",
    "        # new final\n",
    "        q_final = State(\"<KSHUFFLE_FINAL>\")\n",
    "        self.fsa.add_state(q_final)\n",
    "        self.fsa.set_F(q_final, Real.one)\n",
    "\n",
    "        queue = deque()\n",
    "        visited = set()\n",
    "\n",
    "        if self.ngram_model.n>1:\n",
    "            start_ctx = tuple([BOS]*(self.ngram_model.n-1))\n",
    "        else:\n",
    "            start_ctx = ()\n",
    "\n",
    "        def ensure_state(ctx, buf):\n",
    "            sname = f\"{ctx}|{buf}\"\n",
    "            st = State(sname)\n",
    "            self.fsa.add_state(st)\n",
    "            return st\n",
    "\n",
    "        s0 = ensure_state(start_ctx, ())\n",
    "        self.fsa.set_I(s0, Real.one)\n",
    "        visited.add((start_ctx, ()))\n",
    "        queue.append((start_ctx, ()))\n",
    "\n",
    "        # final states in base_fsa\n",
    "        base_final = set()\n",
    "        for (qq,ww) in base_fsa.F:\n",
    "            if ww!=self.R.zero:\n",
    "                base_final.add(qq)\n",
    "\n",
    "        inv_map = {v:k for (k,v) in self.ngram_model.context2state.items()}\n",
    "\n",
    "        # gather arcs from base FSA for a given context\n",
    "        def arcs_for_ctx(ctx):\n",
    "            st_base = self.ngram_model.context2state.get(ctx,None)\n",
    "            if st_base is None:\n",
    "                return []\n",
    "            results=[]\n",
    "            for (a,j,w) in base_fsa.arcs(st_base, no_eps=True, nozero=True, reverse=False):\n",
    "                results.append((a,j,w))\n",
    "            return results\n",
    "\n",
    "        while queue:\n",
    "            (ctx, buf) = queue.popleft()\n",
    "            s_from = ensure_state(ctx, buf)\n",
    "\n",
    "            st_base = self.ngram_model.context2state.get(ctx, None)\n",
    "            base_is_final = (st_base in base_final) if st_base else False\n",
    "\n",
    "            # If base is final => leftover flush => ephemeral chain => final\n",
    "            if base_is_final:\n",
    "                leftover_list = list(buf)\n",
    "                pblock = self.perturbation_fnc(leftover_list)\n",
    "                self._emit_symbol_chain(s_from, pblock, q_final, EOSweight=Real.one)\n",
    "                continue\n",
    "\n",
    "            # If buffer<k => read from base arcs\n",
    "            if len(buf)<self.k:\n",
    "                A = arcs_for_ctx(ctx)\n",
    "                for (a,j,w) in A:\n",
    "                    if a==EOS:\n",
    "                        # partial leftover flush\n",
    "                        leftover_list = list(buf)\n",
    "                        pblock = self.perturbation_fnc(leftover_list)\n",
    "                        self._emit_symbol_chain(s_from, pblock, q_final, symbol=a, weight=w)\n",
    "                    else:\n",
    "                        symbol = str(a)\n",
    "                        new_ctx = inv_map.get(j,None)\n",
    "                        if new_ctx is None:\n",
    "                            continue\n",
    "                        new_buf = tuple(list(buf)+[symbol])\n",
    "                        if (new_ctx,new_buf) not in visited:\n",
    "                            visited.add((new_ctx,new_buf))\n",
    "                            queue.append((new_ctx,new_buf))\n",
    "                        s_to = ensure_state(new_ctx, new_buf)\n",
    "                        self.fsa.set_arc(s_from, ε, s_to, w)\n",
    "                continue\n",
    "\n",
    "            # else => buffer==k => full block flush\n",
    "            if len(buf)==self.k:\n",
    "                pblock = self.perturbation_fnc(list(buf))\n",
    "                # ephemeral chain => next BFS-labeled state = (ctx,())\n",
    "                next_state = ensure_state(ctx, ())\n",
    "                if (ctx,()) not in visited:\n",
    "                    visited.add((ctx,()))\n",
    "                    queue.append((ctx,()))\n",
    "                self._emit_symbol_chain(s_from, pblock, next_state, EOSweight=Real.one, eplabel=ε)\n",
    "                continue\n",
    "\n",
    "    def _emit_symbol_chain(self, s_from:State, syms:List[str], final_st:State,\n",
    "                           symbol: Sym = None, weight=None, EOSweight=None, eplabel=ε):\n",
    "        \"\"\"\n",
    "        Creates ephemeral chain from s_from for each symbol in 'syms' (one symbol per transition).\n",
    "        Then from the last ephemeral state => final_st with either the 'symbol' (like <EOS>) or eplabel.\n",
    "        'weight' is used for that final transition if provided, else Real.one.\n",
    "        'EOSweight' is used for ephemeral transitions if not provided, default Real.one\n",
    "        'eplabel' for the final transition if no symbol is left.\n",
    "\n",
    "        This ensures single symbol per transition PFSA for the flush.\n",
    "        \"\"\"\n",
    "        if EOSweight is None:\n",
    "            EOSweight = self.R.one\n",
    "        curr_st = s_from\n",
    "        # for each symbol => ephemeral state\n",
    "        for i, sym in enumerate(syms):\n",
    "            e_name = f\"EMIT_{s_from}_{i}_{sym}\"\n",
    "            e_st = State(e_name)\n",
    "            self.fsa.add_state(e_st)\n",
    "            # connect curr_st -sym-> e_st\n",
    "            self.fsa.set_arc(curr_st, Sym(sym), e_st, EOSweight)\n",
    "            curr_st = e_st\n",
    "\n",
    "        # now from curr_st => final_st\n",
    "        # if we have an actual 'symbol' to emit (like <EOS>):\n",
    "        if symbol is not None:\n",
    "            self.fsa.set_arc(curr_st, symbol, final_st, weight if weight else self.R.one)\n",
    "        else:\n",
    "            # else we do eplabel => final\n",
    "            self.fsa.set_arc(curr_st, eplabel, final_st, weight if weight else self.R.one)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Usage\n",
    "###############################################################################\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    user_alphabet = ['a','b']\n",
    "    rng_model = RandomNGramModel(alphabet=user_alphabet, n=3, alpha=0.4)\n",
    "    print(\"Base n-gram FSA states:\", rng_model.fsa.num_states)\n",
    "\n",
    "    # left rotate\n",
    "    def left_rotate(lst):\n",
    "        if len(lst) == 0:\n",
    "            return lst\n",
    "        return lst[1:] + [lst[0]]\n",
    "\n",
    "    kmodel = KShuffleNgram(rng_model, k=3, perturbation_fnc=left_rotate)\n",
    "    print(\"K-shuffle FSA states:\", kmodel.fsa.num_states)\n",
    "\n",
    "    print(\"Base n-gram FSA entropy:\", rng_model.fsa.entropy())\n",
    "    print(\"K-shuffle FSA entropy:\", kmodel.fsa.entropy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "       <script>\n",
       "       try {\n",
       "       require.config({\n",
       "       paths: {\n",
       "       \"d3\": \"https://cdnjs.cloudflare.com/ajax/libs/d3/4.13.0/d3\",\n",
       "       \"dagreD3\": \"https://cdnjs.cloudflare.com/ajax/libs/dagre-d3/0.6.1/dagre-d3.min\"\n",
       "       }\n",
       "       });\n",
       "       } catch {\n",
       "       [\"https://cdnjs.cloudflare.com/ajax/libs/d3/4.13.0/d3.js\",\n",
       "       \"https://cdnjs.cloudflare.com/ajax/libs/dagre-d3/0.6.1/dagre-d3.min.js\"].forEach(\n",
       "            function (src) {\n",
       "            var tag = document.createElement('script');\n",
       "            tag.src = src;\n",
       "            document.body.appendChild(tag);\n",
       "            }\n",
       "        )\n",
       "        }\n",
       "        try {\n",
       "        requirejs(['d3', 'dagreD3'], function() {});\n",
       "        } catch (e) {}\n",
       "        try {\n",
       "        require(['d3', 'dagreD3'], function() {});\n",
       "        } catch (e) {}\n",
       "        </script>\n",
       "        <style>\n",
       "        .node rect,\n",
       "        .node circle,\n",
       "        .node ellipse {\n",
       "        stroke: #333;\n",
       "        fill: #fff;\n",
       "        stroke-width: 1px;\n",
       "        }\n",
       "\n",
       "        .edgePath path {\n",
       "        stroke: #333;\n",
       "        fill: #333;\n",
       "        stroke-width: 1.5px;\n",
       "        }\n",
       "        </style>\n",
       "        <center><svg width=\"850\" height=\"600\" id=\"fst_dda21bfe0da94bffa81047218b565a97\"><g/></svg></center>\n",
       "        <script>\n",
       "        (function render_d3() {\n",
       "        var d3, dagreD3;\n",
       "        try { // requirejs is broken on external domains\n",
       "          d3 = require('d3');\n",
       "          dagreD3 = require('dagreD3');\n",
       "        } catch (e) {\n",
       "          // for google colab\n",
       "          if(typeof window.d3 !== \"undefined\" && typeof window.dagreD3 !== \"undefined\"){\n",
       "            d3 = window.d3;\n",
       "            dagreD3 = window.dagreD3;\n",
       "          } else { // not loaded yet, so wait and try again\n",
       "            setTimeout(render_d3, 50);\n",
       "            return;\n",
       "          }\n",
       "        }\n",
       "        //alert(\"loaded\");\n",
       "        var g = new dagreD3.graphlib.Graph().setGraph({ 'rankdir': 'LR' });\n",
       "        g.setNode(\"('BOS', 'BOS')|()\", { label: \"('BOS', 'BOS')|() / 1.000\" , shape: \"circle\" });\n",
       "g.node(\"('BOS', 'BOS')|()\").style = \"fill: #66c2a5\"; \n",
       "g.setNode(\"('b', 'a')|('b', 'a')\",{label:\"('b', 'a')|('b', 'a')\",shape:\"circle\"});\n",
       "g.node(\"('b', 'a')|('b', 'a')\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"('a', 'a')|('a', 'a')\",{label:\"('a', 'a')|('a', 'a')\",shape:\"circle\"});\n",
       "g.node(\"('a', 'a')|('a', 'a')\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('b', 'b')|('b', 'b')_1_b\",{label:\"EMIT_('b', 'b')|('b', 'b')_1_b\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('b', 'b')|('b', 'b')_1_b\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('b', 'b')|('a', 'b', 'b')_1_b\",{label:\"EMIT_('b', 'b')|('a', 'b', 'b')_1_b\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('b', 'b')|('a', 'b', 'b')_1_b\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('b', 'a')|('b', 'a')_1_b\",{label:\"EMIT_('b', 'a')|('b', 'a')_1_b\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('b', 'a')|('b', 'a')_1_b\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"('b', 'b')|()\",{label:\"('b', 'b')|()\",shape:\"circle\"});\n",
       "g.node(\"('b', 'b')|()\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('b', 'a')|('b', 'a')_0_a\",{label:\"EMIT_('b', 'a')|('b', 'a')_0_a\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('b', 'a')|('b', 'a')_0_a\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"('a', 'a')|('a',)\",{label:\"('a', 'a')|('a',)\",shape:\"circle\"});\n",
       "g.node(\"('a', 'a')|('a',)\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('a', 'b')|('a', 'a', 'b')_1_b\",{label:\"EMIT_('a', 'b')|('a', 'a', 'b')_1_b\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('a', 'b')|('a', 'a', 'b')_1_b\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('a', 'b')|('a', 'a', 'b')_0_a\",{label:\"EMIT_('a', 'b')|('a', 'a', 'b')_0_a\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('a', 'b')|('a', 'a', 'b')_0_a\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('b', 'b')|('b', 'b')_0_b\",{label:\"EMIT_('b', 'b')|('b', 'b')_0_b\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('b', 'b')|('b', 'b')_0_b\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('a', 'a')|('a', 'a', 'a')_1_a\",{label:\"EMIT_('a', 'a')|('a', 'a', 'a')_1_a\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('a', 'a')|('a', 'a', 'a')_1_a\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('b', 'a')|('b', 'b', 'a')_0_b\",{label:\"EMIT_('b', 'a')|('b', 'b', 'a')_0_b\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('b', 'a')|('b', 'b', 'a')_0_b\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('a', 'a')|('a', 'a')_1_a\",{label:\"EMIT_('a', 'a')|('a', 'a')_1_a\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('a', 'a')|('a', 'a')_1_a\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('BOS', 'b')|('b',)_0_b\",{label:\"EMIT_('BOS', 'b')|('b',)_0_b\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('BOS', 'b')|('b',)_0_b\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"('a', 'b')|('a', 'a', 'b')\",{label:\"('a', 'b')|('a', 'a', 'b')\",shape:\"circle\"});\n",
       "g.node(\"('a', 'b')|('a', 'a', 'b')\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"('b', 'a')|('a', 'b', 'a')\",{label:\"('b', 'a')|('a', 'b', 'a')\",shape:\"circle\"});\n",
       "g.node(\"('b', 'a')|('a', 'b', 'a')\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"('b', 'a')|('b', 'b', 'a')\",{label:\"('b', 'a')|('b', 'b', 'a')\",shape:\"circle\"});\n",
       "g.node(\"('b', 'a')|('b', 'b', 'a')\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('b', 'a')|('a', 'b', 'a')_0_b\",{label:\"EMIT_('b', 'a')|('a', 'b', 'a')_0_b\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('b', 'a')|('a', 'b', 'a')_0_b\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('a', 'b')|('b', 'a', 'b')_0_a\",{label:\"EMIT_('a', 'b')|('b', 'a', 'b')_0_a\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('a', 'b')|('b', 'a', 'b')_0_a\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"('a', 'a')|('b', 'a', 'a')\",{label:\"('a', 'a')|('b', 'a', 'a')\",shape:\"circle\"});\n",
       "g.node(\"('a', 'a')|('b', 'a', 'a')\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('a', 'a')|('b', 'a', 'a')_2_b\",{label:\"EMIT_('a', 'a')|('b', 'a', 'a')_2_b\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('a', 'a')|('b', 'a', 'a')_2_b\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"('b', 'a')|('a',)\",{label:\"('b', 'a')|('a',)\",shape:\"circle\"});\n",
       "g.node(\"('b', 'a')|('a',)\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('a', 'b')|('b',)_0_b\",{label:\"EMIT_('a', 'b')|('b',)_0_b\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('a', 'b')|('b',)_0_b\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('b', 'a')|('a', 'b', 'a')_2_a\",{label:\"EMIT_('b', 'a')|('a', 'b', 'a')_2_a\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('b', 'a')|('a', 'b', 'a')_2_a\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('a', 'b')|('a', 'a', 'b')_2_a\",{label:\"EMIT_('a', 'b')|('a', 'a', 'b')_2_a\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('a', 'b')|('a', 'a', 'b')_2_a\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('b', 'a')|('b', 'b', 'a')_1_a\",{label:\"EMIT_('b', 'a')|('b', 'b', 'a')_1_a\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('b', 'a')|('b', 'b', 'a')_1_a\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('b', 'a')|('b', 'b', 'a')_2_b\",{label:\"EMIT_('b', 'a')|('b', 'b', 'a')_2_b\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('b', 'a')|('b', 'b', 'a')_2_b\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('b', 'b')|('a', 'b', 'b')_0_b\",{label:\"EMIT_('b', 'b')|('a', 'b', 'b')_0_b\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('b', 'b')|('a', 'b', 'b')_0_b\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('a', 'b')|('b', 'a', 'b')_2_b\",{label:\"EMIT_('a', 'b')|('b', 'a', 'b')_2_b\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('a', 'b')|('b', 'a', 'b')_2_b\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"('a', 'a')|('a', 'a', 'a')\",{label:\"('a', 'a')|('a', 'a', 'a')\",shape:\"circle\"});\n",
       "g.node(\"('a', 'a')|('a', 'a', 'a')\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('b', 'b')|('b', 'b', 'b')_1_b\",{label:\"EMIT_('b', 'b')|('b', 'b', 'b')_1_b\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('b', 'b')|('b', 'b', 'b')_1_b\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('BOS', 'a')|('a',)_0_a\",{label:\"EMIT_('BOS', 'a')|('a',)_0_a\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('BOS', 'a')|('a',)_0_a\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('b', 'b')|('a', 'b', 'b')_2_a\",{label:\"EMIT_('b', 'b')|('a', 'b', 'b')_2_a\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('b', 'b')|('a', 'b', 'b')_2_a\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"('a', 'a')|()\",{label:\"('a', 'a')|()\",shape:\"circle\"});\n",
       "g.node(\"('a', 'a')|()\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('a', 'b')|('a', 'b')_1_a\",{label:\"EMIT_('a', 'b')|('a', 'b')_1_a\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('a', 'b')|('a', 'b')_1_a\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"('a', 'b')|('a', 'b')\",{label:\"('a', 'b')|('a', 'b')\",shape:\"circle\"});\n",
       "g.node(\"('a', 'b')|('a', 'b')\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"('b', 'a')|()\",{label:\"('b', 'a')|()\",shape:\"circle\"});\n",
       "g.node(\"('b', 'a')|()\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"('BOS', 'a')|('a',)\",{label:\"('BOS', 'a')|('a',)\",shape:\"circle\"});\n",
       "g.node(\"('BOS', 'a')|('a',)\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('b', 'b')|('b', 'b', 'b')_2_b\",{label:\"EMIT_('b', 'b')|('b', 'b', 'b')_2_b\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('b', 'b')|('b', 'b', 'b')_2_b\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('a', 'a')|('a', 'a', 'a')_0_a\",{label:\"EMIT_('a', 'a')|('a', 'a', 'a')_0_a\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('a', 'a')|('a', 'a', 'a')_0_a\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('a', 'a')|('b', 'a', 'a')_0_a\",{label:\"EMIT_('a', 'a')|('b', 'a', 'a')_0_a\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('a', 'a')|('b', 'a', 'a')_0_a\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('a', 'b')|('a', 'b')_0_b\",{label:\"EMIT_('a', 'b')|('a', 'b')_0_b\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('a', 'b')|('a', 'b')_0_b\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('a', 'b')|('b', 'a', 'b')_1_b\",{label:\"EMIT_('a', 'b')|('b', 'a', 'b')_1_b\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('a', 'b')|('b', 'a', 'b')_1_b\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"('a', 'b')|()\",{label:\"('a', 'b')|()\",shape:\"circle\"});\n",
       "g.node(\"('a', 'b')|()\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"('a', 'b')|('b',)\",{label:\"('a', 'b')|('b',)\",shape:\"circle\"});\n",
       "g.node(\"('a', 'b')|('b',)\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"('b', 'b')|('b',)\",{label:\"('b', 'b')|('b',)\",shape:\"circle\"});\n",
       "g.node(\"('b', 'b')|('b',)\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('b', 'b')|('b',)_0_b\",{label:\"EMIT_('b', 'b')|('b',)_0_b\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('b', 'b')|('b',)_0_b\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('b', 'a')|('a',)_0_a\",{label:\"EMIT_('b', 'a')|('a',)_0_a\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('b', 'a')|('a',)_0_a\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"('BOS', 'b')|('b',)\",{label:\"('BOS', 'b')|('b',)\",shape:\"circle\"});\n",
       "g.node(\"('BOS', 'b')|('b',)\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('a', 'a')|('a', 'a', 'a')_2_a\",{label:\"EMIT_('a', 'a')|('a', 'a', 'a')_2_a\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('a', 'a')|('a', 'a', 'a')_2_a\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('b', 'b')|('b', 'b', 'b')_0_b\",{label:\"EMIT_('b', 'b')|('b', 'b', 'b')_0_b\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('b', 'b')|('b', 'b', 'b')_0_b\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"('b', 'b')|('a', 'b', 'b')\",{label:\"('b', 'b')|('a', 'b', 'b')\",shape:\"circle\"});\n",
       "g.node(\"('b', 'b')|('a', 'b', 'b')\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('a', 'a')|('a',)_0_a\",{label:\"EMIT_('a', 'a')|('a',)_0_a\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('a', 'a')|('a',)_0_a\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"('b', 'b')|('b', 'b', 'b')\",{label:\"('b', 'b')|('b', 'b', 'b')\",shape:\"circle\"});\n",
       "g.node(\"('b', 'b')|('b', 'b', 'b')\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('a', 'a')|('a', 'a')_0_a\",{label:\"EMIT_('a', 'a')|('a', 'a')_0_a\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('a', 'a')|('a', 'a')_0_a\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('b', 'a')|('a', 'b', 'a')_1_a\",{label:\"EMIT_('b', 'a')|('a', 'b', 'a')_1_a\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('b', 'a')|('a', 'b', 'a')_1_a\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"EMIT_('a', 'a')|('b', 'a', 'a')_1_a\",{label:\"EMIT_('a', 'a')|('b', 'a', 'a')_1_a\",shape:\"circle\"});\n",
       "g.node(\"EMIT_('a', 'a')|('b', 'a', 'a')_1_a\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"('b', 'b')|('b', 'b')\",{label:\"('b', 'b')|('b', 'b')\",shape:\"circle\"});\n",
       "g.node(\"('b', 'b')|('b', 'b')\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"('a', 'b')|('b', 'a', 'b')\",{label:\"('a', 'b')|('b', 'a', 'b')\",shape:\"circle\"});\n",
       "g.node(\"('a', 'b')|('b', 'a', 'b')\").style = \"fill: #8da0cb\"; \n",
       "g.setNode(\"<KSHUFFLE_FINAL>\",{label:\"<KSHUFFLE_FINAL> / 1.000\",shape:\"circle\"});\n",
       "g.node(\"<KSHUFFLE_FINAL>\").style = \"fill: #fc8d62\"; \n",
       "g.setEdge(\"('b', 'a')|('b', 'a')\",\"('a', 'a')|('b', 'a', 'a')\",{arrowhead:\"vee\",label:\"\\u03b5 / 0.993\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('b', 'a')|('b', 'a')\",\"('a', 'b')|('b', 'a', 'b')\",{arrowhead:\"vee\",label:\"\\u03b5 / 0.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('b', 'a')|('b', 'a')\",\"EMIT_('b', 'a')|('b', 'a')_0_a\",{arrowhead:\"vee\",label:\"a / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('a', 'a')|('a', 'a')\",\"('a', 'a')|('a', 'a', 'a')\",{arrowhead:\"vee\",label:\"\\u03b5 / 0.869\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('a', 'a')|('a', 'a')\",\"('a', 'b')|('a', 'a', 'b')\",{arrowhead:\"vee\",label:\"\\u03b5 / 0.096\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('a', 'a')|('a', 'a')\",\"EMIT_('a', 'a')|('a', 'a')_0_a\",{arrowhead:\"vee\",label:\"a / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('b', 'b')|('b', 'b')_1_b\",\"<KSHUFFLE_FINAL>\",{arrowhead:\"vee\",label:\"EOS / 0.468\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('b', 'b')|('a', 'b', 'b')_1_b\",\"EMIT_('b', 'b')|('a', 'b', 'b')_2_a\",{arrowhead:\"vee\",label:\"a / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('b', 'a')|('b', 'a')_1_b\",\"<KSHUFFLE_FINAL>\",{arrowhead:\"vee\",label:\"EOS / 0.007\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('b', 'b')|()\",\"('b', 'a')|('a',)\",{arrowhead:\"vee\",label:\"\\u03b5 / 0.435\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('b', 'b')|()\",\"('b', 'b')|('b',)\",{arrowhead:\"vee\",label:\"\\u03b5 / 0.097\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('b', 'b')|()\",\"<KSHUFFLE_FINAL>\",{arrowhead:\"vee\",label:\"EOS / 0.468\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('b', 'a')|('b', 'a')_0_a\",\"EMIT_('b', 'a')|('b', 'a')_1_b\",{arrowhead:\"vee\",label:\"b / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('a', 'a')|('a',)\",\"('a', 'a')|('a', 'a')\",{arrowhead:\"vee\",label:\"\\u03b5 / 0.869\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('a', 'a')|('a',)\",\"('a', 'b')|('a', 'b')\",{arrowhead:\"vee\",label:\"\\u03b5 / 0.096\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('a', 'a')|('a',)\",\"EMIT_('a', 'a')|('a',)_0_a\",{arrowhead:\"vee\",label:\"a / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('a', 'b')|('a', 'a', 'b')_1_b\",\"EMIT_('a', 'b')|('a', 'a', 'b')_2_a\",{arrowhead:\"vee\",label:\"a / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('a', 'b')|('a', 'a', 'b')_0_a\",\"EMIT_('a', 'b')|('a', 'a', 'b')_1_b\",{arrowhead:\"vee\",label:\"b / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('b', 'b')|('b', 'b')_0_b\",\"EMIT_('b', 'b')|('b', 'b')_1_b\",{arrowhead:\"vee\",label:\"b / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('a', 'a')|('a', 'a', 'a')_1_a\",\"EMIT_('a', 'a')|('a', 'a', 'a')_2_a\",{arrowhead:\"vee\",label:\"a / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('b', 'a')|('b', 'b', 'a')_0_b\",\"EMIT_('b', 'a')|('b', 'b', 'a')_1_a\",{arrowhead:\"vee\",label:\"a / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('a', 'a')|('a', 'a')_1_a\",\"<KSHUFFLE_FINAL>\",{arrowhead:\"vee\",label:\"EOS / 0.035\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('BOS', 'b')|('b',)_0_b\",\"<KSHUFFLE_FINAL>\",{arrowhead:\"vee\",label:\"EOS / 0.485\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('a', 'b')|('a', 'a', 'b')\",\"EMIT_('a', 'b')|('a', 'a', 'b')_0_a\",{arrowhead:\"vee\",label:\"a / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('b', 'a')|('a', 'b', 'a')\",\"EMIT_('b', 'a')|('a', 'b', 'a')_0_b\",{arrowhead:\"vee\",label:\"b / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('b', 'a')|('b', 'b', 'a')\",\"EMIT_('b', 'a')|('b', 'b', 'a')_0_b\",{arrowhead:\"vee\",label:\"b / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('b', 'a')|('a', 'b', 'a')_0_b\",\"EMIT_('b', 'a')|('a', 'b', 'a')_1_a\",{arrowhead:\"vee\",label:\"a / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('a', 'b')|('b', 'a', 'b')_0_a\",\"EMIT_('a', 'b')|('b', 'a', 'b')_1_b\",{arrowhead:\"vee\",label:\"b / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('a', 'a')|('b', 'a', 'a')\",\"EMIT_('a', 'a')|('b', 'a', 'a')_0_a\",{arrowhead:\"vee\",label:\"a / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('a', 'a')|('b', 'a', 'a')_2_b\",\"('a', 'a')|()\",{arrowhead:\"vee\",label:\"\\u03b5 / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('b', 'a')|('a',)\",\"('a', 'a')|('a', 'a')\",{arrowhead:\"vee\",label:\"\\u03b5 / 0.993\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('b', 'a')|('a',)\",\"('a', 'b')|('a', 'b')\",{arrowhead:\"vee\",label:\"\\u03b5 / 0.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('b', 'a')|('a',)\",\"EMIT_('b', 'a')|('a',)_0_a\",{arrowhead:\"vee\",label:\"a / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('a', 'b')|('b',)_0_b\",\"<KSHUFFLE_FINAL>\",{arrowhead:\"vee\",label:\"EOS / 0.957\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('b', 'a')|('a', 'b', 'a')_2_a\",\"('b', 'a')|()\",{arrowhead:\"vee\",label:\"\\u03b5 / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('a', 'b')|('a', 'a', 'b')_2_a\",\"('a', 'b')|()\",{arrowhead:\"vee\",label:\"\\u03b5 / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('b', 'a')|('b', 'b', 'a')_1_a\",\"EMIT_('b', 'a')|('b', 'b', 'a')_2_b\",{arrowhead:\"vee\",label:\"b / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('b', 'a')|('b', 'b', 'a')_2_b\",\"('b', 'a')|()\",{arrowhead:\"vee\",label:\"\\u03b5 / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('b', 'b')|('a', 'b', 'b')_0_b\",\"EMIT_('b', 'b')|('a', 'b', 'b')_1_b\",{arrowhead:\"vee\",label:\"b / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('a', 'b')|('b', 'a', 'b')_2_b\",\"('a', 'b')|()\",{arrowhead:\"vee\",label:\"\\u03b5 / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('a', 'a')|('a', 'a', 'a')\",\"EMIT_('a', 'a')|('a', 'a', 'a')_0_a\",{arrowhead:\"vee\",label:\"a / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('b', 'b')|('b', 'b', 'b')_1_b\",\"EMIT_('b', 'b')|('b', 'b', 'b')_2_b\",{arrowhead:\"vee\",label:\"b / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('BOS', 'a')|('a',)_0_a\",\"<KSHUFFLE_FINAL>\",{arrowhead:\"vee\",label:\"EOS / 0.350\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('b', 'b')|('a', 'b', 'b')_2_a\",\"('b', 'b')|()\",{arrowhead:\"vee\",label:\"\\u03b5 / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('a', 'a')|()\",\"('a', 'a')|('a',)\",{arrowhead:\"vee\",label:\"\\u03b5 / 0.869\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('a', 'a')|()\",\"('a', 'b')|('b',)\",{arrowhead:\"vee\",label:\"\\u03b5 / 0.096\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('a', 'a')|()\",\"<KSHUFFLE_FINAL>\",{arrowhead:\"vee\",label:\"EOS / 0.035\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('a', 'b')|('a', 'b')_1_a\",\"<KSHUFFLE_FINAL>\",{arrowhead:\"vee\",label:\"EOS / 0.957\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('a', 'b')|('a', 'b')\",\"('b', 'a')|('a', 'b', 'a')\",{arrowhead:\"vee\",label:\"\\u03b5 / 0.025\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('a', 'b')|('a', 'b')\",\"('b', 'b')|('a', 'b', 'b')\",{arrowhead:\"vee\",label:\"\\u03b5 / 0.018\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('a', 'b')|('a', 'b')\",\"EMIT_('a', 'b')|('a', 'b')_0_b\",{arrowhead:\"vee\",label:\"b / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('b', 'a')|()\",\"('a', 'a')|('a',)\",{arrowhead:\"vee\",label:\"\\u03b5 / 0.993\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('b', 'a')|()\",\"('a', 'b')|('b',)\",{arrowhead:\"vee\",label:\"\\u03b5 / 0.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('b', 'a')|()\",\"<KSHUFFLE_FINAL>\",{arrowhead:\"vee\",label:\"EOS / 0.007\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('BOS', 'a')|('a',)\",\"('a', 'a')|('a', 'a')\",{arrowhead:\"vee\",label:\"\\u03b5 / 0.603\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('BOS', 'a')|('a',)\",\"('a', 'b')|('a', 'b')\",{arrowhead:\"vee\",label:\"\\u03b5 / 0.047\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('BOS', 'a')|('a',)\",\"EMIT_('BOS', 'a')|('a',)_0_a\",{arrowhead:\"vee\",label:\"a / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('b', 'b')|('b', 'b', 'b')_2_b\",\"('b', 'b')|()\",{arrowhead:\"vee\",label:\"\\u03b5 / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('BOS', 'BOS')|()\",\"('BOS', 'a')|('a',)\",{arrowhead:\"vee\",label:\"\\u03b5 / 0.659\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('BOS', 'BOS')|()\",\"('BOS', 'b')|('b',)\",{arrowhead:\"vee\",label:\"\\u03b5 / 0.258\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('BOS', 'BOS')|()\",\"<KSHUFFLE_FINAL>\",{arrowhead:\"vee\",label:\"EOS / 0.083\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('a', 'a')|('a', 'a', 'a')_0_a\",\"EMIT_('a', 'a')|('a', 'a', 'a')_1_a\",{arrowhead:\"vee\",label:\"a / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('a', 'a')|('b', 'a', 'a')_0_a\",\"EMIT_('a', 'a')|('b', 'a', 'a')_1_a\",{arrowhead:\"vee\",label:\"a / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('a', 'b')|('a', 'b')_0_b\",\"EMIT_('a', 'b')|('a', 'b')_1_a\",{arrowhead:\"vee\",label:\"a / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('a', 'b')|('b', 'a', 'b')_1_b\",\"EMIT_('a', 'b')|('b', 'a', 'b')_2_b\",{arrowhead:\"vee\",label:\"b / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('a', 'b')|()\",\"('b', 'a')|('a',)\",{arrowhead:\"vee\",label:\"\\u03b5 / 0.025\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('a', 'b')|()\",\"('b', 'b')|('b',)\",{arrowhead:\"vee\",label:\"\\u03b5 / 0.018\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('a', 'b')|()\",\"<KSHUFFLE_FINAL>\",{arrowhead:\"vee\",label:\"EOS / 0.957\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('a', 'b')|('b',)\",\"('b', 'a')|('b', 'a')\",{arrowhead:\"vee\",label:\"\\u03b5 / 0.025\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('a', 'b')|('b',)\",\"('b', 'b')|('b', 'b')\",{arrowhead:\"vee\",label:\"\\u03b5 / 0.018\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('a', 'b')|('b',)\",\"EMIT_('a', 'b')|('b',)_0_b\",{arrowhead:\"vee\",label:\"b / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('b', 'b')|('b',)\",\"('b', 'a')|('b', 'a')\",{arrowhead:\"vee\",label:\"\\u03b5 / 0.435\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('b', 'b')|('b',)\",\"('b', 'b')|('b', 'b')\",{arrowhead:\"vee\",label:\"\\u03b5 / 0.097\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('b', 'b')|('b',)\",\"EMIT_('b', 'b')|('b',)_0_b\",{arrowhead:\"vee\",label:\"b / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('b', 'b')|('b',)_0_b\",\"<KSHUFFLE_FINAL>\",{arrowhead:\"vee\",label:\"EOS / 0.468\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('b', 'a')|('a',)_0_a\",\"<KSHUFFLE_FINAL>\",{arrowhead:\"vee\",label:\"EOS / 0.007\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('BOS', 'b')|('b',)\",\"('b', 'a')|('b', 'a')\",{arrowhead:\"vee\",label:\"\\u03b5 / 0.044\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('BOS', 'b')|('b',)\",\"('b', 'b')|('b', 'b')\",{arrowhead:\"vee\",label:\"\\u03b5 / 0.471\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('BOS', 'b')|('b',)\",\"EMIT_('BOS', 'b')|('b',)_0_b\",{arrowhead:\"vee\",label:\"b / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('a', 'a')|('a', 'a', 'a')_2_a\",\"('a', 'a')|()\",{arrowhead:\"vee\",label:\"\\u03b5 / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('b', 'b')|('b', 'b', 'b')_0_b\",\"EMIT_('b', 'b')|('b', 'b', 'b')_1_b\",{arrowhead:\"vee\",label:\"b / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('b', 'b')|('a', 'b', 'b')\",\"EMIT_('b', 'b')|('a', 'b', 'b')_0_b\",{arrowhead:\"vee\",label:\"b / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('a', 'a')|('a',)_0_a\",\"<KSHUFFLE_FINAL>\",{arrowhead:\"vee\",label:\"EOS / 0.035\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('b', 'b')|('b', 'b', 'b')\",\"EMIT_('b', 'b')|('b', 'b', 'b')_0_b\",{arrowhead:\"vee\",label:\"b / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('a', 'a')|('a', 'a')_0_a\",\"EMIT_('a', 'a')|('a', 'a')_1_a\",{arrowhead:\"vee\",label:\"a / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('b', 'a')|('a', 'b', 'a')_1_a\",\"EMIT_('b', 'a')|('a', 'b', 'a')_2_a\",{arrowhead:\"vee\",label:\"a / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"EMIT_('a', 'a')|('b', 'a', 'a')_1_a\",\"EMIT_('a', 'a')|('b', 'a', 'a')_2_b\",{arrowhead:\"vee\",label:\"b / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('b', 'b')|('b', 'b')\",\"('b', 'a')|('b', 'b', 'a')\",{arrowhead:\"vee\",label:\"\\u03b5 / 0.435\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('b', 'b')|('b', 'b')\",\"('b', 'b')|('b', 'b', 'b')\",{arrowhead:\"vee\",label:\"\\u03b5 / 0.097\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('b', 'b')|('b', 'b')\",\"EMIT_('b', 'b')|('b', 'b')_0_b\",{arrowhead:\"vee\",label:\"b / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "g.setEdge(\"('a', 'b')|('b', 'a', 'b')\",\"EMIT_('a', 'b')|('b', 'a', 'b')_0_a\",{arrowhead:\"vee\",label:\"a / 1.000\",\"style\": \"stroke: rgb(192, 192, 192); fill: none;\", \"labelStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192); \", \"arrowheadStyle\": \"fill: rgb(192, 192, 192); stroke: rgb(192, 192, 192);\"});\n",
       "var svg = d3.select(\"#fst_dda21bfe0da94bffa81047218b565a97\"); \n",
       "\n",
       "        var inner = svg.select(\"g\");\n",
       "\n",
       "        // Set up zoom support\n",
       "        var zoom = d3.zoom().scaleExtent([0.3, 5]).on(\"zoom\", function() {\n",
       "        inner.attr(\"transform\", d3.event.transform);\n",
       "        });\n",
       "        svg.call(zoom);\n",
       "\n",
       "        // Create the renderer\n",
       "        var render = new dagreD3.render();\n",
       "\n",
       "        // Run the renderer. This is what draws the final graph.\n",
       "        render(inner, g);\n",
       "\n",
       "        // Center the graph\n",
       "        var initialScale = 0.75;\n",
       "        svg.call(zoom.transform, d3.zoomIdentity.translate(\n",
       "            (svg.attr(\"width\")-g.graph().width*initialScale)/2,20).scale(initialScale));\n",
       "\n",
       "        svg.attr('height', g.graph().height * initialScale + 50);\n",
       "        })();\n",
       "\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "WFSA(62 states, <class 'rayuela.base.semiring.Real'>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmodel.fsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-EPS states (base): 8\n",
      "Non-EPS states (kshuffle): 62\n",
      "Base n-gram FSA entropy: 34.45959\n",
      "K-shuffle FSA entropy: 157.56298\n"
     ]
    }
   ],
   "source": [
    "from rayuela.fsa.transformer import Transformer\n",
    "\n",
    "rng_model_non_eps = rng_model.fsa.push().epsremove().normalize()\n",
    "kshuffle_model_non_eps = kmodel.fsa.push().epsremove()\n",
    "print(\"Non-EPS states (base):\", rng_model_non_eps.num_states)\n",
    "print(\"Non-EPS states (kshuffle):\", kshuffle_model_non_eps.num_states)\n",
    "print(\"Base n-gram FSA entropy:\", rng_model_non_eps.entropy())\n",
    "print(\"K-shuffle FSA entropy:\", kshuffle_model_non_eps.entropy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.45959"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmodel.fsa.push().entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157.56298"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmodel.fsa.push().epsremove().entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(fsa, partition_symbol: Sym = ε) -> Tuple[FSA, FSA]:\n",
    "    \"\"\"Partition FSA into two\n",
    "    (one with arcs of the partition symbol and one with all others)\n",
    "\n",
    "    Args:\n",
    "        fsa (FSA): The input FSA\n",
    "        partition_symbol (Sym, optional): The symbol based on which to\n",
    "        partition the input FSA\n",
    "\n",
    "    Returns:\n",
    "        Tuple[FSA, FSA]: The FSA with non-partition symbol arcs\n",
    "                            and the FSA with only the partition symbol arcs\n",
    "    \"\"\"\n",
    "\n",
    "    E = fsa.spawn()\n",
    "    N = fsa.spawn(keep_init=True, keep_final=True)\n",
    "\n",
    "    for q in fsa.Q:\n",
    "        E.add_state(q)\n",
    "        N.add_state(q)\n",
    "\n",
    "    for i in fsa.Q:\n",
    "        for a, j, w in fsa.arcs(i):\n",
    "            if a == partition_symbol:\n",
    "                E.add_arc(i, a, j, w)\n",
    "            else:\n",
    "                N.add_arc(i, a, j, w)\n",
    "\n",
    "    return N, E\n",
    "\n",
    "@staticmethod\n",
    "def epsremoval(fsa):\n",
    "    # note that N keeps same initial and final weights\n",
    "    N, E = Transformer.partition(fsa)\n",
    "    W = Pathsum(E).lehmann(zero=False)\n",
    "\n",
    "    for i in fsa.Q:\n",
    "        for a, j, w in fsa.arcs(i, no_eps=True):\n",
    "            print(a)\n",
    "            for k in fsa.Q:\n",
    "                N.add_arc(i, a, k, w * W[j, k])\n",
    "\n",
    "    # additional initial states\n",
    "    for i, j in product(fsa.Q, repeat=2):\n",
    "        N.add_I(j, fsa.λ[i] * W[i, j])\n",
    "\n",
    "    return N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsa = kmodel.fsa\n",
    "E = fsa.spawn()\n",
    "N = fsa.spawn(keep_init=True, keep_final=True)\n",
    "\n",
    "for q in fsa.Q:\n",
    "    E.add_state(q)\n",
    "    N.add_state(q)\n",
    "\n",
    "for i in fsa.Q:\n",
    "    for a, j, w in fsa.arcs(i):\n",
    "        if a == ε:\n",
    "            E.add_arc(i, a, j, w)\n",
    "        else:\n",
    "            N.add_arc(i, a, j, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157.56298"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kshuffle_model_non_eps = kshuffle_model_non_eps.epsremove()\n",
    "kshuffle_model_non_eps.entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/agiats/Projects/impossible_inherent_entropy/.venv/src/rayuela/rayuela/base/semiring.py:694: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return Real(1.0 / self.value)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64.38882"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kshuffle_model_non_eps = kshuffle_model_non_eps.normalize()\n",
    "kshuffle_model_non_eps.entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.38882"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kshuffle_model_non_eps.entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 566.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'aa', 'ccba', 'cacbba', 'a', 'abbacccbb', 'cccba', '', 'bbba', 'cabaccaa']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "kshuffle_model_non_eps_sampler = Sampler(kshuffle_model_non_eps)\n",
    "print([\"\".join([i for i in item if i != \"ε\"]) for item in kshuffle_model_non_eps_sampler.sample(10, sep='')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base n-gram FSA states: 8\n",
      "Base n-gram FSA entropy => 8.03324\n",
      "K-shuffle FSA states: 30\n",
      "K-shuffle FSA entropy => 8.03324\n",
      "frozendict.frozendict({(EMIT_('b', 'a')|('b', 'a')_1_b, EMIT_('b', 'a')|('b', 'a')_1_b): 0.0, (EMIT_('b', 'a')|('b', 'a')_1_b, ('b', 'a')|('a',)): 0.0, (EMIT_('b', 'a')|('b', 'a')_1_b, ('b', 'b')|('b',)): 0.0, (EMIT_('b', 'a')|('b', 'a')_1_b, ('a', 'b')|('a', 'b')): 0.01029, (EMIT_('b', 'a')|('b', 'a')_1_b, EMIT_('b', 'b')|('b', 'b')_0_b): 0.0, (EMIT_('b', 'a')|('b', 'a')_1_b, EMIT_('b', 'a')|('a',)_0_a): 0.0, (EMIT_('b', 'a')|('b', 'a')_1_b, EMIT_('BOS', 'b')|('b',)_0_b): 0.0, (EMIT_('b', 'a')|('b', 'a')_1_b, EMIT_('a', 'a')|('a', 'a')_1_a): 0.0, (EMIT_('b', 'a')|('b', 'a')_1_b, ('b', 'a')|()): 1.0, (EMIT_('b', 'a')|('b', 'a')_1_b, ('a', 'b')|('b',)): 0.16415, (EMIT_('b', 'a')|('b', 'a')_1_b, ('BOS', 'BOS')|()): 0.0, (EMIT_('b', 'a')|('b', 'a')_1_b, <KSHUFFLE_FINAL>): 0.0, (EMIT_('b', 'a')|('b', 'a')_1_b, EMIT_('a', 'a')|('a',)_0_a): 0.0, (EMIT_('b', 'a')|('b', 'a')_1_b, ('a', 'b')|()): 0.0, (EMIT_('b', 'a')|('b', 'a')_1_b, ('BOS', 'a')|('a',)): 0.0, (EMIT_('b', 'a')|('b', 'a')_1_b, ('b', 'b')|('b', 'b')): 0.00671, (EMIT_('b', 'a')|('b', 'a')_1_b, ('a', 'a')|()): 0.0, (EMIT_('b', 'a')|('b', 'a')_1_b, EMIT_('a', 'a')|('a', 'a')_0_a): 0.0, (EMIT_('b', 'a')|('b', 'a')_1_b, ('b', 'b')|()): 0.0, (EMIT_('b', 'a')|('b', 'a')_1_b, EMIT_('a', 'b')|('a', 'b')_0_b): 0.0, (EMIT_('b', 'a')|('b', 'a')_1_b, ('BOS', 'b')|('b',)): 0.0, (EMIT_('b', 'a')|('b', 'a')_1_b, EMIT_('BOS', 'a')|('a',)_0_a): 0.0, (EMIT_('b', 'a')|('b', 'a')_1_b, EMIT_('b', 'b')|('b', 'b')_1_b): 0.0, (EMIT_('b', 'a')|('b', 'a')_1_b, ('a', 'a')|('a',)): 0.06347, (EMIT_('b', 'a')|('b', 'a')_1_b, EMIT_('b', 'a')|('b', 'a')_0_a): 0.0, (EMIT_('b', 'a')|('b', 'a')_1_b, EMIT_('a', 'b')|('a', 'b')_1_a): 0.0, (EMIT_('b', 'a')|('b', 'a')_1_b, ('b', 'a')|('b', 'a')): 0.1105, (EMIT_('b', 'a')|('b', 'a')_1_b, ('a', 'a')|('a', 'a')): 0.03677, (EMIT_('b', 'a')|('b', 'a')_1_b, EMIT_('b', 'b')|('b',)_0_b): 0.0, (EMIT_('b', 'a')|('b', 'a')_1_b, EMIT_('a', 'b')|('b',)_0_b): 0.0, (('b', 'a')|('a',), EMIT_('b', 'a')|('b', 'a')_1_b): 0.0, (('b', 'a')|('a',), ('b', 'a')|('a',)): 0.0, (('b', 'a')|('a',), ('b', 'b')|('b',)): 0.0, (('b', 'a')|('a',), ('a', 'b')|('a', 'b')): 0.16415, (('b', 'a')|('a',), EMIT_('b', 'b')|('b', 'b')_0_b): 0.0, (('b', 'a')|('a',), EMIT_('b', 'a')|('a',)_0_a): 0.0, (('b', 'a')|('a',), EMIT_('BOS', 'b')|('b',)_0_b): 0.0, (('b', 'a')|('a',), EMIT_('a', 'a')|('a', 'a')_1_a): 0.0, (('b', 'a')|('a',), ('b', 'a')|()): 0.0, (('b', 'a')|('a',), ('a', 'b')|('b',)): 0.0, (('b', 'a')|('a',), ('BOS', 'BOS')|()): 0.0, (('b', 'a')|('a',), <KSHUFFLE_FINAL>): 0.0, (('b', 'a')|('a',), EMIT_('a', 'a')|('a',)_0_a): 0.0, (('b', 'a')|('a',), ('a', 'b')|()): 0.0, (('b', 'a')|('a',), ('BOS', 'a')|('a',)): 0.0, (('b', 'a')|('a',), ('b', 'b')|('b', 'b')): 0.0, (('b', 'a')|('a',), ('a', 'a')|()): 0.0, (('b', 'a')|('a',), EMIT_('a', 'a')|('a', 'a')_0_a): 0.0, (('b', 'a')|('a',), ('b', 'b')|()): 0.0, (('b', 'a')|('a',), EMIT_('a', 'b')|('a', 'b')_0_b): 0.0, (('b', 'a')|('a',), ('BOS', 'b')|('b',)): 0.0, (('b', 'a')|('a',), EMIT_('BOS', 'a')|('a',)_0_a): 0.0, (('b', 'a')|('a',), EMIT_('b', 'b')|('b', 'b')_1_b): 0.0, (('b', 'a')|('a',), ('a', 'a')|('a',)): 0.0, (('b', 'a')|('a',), EMIT_('b', 'a')|('b', 'a')_0_a): 0.0, (('b', 'a')|('a',), EMIT_('a', 'b')|('a', 'b')_1_a): 0.0, (('b', 'a')|('a',), ('b', 'a')|('b', 'a')): 0.0, (('b', 'a')|('a',), ('a', 'a')|('a', 'a')): 0.06347, (('b', 'a')|('a',), EMIT_('b', 'b')|('b',)_0_b): 0.0, (('b', 'a')|('a',), EMIT_('a', 'b')|('b',)_0_b): 0.0, (('b', 'b')|('b',), EMIT_('b', 'a')|('b', 'a')_1_b): 0.0, (('b', 'b')|('b',), ('b', 'a')|('a',)): 0.0, (('b', 'b')|('b',), ('b', 'b')|('b',)): 0.0, (('b', 'b')|('b',), ('a', 'b')|('a', 'b')): 0.0, (('b', 'b')|('b',), EMIT_('b', 'b')|('b', 'b')_0_b): 0.0, (('b', 'b')|('b',), EMIT_('b', 'a')|('a',)_0_a): 0.0, (('b', 'b')|('b',), EMIT_('BOS', 'b')|('b',)_0_b): 0.0, (('b', 'b')|('b',), EMIT_('a', 'a')|('a', 'a')_1_a): 0.0, (('b', 'b')|('b',), ('b', 'a')|()): 0.0, (('b', 'b')|('b',), ('a', 'b')|('b',)): 0.0, (('b', 'b')|('b',), ('BOS', 'BOS')|()): 0.0, (('b', 'b')|('b',), <KSHUFFLE_FINAL>): 0.0, (('b', 'b')|('b',), EMIT_('a', 'a')|('a',)_0_a): 0.0, (('b', 'b')|('b',), ('a', 'b')|()): 0.0, (('b', 'b')|('b',), ('BOS', 'a')|('a',)): 0.0, (('b', 'b')|('b',), ('b', 'b')|('b', 'b')): 0.09529, (('b', 'b')|('b',), ('a', 'a')|()): 0.0, (('b', 'b')|('b',), EMIT_('a', 'a')|('a', 'a')_0_a): 0.0, (('b', 'b')|('b',), ('b', 'b')|()): 0.0, (('b', 'b')|('b',), EMIT_('a', 'b')|('a', 'b')_0_b): 0.0, (('b', 'b')|('b',), ('BOS', 'b')|('b',)): 0.0, (('b', 'b')|('b',), EMIT_('BOS', 'a')|('a',)_0_a): 0.0, (('b', 'b')|('b',), EMIT_('b', 'b')|('b', 'b')_1_b): 0.0, (('b', 'b')|('b',), ('a', 'a')|('a',)): 0.0, (('b', 'b')|('b',), EMIT_('b', 'a')|('b', 'a')_0_a): 0.0, (('b', 'b')|('b',), EMIT_('a', 'b')|('a', 'b')_1_a): 0.0, (('b', 'b')|('b',), ('b', 'a')|('b', 'a')): 0.85956, (('b', 'b')|('b',), ('a', 'a')|('a', 'a')): 0.0, (('b', 'b')|('b',), EMIT_('b', 'b')|('b',)_0_b): 0.0, (('b', 'b')|('b',), EMIT_('a', 'b')|('b',)_0_b): 0.0, (('a', 'b')|('a', 'b'), EMIT_('b', 'a')|('b', 'a')_1_b): 0.0, (('a', 'b')|('a', 'b'), ('b', 'a')|('a',)): 0.0, (('a', 'b')|('a', 'b'), ('b', 'b')|('b',)): 0.0, (('a', 'b')|('a', 'b'), ('a', 'b')|('a', 'b')): 0.0, (('a', 'b')|('a', 'b'), EMIT_('b', 'b')|('b', 'b')_0_b): 0.0, (('a', 'b')|('a', 'b'), EMIT_('b', 'a')|('a',)_0_a): 0.0, (('a', 'b')|('a', 'b'), EMIT_('BOS', 'b')|('b',)_0_b): 0.0, (('a', 'b')|('a', 'b'), EMIT_('a', 'a')|('a', 'a')_1_a): 0.0, (('a', 'b')|('a', 'b'), ('b', 'a')|()): 0.0, (('a', 'b')|('a', 'b'), ('a', 'b')|('b',)): 0.0, (('a', 'b')|('a', 'b'), ('BOS', 'BOS')|()): 0.0, (('a', 'b')|('a', 'b'), <KSHUFFLE_FINAL>): 0.0, (('a', 'b')|('a', 'b'), EMIT_('a', 'a')|('a',)_0_a): 0.0, (('a', 'b')|('a', 'b'), ('a', 'b')|()): 0.0, (('a', 'b')|('a', 'b'), ('BOS', 'a')|('a',)): 0.0, (('a', 'b')|('a', 'b'), ('b', 'b')|('b', 'b')): 0.0, (('a', 'b')|('a', 'b'), ('a', 'a')|()): 0.0, (('a', 'b')|('a', 'b'), EMIT_('a', 'a')|('a', 'a')_0_a): 0.0, (('a', 'b')|('a', 'b'), ('b', 'b')|()): 0.0, (('a', 'b')|('a', 'b'), EMIT_('a', 'b')|('a', 'b')_0_b): 0.0, (('a', 'b')|('a', 'b'), ('BOS', 'b')|('b',)): 0.0, (('a', 'b')|('a', 'b'), EMIT_('BOS', 'a')|('a',)_0_a): 0.0, (('a', 'b')|('a', 'b'), EMIT_('b', 'b')|('b', 'b')_1_b): 0.0, (('a', 'b')|('a', 'b'), ('a', 'a')|('a',)): 0.0, (('a', 'b')|('a', 'b'), EMIT_('b', 'a')|('b', 'a')_0_a): 0.0, (('a', 'b')|('a', 'b'), EMIT_('a', 'b')|('a', 'b')_1_a): 0.0, (('a', 'b')|('a', 'b'), ('b', 'a')|('b', 'a')): 0.0, (('a', 'b')|('a', 'b'), ('a', 'a')|('a', 'a')): 0.0, (('a', 'b')|('a', 'b'), EMIT_('b', 'b')|('b',)_0_b): 0.0, (('a', 'b')|('a', 'b'), EMIT_('a', 'b')|('b',)_0_b): 0.0, (EMIT_('b', 'b')|('b', 'b')_0_b, EMIT_('b', 'a')|('b', 'a')_1_b): 0.0, (EMIT_('b', 'b')|('b', 'b')_0_b, ('b', 'a')|('a',)): 0.0, (EMIT_('b', 'b')|('b', 'b')_0_b, ('b', 'b')|('b',)): 0.0, (EMIT_('b', 'b')|('b', 'b')_0_b, ('a', 'b')|('a', 'b')): 0.0, (EMIT_('b', 'b')|('b', 'b')_0_b, EMIT_('b', 'b')|('b', 'b')_0_b): 0.0, (EMIT_('b', 'b')|('b', 'b')_0_b, EMIT_('b', 'a')|('a',)_0_a): 0.0, (EMIT_('b', 'b')|('b', 'b')_0_b, EMIT_('BOS', 'b')|('b',)_0_b): 0.0, (EMIT_('b', 'b')|('b', 'b')_0_b, EMIT_('a', 'a')|('a', 'a')_1_a): 0.0, (EMIT_('b', 'b')|('b', 'b')_0_b, ('b', 'a')|()): 0.0, (EMIT_('b', 'b')|('b', 'b')_0_b, ('a', 'b')|('b',)): 0.0, (EMIT_('b', 'b')|('b', 'b')_0_b, ('BOS', 'BOS')|()): 0.0, (EMIT_('b', 'b')|('b', 'b')_0_b, <KSHUFFLE_FINAL>): 0.0, (EMIT_('b', 'b')|('b', 'b')_0_b, EMIT_('a', 'a')|('a',)_0_a): 0.0, (EMIT_('b', 'b')|('b', 'b')_0_b, ('a', 'b')|()): 0.0, (EMIT_('b', 'b')|('b', 'b')_0_b, ('BOS', 'a')|('a',)): 0.0, (EMIT_('b', 'b')|('b', 'b')_0_b, ('b', 'b')|('b', 'b')): 0.0, (EMIT_('b', 'b')|('b', 'b')_0_b, ('a', 'a')|()): 0.0, (EMIT_('b', 'b')|('b', 'b')_0_b, EMIT_('a', 'a')|('a', 'a')_0_a): 0.0, (EMIT_('b', 'b')|('b', 'b')_0_b, ('b', 'b')|()): 0.0, (EMIT_('b', 'b')|('b', 'b')_0_b, EMIT_('a', 'b')|('a', 'b')_0_b): 0.0, (EMIT_('b', 'b')|('b', 'b')_0_b, ('BOS', 'b')|('b',)): 0.0, (EMIT_('b', 'b')|('b', 'b')_0_b, EMIT_('BOS', 'a')|('a',)_0_a): 0.0, (EMIT_('b', 'b')|('b', 'b')_0_b, EMIT_('b', 'b')|('b', 'b')_1_b): 0.0, (EMIT_('b', 'b')|('b', 'b')_0_b, ('a', 'a')|('a',)): 0.0, (EMIT_('b', 'b')|('b', 'b')_0_b, EMIT_('b', 'a')|('b', 'a')_0_a): 0.0, (EMIT_('b', 'b')|('b', 'b')_0_b, EMIT_('a', 'b')|('a', 'b')_1_a): 0.0, (EMIT_('b', 'b')|('b', 'b')_0_b, ('b', 'a')|('b', 'a')): 0.0, (EMIT_('b', 'b')|('b', 'b')_0_b, ('a', 'a')|('a', 'a')): 0.0, (EMIT_('b', 'b')|('b', 'b')_0_b, EMIT_('b', 'b')|('b',)_0_b): 0.0, (EMIT_('b', 'b')|('b', 'b')_0_b, EMIT_('a', 'b')|('b',)_0_b): 0.0, (EMIT_('b', 'a')|('a',)_0_a, EMIT_('b', 'a')|('b', 'a')_1_b): 0.0, (EMIT_('b', 'a')|('a',)_0_a, ('b', 'a')|('a',)): 0.0, (EMIT_('b', 'a')|('a',)_0_a, ('b', 'b')|('b',)): 0.0, (EMIT_('b', 'a')|('a',)_0_a, ('a', 'b')|('a', 'b')): 0.0, (EMIT_('b', 'a')|('a',)_0_a, EMIT_('b', 'b')|('b', 'b')_0_b): 0.0, (EMIT_('b', 'a')|('a',)_0_a, EMIT_('b', 'a')|('a',)_0_a): 0.0, (EMIT_('b', 'a')|('a',)_0_a, EMIT_('BOS', 'b')|('b',)_0_b): 0.0, (EMIT_('b', 'a')|('a',)_0_a, EMIT_('a', 'a')|('a', 'a')_1_a): 0.0, (EMIT_('b', 'a')|('a',)_0_a, ('b', 'a')|()): 0.0, (EMIT_('b', 'a')|('a',)_0_a, ('a', 'b')|('b',)): 0.0, (EMIT_('b', 'a')|('a',)_0_a, ('BOS', 'BOS')|()): 0.0, (EMIT_('b', 'a')|('a',)_0_a, <KSHUFFLE_FINAL>): 0.0, (EMIT_('b', 'a')|('a',)_0_a, EMIT_('a', 'a')|('a',)_0_a): 0.0, (EMIT_('b', 'a')|('a',)_0_a, ('a', 'b')|()): 0.0, (EMIT_('b', 'a')|('a',)_0_a, ('BOS', 'a')|('a',)): 0.0, (EMIT_('b', 'a')|('a',)_0_a, ('b', 'b')|('b', 'b')): 0.0, (EMIT_('b', 'a')|('a',)_0_a, ('a', 'a')|()): 0.0, (EMIT_('b', 'a')|('a',)_0_a, EMIT_('a', 'a')|('a', 'a')_0_a): 0.0, (EMIT_('b', 'a')|('a',)_0_a, ('b', 'b')|()): 0.0, (EMIT_('b', 'a')|('a',)_0_a, EMIT_('a', 'b')|('a', 'b')_0_b): 0.0, (EMIT_('b', 'a')|('a',)_0_a, ('BOS', 'b')|('b',)): 0.0, (EMIT_('b', 'a')|('a',)_0_a, EMIT_('BOS', 'a')|('a',)_0_a): 0.0, (EMIT_('b', 'a')|('a',)_0_a, EMIT_('b', 'b')|('b', 'b')_1_b): 0.0, (EMIT_('b', 'a')|('a',)_0_a, ('a', 'a')|('a',)): 0.0, (EMIT_('b', 'a')|('a',)_0_a, EMIT_('b', 'a')|('b', 'a')_0_a): 0.0, (EMIT_('b', 'a')|('a',)_0_a, EMIT_('a', 'b')|('a', 'b')_1_a): 0.0, (EMIT_('b', 'a')|('a',)_0_a, ('b', 'a')|('b', 'a')): 0.0, (EMIT_('b', 'a')|('a',)_0_a, ('a', 'a')|('a', 'a')): 0.0, (EMIT_('b', 'a')|('a',)_0_a, EMIT_('b', 'b')|('b',)_0_b): 0.0, (EMIT_('b', 'a')|('a',)_0_a, EMIT_('a', 'b')|('b',)_0_b): 0.0, (EMIT_('BOS', 'b')|('b',)_0_b, EMIT_('b', 'a')|('b', 'a')_1_b): 0.0, (EMIT_('BOS', 'b')|('b',)_0_b, ('b', 'a')|('a',)): 0.0, (EMIT_('BOS', 'b')|('b',)_0_b, ('b', 'b')|('b',)): 0.0, (EMIT_('BOS', 'b')|('b',)_0_b, ('a', 'b')|('a', 'b')): 0.0, (EMIT_('BOS', 'b')|('b',)_0_b, EMIT_('b', 'b')|('b', 'b')_0_b): 0.0, (EMIT_('BOS', 'b')|('b',)_0_b, EMIT_('b', 'a')|('a',)_0_a): 0.0, (EMIT_('BOS', 'b')|('b',)_0_b, EMIT_('BOS', 'b')|('b',)_0_b): 0.0, (EMIT_('BOS', 'b')|('b',)_0_b, EMIT_('a', 'a')|('a', 'a')_1_a): 0.0, (EMIT_('BOS', 'b')|('b',)_0_b, ('b', 'a')|()): 0.0, (EMIT_('BOS', 'b')|('b',)_0_b, ('a', 'b')|('b',)): 0.0, (EMIT_('BOS', 'b')|('b',)_0_b, ('BOS', 'BOS')|()): 0.0, (EMIT_('BOS', 'b')|('b',)_0_b, <KSHUFFLE_FINAL>): 0.0, (EMIT_('BOS', 'b')|('b',)_0_b, EMIT_('a', 'a')|('a',)_0_a): 0.0, (EMIT_('BOS', 'b')|('b',)_0_b, ('a', 'b')|()): 0.0, (EMIT_('BOS', 'b')|('b',)_0_b, ('BOS', 'a')|('a',)): 0.0, (EMIT_('BOS', 'b')|('b',)_0_b, ('b', 'b')|('b', 'b')): 0.0, (EMIT_('BOS', 'b')|('b',)_0_b, ('a', 'a')|()): 0.0, (EMIT_('BOS', 'b')|('b',)_0_b, EMIT_('a', 'a')|('a', 'a')_0_a): 0.0, (EMIT_('BOS', 'b')|('b',)_0_b, ('b', 'b')|()): 0.0, (EMIT_('BOS', 'b')|('b',)_0_b, EMIT_('a', 'b')|('a', 'b')_0_b): 0.0, (EMIT_('BOS', 'b')|('b',)_0_b, ('BOS', 'b')|('b',)): 0.0, (EMIT_('BOS', 'b')|('b',)_0_b, EMIT_('BOS', 'a')|('a',)_0_a): 0.0, (EMIT_('BOS', 'b')|('b',)_0_b, EMIT_('b', 'b')|('b', 'b')_1_b): 0.0, (EMIT_('BOS', 'b')|('b',)_0_b, ('a', 'a')|('a',)): 0.0, (EMIT_('BOS', 'b')|('b',)_0_b, EMIT_('b', 'a')|('b', 'a')_0_a): 0.0, (EMIT_('BOS', 'b')|('b',)_0_b, EMIT_('a', 'b')|('a', 'b')_1_a): 0.0, (EMIT_('BOS', 'b')|('b',)_0_b, ('b', 'a')|('b', 'a')): 0.0, (EMIT_('BOS', 'b')|('b',)_0_b, ('a', 'a')|('a', 'a')): 0.0, (EMIT_('BOS', 'b')|('b',)_0_b, EMIT_('b', 'b')|('b',)_0_b): 0.0, (EMIT_('BOS', 'b')|('b',)_0_b, EMIT_('a', 'b')|('b',)_0_b): 0.0, (EMIT_('a', 'a')|('a', 'a')_1_a, EMIT_('b', 'a')|('b', 'a')_1_b): 0.0, (EMIT_('a', 'a')|('a', 'a')_1_a, ('b', 'a')|('a',)): 0.0, (EMIT_('a', 'a')|('a', 'a')_1_a, ('b', 'b')|('b',)): 0.0, (EMIT_('a', 'a')|('a', 'a')_1_a, ('a', 'b')|('a', 'b')): 0.0939, (EMIT_('a', 'a')|('a', 'a')_1_a, EMIT_('b', 'b')|('b', 'b')_0_b): 0.0, (EMIT_('a', 'a')|('a', 'a')_1_a, EMIT_('b', 'a')|('a',)_0_a): 0.0, (EMIT_('a', 'a')|('a', 'a')_1_a, EMIT_('BOS', 'b')|('b',)_0_b): 0.0, (EMIT_('a', 'a')|('a', 'a')_1_a, EMIT_('a', 'a')|('a', 'a')_1_a): 0.0, (EMIT_('a', 'a')|('a', 'a')_1_a, ('b', 'a')|()): 0.0, (EMIT_('a', 'a')|('a', 'a')_1_a, ('a', 'b')|('b',)): 0.16208, (EMIT_('a', 'a')|('a', 'a')_1_a, ('BOS', 'BOS')|()): 0.0, (EMIT_('a', 'a')|('a', 'a')_1_a, <KSHUFFLE_FINAL>): 0.0, (EMIT_('a', 'a')|('a', 'a')_1_a, EMIT_('a', 'a')|('a',)_0_a): 0.0, (EMIT_('a', 'a')|('a', 'a')_1_a, ('a', 'b')|()): 0.0, (EMIT_('a', 'a')|('a', 'a')_1_a, ('BOS', 'a')|('a',)): 0.0, (EMIT_('a', 'a')|('a', 'a')_1_a, ('b', 'b')|('b', 'b')): 0.00663, (EMIT_('a', 'a')|('a', 'a')_1_a, ('a', 'a')|()): 1.0, (EMIT_('a', 'a')|('a', 'a')_1_a, EMIT_('a', 'a')|('a', 'a')_0_a): 0.0, (EMIT_('a', 'a')|('a', 'a')_1_a, ('b', 'b')|()): 0.0, (EMIT_('a', 'a')|('a', 'a')_1_a, EMIT_('a', 'b')|('a', 'b')_0_b): 0.0, (EMIT_('a', 'a')|('a', 'a')_1_a, ('BOS', 'b')|('b',)): 0.0, (EMIT_('a', 'a')|('a', 'a')_1_a, EMIT_('BOS', 'a')|('a',)_0_a): 0.0, (EMIT_('a', 'a')|('a', 'a')_1_a, EMIT_('b', 'b')|('b', 'b')_1_b): 0.0, (EMIT_('a', 'a')|('a', 'a')_1_a, ('a', 'a')|('a',)): 0.57932, (EMIT_('a', 'a')|('a', 'a')_1_a, EMIT_('b', 'a')|('b', 'a')_0_a): 0.0, (EMIT_('a', 'a')|('a', 'a')_1_a, EMIT_('a', 'b')|('a', 'b')_1_a): 0.0, (EMIT_('a', 'a')|('a', 'a')_1_a, ('b', 'a')|('b', 'a')): 0.10911, (EMIT_('a', 'a')|('a', 'a')_1_a, ('a', 'a')|('a', 'a')): 0.33561, (EMIT_('a', 'a')|('a', 'a')_1_a, EMIT_('b', 'b')|('b',)_0_b): 0.0, (EMIT_('a', 'a')|('a', 'a')_1_a, EMIT_('a', 'b')|('b',)_0_b): 0.0, (('b', 'a')|(), EMIT_('b', 'a')|('b', 'a')_1_b): 0.0, (('b', 'a')|(), ('b', 'a')|('a',)): 0.0, (('b', 'a')|(), ('b', 'b')|('b',)): 0.0, (('b', 'a')|(), ('a', 'b')|('a', 'b')): 0.01029, (('b', 'a')|(), EMIT_('b', 'b')|('b', 'b')_0_b): 0.0, (('b', 'a')|(), EMIT_('b', 'a')|('a',)_0_a): 0.0, (('b', 'a')|(), EMIT_('BOS', 'b')|('b',)_0_b): 0.0, (('b', 'a')|(), EMIT_('a', 'a')|('a', 'a')_1_a): 0.0, (('b', 'a')|(), ('b', 'a')|()): 0.0, (('b', 'a')|(), ('a', 'b')|('b',)): 0.16415, (('b', 'a')|(), ('BOS', 'BOS')|()): 0.0, (('b', 'a')|(), <KSHUFFLE_FINAL>): 0.0, (('b', 'a')|(), EMIT_('a', 'a')|('a',)_0_a): 0.0, (('b', 'a')|(), ('a', 'b')|()): 0.0, (('b', 'a')|(), ('BOS', 'a')|('a',)): 0.0, (('b', 'a')|(), ('b', 'b')|('b', 'b')): 0.00671, (('b', 'a')|(), ('a', 'a')|()): 0.0, (('b', 'a')|(), EMIT_('a', 'a')|('a', 'a')_0_a): 0.0, (('b', 'a')|(), ('b', 'b')|()): 0.0, (('b', 'a')|(), EMIT_('a', 'b')|('a', 'b')_0_b): 0.0, (('b', 'a')|(), ('BOS', 'b')|('b',)): 0.0, (('b', 'a')|(), EMIT_('BOS', 'a')|('a',)_0_a): 0.0, (('b', 'a')|(), EMIT_('b', 'b')|('b', 'b')_1_b): 0.0, (('b', 'a')|(), ('a', 'a')|('a',)): 0.06347, (('b', 'a')|(), EMIT_('b', 'a')|('b', 'a')_0_a): 0.0, (('b', 'a')|(), EMIT_('a', 'b')|('a', 'b')_1_a): 0.0, (('b', 'a')|(), ('b', 'a')|('b', 'a')): 0.1105, (('b', 'a')|(), ('a', 'a')|('a', 'a')): 0.03677, (('b', 'a')|(), EMIT_('b', 'b')|('b',)_0_b): 0.0, (('b', 'a')|(), EMIT_('a', 'b')|('b',)_0_b): 0.0, (('a', 'b')|('b',), EMIT_('b', 'a')|('b', 'a')_1_b): 0.0, (('a', 'b')|('b',), ('b', 'a')|('a',)): 0.0, (('a', 'b')|('b',), ('b', 'b')|('b',)): 0.0, (('a', 'b')|('b',), ('a', 'b')|('a', 'b')): 0.0, (('a', 'b')|('b',), EMIT_('b', 'b')|('b', 'b')_0_b): 0.0, (('a', 'b')|('b',), EMIT_('b', 'a')|('a',)_0_a): 0.0, (('a', 'b')|('b',), EMIT_('BOS', 'b')|('b',)_0_b): 0.0, (('a', 'b')|('b',), EMIT_('a', 'a')|('a', 'a')_1_a): 0.0, (('a', 'b')|('b',), ('b', 'a')|()): 0.0, (('a', 'b')|('b',), ('a', 'b')|('b',)): 0.0, (('a', 'b')|('b',), ('BOS', 'BOS')|()): 0.0, (('a', 'b')|('b',), <KSHUFFLE_FINAL>): 0.0, (('a', 'b')|('b',), EMIT_('a', 'a')|('a',)_0_a): 0.0, (('a', 'b')|('b',), ('a', 'b')|()): 0.0, (('a', 'b')|('b',), ('BOS', 'a')|('a',)): 0.0, (('a', 'b')|('b',), ('b', 'b')|('b', 'b')): 0.04089, (('a', 'b')|('b',), ('a', 'a')|()): 0.0, (('a', 'b')|('b',), EMIT_('a', 'a')|('a', 'a')_0_a): 0.0, (('a', 'b')|('b',), ('b', 'b')|()): 0.0, (('a', 'b')|('b',), EMIT_('a', 'b')|('a', 'b')_0_b): 0.0, (('a', 'b')|('b',), ('BOS', 'b')|('b',)): 0.0, (('a', 'b')|('b',), EMIT_('BOS', 'a')|('a',)_0_a): 0.0, (('a', 'b')|('b',), EMIT_('b', 'b')|('b', 'b')_1_b): 0.0, (('a', 'b')|('b',), ('a', 'a')|('a',)): 0.0, (('a', 'b')|('b',), EMIT_('b', 'a')|('b', 'a')_0_a): 0.0, (('a', 'b')|('b',), EMIT_('a', 'b')|('a', 'b')_1_a): 0.0, (('a', 'b')|('b',), ('b', 'a')|('b', 'a')): 0.67317, (('a', 'b')|('b',), ('a', 'a')|('a', 'a')): 0.0, (('a', 'b')|('b',), EMIT_('b', 'b')|('b',)_0_b): 0.0, (('a', 'b')|('b',), EMIT_('a', 'b')|('b',)_0_b): 0.0, (('BOS', 'BOS')|(), EMIT_('b', 'a')|('b', 'a')_1_b): 0.0, (('BOS', 'BOS')|(), ('b', 'a')|('a',)): 0.0, (('BOS', 'BOS')|(), ('b', 'b')|('b',)): 0.0, (('BOS', 'BOS')|(), ('a', 'b')|('a', 'b')): 0.00584, (('BOS', 'BOS')|(), EMIT_('b', 'b')|('b', 'b')_0_b): 0.0, (('BOS', 'BOS')|(), EMIT_('b', 'a')|('a',)_0_a): 0.0, (('BOS', 'BOS')|(), EMIT_('BOS', 'b')|('b',)_0_b): 0.0, (('BOS', 'BOS')|(), EMIT_('a', 'a')|('a', 'a')_1_a): 0.0, (('BOS', 'BOS')|(), ('b', 'a')|()): 0.0, (('BOS', 'BOS')|(), ('a', 'b')|('b',)): 0.0, (('BOS', 'BOS')|(), ('BOS', 'BOS')|()): 0.0, (('BOS', 'BOS')|(), <KSHUFFLE_FINAL>): 0.0, (('BOS', 'BOS')|(), EMIT_('a', 'a')|('a',)_0_a): 0.0, (('BOS', 'BOS')|(), ('a', 'b')|()): 0.0, (('BOS', 'BOS')|(), ('BOS', 'a')|('a',)): 0.09155, (('BOS', 'BOS')|(), ('b', 'b')|('b', 'b')): 0.01686, (('BOS', 'BOS')|(), ('a', 'a')|()): 0.0, (('BOS', 'BOS')|(), EMIT_('a', 'a')|('a', 'a')_0_a): 0.0, (('BOS', 'BOS')|(), ('b', 'b')|()): 0.0, (('BOS', 'BOS')|(), EMIT_('a', 'b')|('a', 'b')_0_b): 0.0, (('BOS', 'BOS')|(), ('BOS', 'b')|('b',)): 0.14143, (('BOS', 'BOS')|(), EMIT_('BOS', 'a')|('a',)_0_a): 0.0, (('BOS', 'BOS')|(), EMIT_('b', 'b')|('b', 'b')_1_b): 0.0, (('BOS', 'BOS')|(), ('a', 'a')|('a',)): 0.0, (('BOS', 'BOS')|(), EMIT_('b', 'a')|('b', 'a')_0_a): 0.0, (('BOS', 'BOS')|(), EMIT_('a', 'b')|('a', 'b')_1_a): 0.0, (('BOS', 'BOS')|(), ('b', 'a')|('b', 'a')): 0.02693, (('BOS', 'BOS')|(), ('a', 'a')|('a', 'a')): 0.08571, (('BOS', 'BOS')|(), EMIT_('b', 'b')|('b',)_0_b): 0.0, (('BOS', 'BOS')|(), EMIT_('a', 'b')|('b',)_0_b): 0.0, (<KSHUFFLE_FINAL>, EMIT_('b', 'a')|('b', 'a')_1_b): 0.0, (<KSHUFFLE_FINAL>, ('b', 'a')|('a',)): 0.0, (<KSHUFFLE_FINAL>, ('b', 'b')|('b',)): 0.0, (<KSHUFFLE_FINAL>, ('a', 'b')|('a', 'b')): 0.0, (<KSHUFFLE_FINAL>, EMIT_('b', 'b')|('b', 'b')_0_b): 0.0, (<KSHUFFLE_FINAL>, EMIT_('b', 'a')|('a',)_0_a): 0.0, (<KSHUFFLE_FINAL>, EMIT_('BOS', 'b')|('b',)_0_b): 0.0, (<KSHUFFLE_FINAL>, EMIT_('a', 'a')|('a', 'a')_1_a): 0.0, (<KSHUFFLE_FINAL>, ('b', 'a')|()): 0.0, (<KSHUFFLE_FINAL>, ('a', 'b')|('b',)): 0.0, (<KSHUFFLE_FINAL>, ('BOS', 'BOS')|()): 0.0, (<KSHUFFLE_FINAL>, <KSHUFFLE_FINAL>): 0.0, (<KSHUFFLE_FINAL>, EMIT_('a', 'a')|('a',)_0_a): 0.0, (<KSHUFFLE_FINAL>, ('a', 'b')|()): 0.0, (<KSHUFFLE_FINAL>, ('BOS', 'a')|('a',)): 0.0, (<KSHUFFLE_FINAL>, ('b', 'b')|('b', 'b')): 0.0, (<KSHUFFLE_FINAL>, ('a', 'a')|()): 0.0, (<KSHUFFLE_FINAL>, EMIT_('a', 'a')|('a', 'a')_0_a): 0.0, (<KSHUFFLE_FINAL>, ('b', 'b')|()): 0.0, (<KSHUFFLE_FINAL>, EMIT_('a', 'b')|('a', 'b')_0_b): 0.0, (<KSHUFFLE_FINAL>, ('BOS', 'b')|('b',)): 0.0, (<KSHUFFLE_FINAL>, EMIT_('BOS', 'a')|('a',)_0_a): 0.0, (<KSHUFFLE_FINAL>, EMIT_('b', 'b')|('b', 'b')_1_b): 0.0, (<KSHUFFLE_FINAL>, ('a', 'a')|('a',)): 0.0, (<KSHUFFLE_FINAL>, EMIT_('b', 'a')|('b', 'a')_0_a): 0.0, (<KSHUFFLE_FINAL>, EMIT_('a', 'b')|('a', 'b')_1_a): 0.0, (<KSHUFFLE_FINAL>, ('b', 'a')|('b', 'a')): 0.0, (<KSHUFFLE_FINAL>, ('a', 'a')|('a', 'a')): 0.0, (<KSHUFFLE_FINAL>, EMIT_('b', 'b')|('b',)_0_b): 0.0, (<KSHUFFLE_FINAL>, EMIT_('a', 'b')|('b',)_0_b): 0.0, (EMIT_('a', 'a')|('a',)_0_a, EMIT_('b', 'a')|('b', 'a')_1_b): 0.0, (EMIT_('a', 'a')|('a',)_0_a, ('b', 'a')|('a',)): 0.0, (EMIT_('a', 'a')|('a',)_0_a, ('b', 'b')|('b',)): 0.0, (EMIT_('a', 'a')|('a',)_0_a, ('a', 'b')|('a', 'b')): 0.0, (EMIT_('a', 'a')|('a',)_0_a, EMIT_('b', 'b')|('b', 'b')_0_b): 0.0, (EMIT_('a', 'a')|('a',)_0_a, EMIT_('b', 'a')|('a',)_0_a): 0.0, (EMIT_('a', 'a')|('a',)_0_a, EMIT_('BOS', 'b')|('b',)_0_b): 0.0, (EMIT_('a', 'a')|('a',)_0_a, EMIT_('a', 'a')|('a', 'a')_1_a): 0.0, (EMIT_('a', 'a')|('a',)_0_a, ('b', 'a')|()): 0.0, (EMIT_('a', 'a')|('a',)_0_a, ('a', 'b')|('b',)): 0.0, (EMIT_('a', 'a')|('a',)_0_a, ('BOS', 'BOS')|()): 0.0, (EMIT_('a', 'a')|('a',)_0_a, <KSHUFFLE_FINAL>): 0.0, (EMIT_('a', 'a')|('a',)_0_a, EMIT_('a', 'a')|('a',)_0_a): 0.0, (EMIT_('a', 'a')|('a',)_0_a, ('a', 'b')|()): 0.0, (EMIT_('a', 'a')|('a',)_0_a, ('BOS', 'a')|('a',)): 0.0, (EMIT_('a', 'a')|('a',)_0_a, ('b', 'b')|('b', 'b')): 0.0, (EMIT_('a', 'a')|('a',)_0_a, ('a', 'a')|()): 0.0, (EMIT_('a', 'a')|('a',)_0_a, EMIT_('a', 'a')|('a', 'a')_0_a): 0.0, (EMIT_('a', 'a')|('a',)_0_a, ('b', 'b')|()): 0.0, (EMIT_('a', 'a')|('a',)_0_a, EMIT_('a', 'b')|('a', 'b')_0_b): 0.0, (EMIT_('a', 'a')|('a',)_0_a, ('BOS', 'b')|('b',)): 0.0, (EMIT_('a', 'a')|('a',)_0_a, EMIT_('BOS', 'a')|('a',)_0_a): 0.0, (EMIT_('a', 'a')|('a',)_0_a, EMIT_('b', 'b')|('b', 'b')_1_b): 0.0, (EMIT_('a', 'a')|('a',)_0_a, ('a', 'a')|('a',)): 0.0, (EMIT_('a', 'a')|('a',)_0_a, EMIT_('b', 'a')|('b', 'a')_0_a): 0.0, (EMIT_('a', 'a')|('a',)_0_a, EMIT_('a', 'b')|('a', 'b')_1_a): 0.0, (EMIT_('a', 'a')|('a',)_0_a, ('b', 'a')|('b', 'a')): 0.0, (EMIT_('a', 'a')|('a',)_0_a, ('a', 'a')|('a', 'a')): 0.0, (EMIT_('a', 'a')|('a',)_0_a, EMIT_('b', 'b')|('b',)_0_b): 0.0, (EMIT_('a', 'a')|('a',)_0_a, EMIT_('a', 'b')|('b',)_0_b): 0.0, (('a', 'b')|(), EMIT_('b', 'a')|('b', 'a')_1_b): 0.0, (('a', 'b')|(), ('b', 'a')|('a',)): 0.67317, (('a', 'b')|(), ('b', 'b')|('b',)): 0.04089, (('a', 'b')|(), ('a', 'b')|('a', 'b')): 0.1105, (('a', 'b')|(), EMIT_('b', 'b')|('b', 'b')_0_b): 0.0, (('a', 'b')|(), EMIT_('b', 'a')|('a',)_0_a): 0.0, (('a', 'b')|(), EMIT_('BOS', 'b')|('b',)_0_b): 0.0, (('a', 'b')|(), EMIT_('a', 'a')|('a', 'a')_1_a): 0.0, (('a', 'b')|(), ('b', 'a')|()): 0.0, (('a', 'b')|(), ('a', 'b')|('b',)): 0.0, (('a', 'b')|(), ('BOS', 'BOS')|()): 0.0, (('a', 'b')|(), <KSHUFFLE_FINAL>): 0.0, (('a', 'b')|(), EMIT_('a', 'a')|('a',)_0_a): 0.0, (('a', 'b')|(), ('a', 'b')|()): 0.0, (('a', 'b')|(), ('BOS', 'a')|('a',)): 0.0, (('a', 'b')|(), ('b', 'b')|('b', 'b')): 0.0039, (('a', 'b')|(), ('a', 'a')|()): 0.0, (('a', 'b')|(), EMIT_('a', 'a')|('a', 'a')_0_a): 0.0, (('a', 'b')|(), ('b', 'b')|()): 0.0, (('a', 'b')|(), EMIT_('a', 'b')|('a', 'b')_0_b): 0.0, (('a', 'b')|(), ('BOS', 'b')|('b',)): 0.0, (('a', 'b')|(), EMIT_('BOS', 'a')|('a',)_0_a): 0.0, (('a', 'b')|(), EMIT_('b', 'b')|('b', 'b')_1_b): 0.0, (('a', 'b')|(), ('a', 'a')|('a',)): 0.0, (('a', 'b')|(), EMIT_('b', 'a')|('b', 'a')_0_a): 0.0, (('a', 'b')|(), EMIT_('a', 'b')|('a', 'b')_1_a): 0.0, (('a', 'b')|(), ('b', 'a')|('b', 'a')): 0.03515, (('a', 'b')|(), ('a', 'a')|('a', 'a')): 0.04272, (('a', 'b')|(), EMIT_('b', 'b')|('b',)_0_b): 0.0, (('a', 'b')|(), EMIT_('a', 'b')|('b',)_0_b): 0.0, (('BOS', 'a')|('a',), EMIT_('b', 'a')|('b', 'a')_1_b): 0.0, (('BOS', 'a')|('a',), ('b', 'a')|('a',)): 0.0, (('BOS', 'a')|('a',), ('b', 'b')|('b',)): 0.0, (('BOS', 'a')|('a',), ('a', 'b')|('a', 'b')): 0.06381, (('BOS', 'a')|('a',), EMIT_('b', 'b')|('b', 'b')_0_b): 0.0, (('BOS', 'a')|('a',), EMIT_('b', 'a')|('a',)_0_a): 0.0, (('BOS', 'a')|('a',), EMIT_('BOS', 'b')|('b',)_0_b): 0.0, (('BOS', 'a')|('a',), EMIT_('a', 'a')|('a', 'a')_1_a): 0.0, (('BOS', 'a')|('a',), ('b', 'a')|()): 0.0, (('BOS', 'a')|('a',), ('a', 'b')|('b',)): 0.0, (('BOS', 'a')|('a',), ('BOS', 'BOS')|()): 0.0, (('BOS', 'a')|('a',), <KSHUFFLE_FINAL>): 0.0, (('BOS', 'a')|('a',), EMIT_('a', 'a')|('a',)_0_a): 0.0, (('BOS', 'a')|('a',), ('a', 'b')|()): 0.0, (('BOS', 'a')|('a',), ('BOS', 'a')|('a',)): 0.0, (('BOS', 'a')|('a',), ('b', 'b')|('b', 'b')): 0.0, (('BOS', 'a')|('a',), ('a', 'a')|()): 0.0, (('BOS', 'a')|('a',), EMIT_('a', 'a')|('a', 'a')_0_a): 0.0, (('BOS', 'a')|('a',), ('b', 'b')|()): 0.0, (('BOS', 'a')|('a',), EMIT_('a', 'b')|('a', 'b')_0_b): 0.0, (('BOS', 'a')|('a',), ('BOS', 'b')|('b',)): 0.0, (('BOS', 'a')|('a',), EMIT_('BOS', 'a')|('a',)_0_a): 0.0, (('BOS', 'a')|('a',), EMIT_('b', 'b')|('b', 'b')_1_b): 0.0, (('BOS', 'a')|('a',), ('a', 'a')|('a',)): 0.0, (('BOS', 'a')|('a',), EMIT_('b', 'a')|('b', 'a')_0_a): 0.0, (('BOS', 'a')|('a',), EMIT_('a', 'b')|('a', 'b')_1_a): 0.0, (('BOS', 'a')|('a',), ('b', 'a')|('b', 'a')): 0.0, (('BOS', 'a')|('a',), ('a', 'a')|('a', 'a')): 0.93617, (('BOS', 'a')|('a',), EMIT_('b', 'b')|('b',)_0_b): 0.0, (('BOS', 'a')|('a',), EMIT_('a', 'b')|('b',)_0_b): 0.0, (('b', 'b')|('b', 'b'), EMIT_('b', 'a')|('b', 'a')_1_b): 0.0, (('b', 'b')|('b', 'b'), ('b', 'a')|('a',)): 0.0, (('b', 'b')|('b', 'b'), ('b', 'b')|('b',)): 0.0, (('b', 'b')|('b', 'b'), ('a', 'b')|('a', 'b')): 0.0, (('b', 'b')|('b', 'b'), EMIT_('b', 'b')|('b', 'b')_0_b): 0.0, (('b', 'b')|('b', 'b'), EMIT_('b', 'a')|('a',)_0_a): 0.0, (('b', 'b')|('b', 'b'), EMIT_('BOS', 'b')|('b',)_0_b): 0.0, (('b', 'b')|('b', 'b'), EMIT_('a', 'a')|('a', 'a')_1_a): 0.0, (('b', 'b')|('b', 'b'), ('b', 'a')|()): 0.0, (('b', 'b')|('b', 'b'), ('a', 'b')|('b',)): 0.0, (('b', 'b')|('b', 'b'), ('BOS', 'BOS')|()): 0.0, (('b', 'b')|('b', 'b'), <KSHUFFLE_FINAL>): 0.0, (('b', 'b')|('b', 'b'), EMIT_('a', 'a')|('a',)_0_a): 0.0, (('b', 'b')|('b', 'b'), ('a', 'b')|()): 0.0, (('b', 'b')|('b', 'b'), ('BOS', 'a')|('a',)): 0.0, (('b', 'b')|('b', 'b'), ('b', 'b')|('b', 'b')): 0.0, (('b', 'b')|('b', 'b'), ('a', 'a')|()): 0.0, (('b', 'b')|('b', 'b'), EMIT_('a', 'a')|('a', 'a')_0_a): 0.0, (('b', 'b')|('b', 'b'), ('b', 'b')|()): 0.0, (('b', 'b')|('b', 'b'), EMIT_('a', 'b')|('a', 'b')_0_b): 0.0, (('b', 'b')|('b', 'b'), ('BOS', 'b')|('b',)): 0.0, (('b', 'b')|('b', 'b'), EMIT_('BOS', 'a')|('a',)_0_a): 0.0, (('b', 'b')|('b', 'b'), EMIT_('b', 'b')|('b', 'b')_1_b): 0.0, (('b', 'b')|('b', 'b'), ('a', 'a')|('a',)): 0.0, (('b', 'b')|('b', 'b'), EMIT_('b', 'a')|('b', 'a')_0_a): 0.0, (('b', 'b')|('b', 'b'), EMIT_('a', 'b')|('a', 'b')_1_a): 0.0, (('b', 'b')|('b', 'b'), ('b', 'a')|('b', 'a')): 0.0, (('b', 'b')|('b', 'b'), ('a', 'a')|('a', 'a')): 0.0, (('b', 'b')|('b', 'b'), EMIT_('b', 'b')|('b',)_0_b): 0.0, (('b', 'b')|('b', 'b'), EMIT_('a', 'b')|('b',)_0_b): 0.0, (('a', 'a')|(), EMIT_('b', 'a')|('b', 'a')_1_b): 0.0, (('a', 'a')|(), ('b', 'a')|('a',)): 0.0, (('a', 'a')|(), ('b', 'b')|('b',)): 0.0, (('a', 'a')|(), ('a', 'b')|('a', 'b')): 0.0939, (('a', 'a')|(), EMIT_('b', 'b')|('b', 'b')_0_b): 0.0, (('a', 'a')|(), EMIT_('b', 'a')|('a',)_0_a): 0.0, (('a', 'a')|(), EMIT_('BOS', 'b')|('b',)_0_b): 0.0, (('a', 'a')|(), EMIT_('a', 'a')|('a', 'a')_1_a): 0.0, (('a', 'a')|(), ('b', 'a')|()): 0.0, (('a', 'a')|(), ('a', 'b')|('b',)): 0.16208, (('a', 'a')|(), ('BOS', 'BOS')|()): 0.0, (('a', 'a')|(), <KSHUFFLE_FINAL>): 0.0, (('a', 'a')|(), EMIT_('a', 'a')|('a',)_0_a): 0.0, (('a', 'a')|(), ('a', 'b')|()): 0.0, (('a', 'a')|(), ('BOS', 'a')|('a',)): 0.0, (('a', 'a')|(), ('b', 'b')|('b', 'b')): 0.00663, (('a', 'a')|(), ('a', 'a')|()): 0.0, (('a', 'a')|(), EMIT_('a', 'a')|('a', 'a')_0_a): 0.0, (('a', 'a')|(), ('b', 'b')|()): 0.0, (('a', 'a')|(), EMIT_('a', 'b')|('a', 'b')_0_b): 0.0, (('a', 'a')|(), ('BOS', 'b')|('b',)): 0.0, (('a', 'a')|(), EMIT_('BOS', 'a')|('a',)_0_a): 0.0, (('a', 'a')|(), EMIT_('b', 'b')|('b', 'b')_1_b): 0.0, (('a', 'a')|(), ('a', 'a')|('a',)): 0.57932, (('a', 'a')|(), EMIT_('b', 'a')|('b', 'a')_0_a): 0.0, (('a', 'a')|(), EMIT_('a', 'b')|('a', 'b')_1_a): 0.0, (('a', 'a')|(), ('b', 'a')|('b', 'a')): 0.10911, (('a', 'a')|(), ('a', 'a')|('a', 'a')): 0.33561, (('a', 'a')|(), EMIT_('b', 'b')|('b',)_0_b): 0.0, (('a', 'a')|(), EMIT_('a', 'b')|('b',)_0_b): 0.0, (EMIT_('a', 'a')|('a', 'a')_0_a, EMIT_('b', 'a')|('b', 'a')_1_b): 0.0, (EMIT_('a', 'a')|('a', 'a')_0_a, ('b', 'a')|('a',)): 0.0, (EMIT_('a', 'a')|('a', 'a')_0_a, ('b', 'b')|('b',)): 0.0, (EMIT_('a', 'a')|('a', 'a')_0_a, ('a', 'b')|('a', 'b')): 0.0, (EMIT_('a', 'a')|('a', 'a')_0_a, EMIT_('b', 'b')|('b', 'b')_0_b): 0.0, (EMIT_('a', 'a')|('a', 'a')_0_a, EMIT_('b', 'a')|('a',)_0_a): 0.0, (EMIT_('a', 'a')|('a', 'a')_0_a, EMIT_('BOS', 'b')|('b',)_0_b): 0.0, (EMIT_('a', 'a')|('a', 'a')_0_a, EMIT_('a', 'a')|('a', 'a')_1_a): 0.0, (EMIT_('a', 'a')|('a', 'a')_0_a, ('b', 'a')|()): 0.0, (EMIT_('a', 'a')|('a', 'a')_0_a, ('a', 'b')|('b',)): 0.0, (EMIT_('a', 'a')|('a', 'a')_0_a, ('BOS', 'BOS')|()): 0.0, (EMIT_('a', 'a')|('a', 'a')_0_a, <KSHUFFLE_FINAL>): 0.0, (EMIT_('a', 'a')|('a', 'a')_0_a, EMIT_('a', 'a')|('a',)_0_a): 0.0, (EMIT_('a', 'a')|('a', 'a')_0_a, ('a', 'b')|()): 0.0, (EMIT_('a', 'a')|('a', 'a')_0_a, ('BOS', 'a')|('a',)): 0.0, (EMIT_('a', 'a')|('a', 'a')_0_a, ('b', 'b')|('b', 'b')): 0.0, (EMIT_('a', 'a')|('a', 'a')_0_a, ('a', 'a')|()): 0.0, (EMIT_('a', 'a')|('a', 'a')_0_a, EMIT_('a', 'a')|('a', 'a')_0_a): 0.0, (EMIT_('a', 'a')|('a', 'a')_0_a, ('b', 'b')|()): 0.0, (EMIT_('a', 'a')|('a', 'a')_0_a, EMIT_('a', 'b')|('a', 'b')_0_b): 0.0, (EMIT_('a', 'a')|('a', 'a')_0_a, ('BOS', 'b')|('b',)): 0.0, (EMIT_('a', 'a')|('a', 'a')_0_a, EMIT_('BOS', 'a')|('a',)_0_a): 0.0, (EMIT_('a', 'a')|('a', 'a')_0_a, EMIT_('b', 'b')|('b', 'b')_1_b): 0.0, (EMIT_('a', 'a')|('a', 'a')_0_a, ('a', 'a')|('a',)): 0.0, (EMIT_('a', 'a')|('a', 'a')_0_a, EMIT_('b', 'a')|('b', 'a')_0_a): 0.0, (EMIT_('a', 'a')|('a', 'a')_0_a, EMIT_('a', 'b')|('a', 'b')_1_a): 0.0, (EMIT_('a', 'a')|('a', 'a')_0_a, ('b', 'a')|('b', 'a')): 0.0, (EMIT_('a', 'a')|('a', 'a')_0_a, ('a', 'a')|('a', 'a')): 0.0, (EMIT_('a', 'a')|('a', 'a')_0_a, EMIT_('b', 'b')|('b',)_0_b): 0.0, (EMIT_('a', 'a')|('a', 'a')_0_a, EMIT_('a', 'b')|('b',)_0_b): 0.0, (('b', 'b')|(), EMIT_('b', 'a')|('b', 'a')_1_b): 0.0, (('b', 'b')|(), ('b', 'a')|('a',)): 0.85956, (('b', 'b')|(), ('b', 'b')|('b',)): 0.09529, (('b', 'b')|(), ('a', 'b')|('a', 'b')): 0.1411, (('b', 'b')|(), EMIT_('b', 'b')|('b', 'b')_0_b): 0.0, (('b', 'b')|(), EMIT_('b', 'a')|('a',)_0_a): 0.0, (('b', 'b')|(), EMIT_('BOS', 'b')|('b',)_0_b): 0.0, (('b', 'b')|(), EMIT_('a', 'a')|('a', 'a')_1_a): 0.0, (('b', 'b')|(), ('b', 'a')|()): 0.0, (('b', 'b')|(), ('a', 'b')|('b',)): 0.0, (('b', 'b')|(), ('BOS', 'BOS')|()): 0.0, (('b', 'b')|(), <KSHUFFLE_FINAL>): 0.0, (('b', 'b')|(), EMIT_('a', 'a')|('a',)_0_a): 0.0, (('b', 'b')|(), ('a', 'b')|()): 0.0, (('b', 'b')|(), ('BOS', 'a')|('a',)): 0.0, (('b', 'b')|(), ('b', 'b')|('b', 'b')): 0.00908, (('b', 'b')|(), ('a', 'a')|()): 0.0, (('b', 'b')|(), EMIT_('a', 'a')|('a', 'a')_0_a): 0.0, (('b', 'b')|(), ('b', 'b')|()): 0.0, (('b', 'b')|(), EMIT_('a', 'b')|('a', 'b')_0_b): 0.0, (('b', 'b')|(), ('BOS', 'b')|('b',)): 0.0, (('b', 'b')|(), EMIT_('BOS', 'a')|('a',)_0_a): 0.0, (('b', 'b')|(), EMIT_('b', 'b')|('b', 'b')_1_b): 0.0, (('b', 'b')|(), ('a', 'a')|('a',)): 0.0, (('b', 'b')|(), EMIT_('b', 'a')|('b', 'a')_0_a): 0.0, (('b', 'b')|(), EMIT_('a', 'b')|('a', 'b')_1_a): 0.0, (('b', 'b')|(), ('b', 'a')|('b', 'a')): 0.0819, (('b', 'b')|(), ('a', 'a')|('a', 'a')): 0.05455, (('b', 'b')|(), EMIT_('b', 'b')|('b',)_0_b): 0.0, (('b', 'b')|(), EMIT_('a', 'b')|('b',)_0_b): 0.0, (EMIT_('a', 'b')|('a', 'b')_0_b, EMIT_('b', 'a')|('b', 'a')_1_b): 0.0, (EMIT_('a', 'b')|('a', 'b')_0_b, ('b', 'a')|('a',)): 0.0, (EMIT_('a', 'b')|('a', 'b')_0_b, ('b', 'b')|('b',)): 0.0, (EMIT_('a', 'b')|('a', 'b')_0_b, ('a', 'b')|('a', 'b')): 0.0, (EMIT_('a', 'b')|('a', 'b')_0_b, EMIT_('b', 'b')|('b', 'b')_0_b): 0.0, (EMIT_('a', 'b')|('a', 'b')_0_b, EMIT_('b', 'a')|('a',)_0_a): 0.0, (EMIT_('a', 'b')|('a', 'b')_0_b, EMIT_('BOS', 'b')|('b',)_0_b): 0.0, (EMIT_('a', 'b')|('a', 'b')_0_b, EMIT_('a', 'a')|('a', 'a')_1_a): 0.0, (EMIT_('a', 'b')|('a', 'b')_0_b, ('b', 'a')|()): 0.0, (EMIT_('a', 'b')|('a', 'b')_0_b, ('a', 'b')|('b',)): 0.0, (EMIT_('a', 'b')|('a', 'b')_0_b, ('BOS', 'BOS')|()): 0.0, (EMIT_('a', 'b')|('a', 'b')_0_b, <KSHUFFLE_FINAL>): 0.0, (EMIT_('a', 'b')|('a', 'b')_0_b, EMIT_('a', 'a')|('a',)_0_a): 0.0, (EMIT_('a', 'b')|('a', 'b')_0_b, ('a', 'b')|()): 0.0, (EMIT_('a', 'b')|('a', 'b')_0_b, ('BOS', 'a')|('a',)): 0.0, (EMIT_('a', 'b')|('a', 'b')_0_b, ('b', 'b')|('b', 'b')): 0.0, (EMIT_('a', 'b')|('a', 'b')_0_b, ('a', 'a')|()): 0.0, (EMIT_('a', 'b')|('a', 'b')_0_b, EMIT_('a', 'a')|('a', 'a')_0_a): 0.0, (EMIT_('a', 'b')|('a', 'b')_0_b, ('b', 'b')|()): 0.0, (EMIT_('a', 'b')|('a', 'b')_0_b, EMIT_('a', 'b')|('a', 'b')_0_b): 0.0, (EMIT_('a', 'b')|('a', 'b')_0_b, ('BOS', 'b')|('b',)): 0.0, (EMIT_('a', 'b')|('a', 'b')_0_b, EMIT_('BOS', 'a')|('a',)_0_a): 0.0, (EMIT_('a', 'b')|('a', 'b')_0_b, EMIT_('b', 'b')|('b', 'b')_1_b): 0.0, (EMIT_('a', 'b')|('a', 'b')_0_b, ('a', 'a')|('a',)): 0.0, (EMIT_('a', 'b')|('a', 'b')_0_b, EMIT_('b', 'a')|('b', 'a')_0_a): 0.0, (EMIT_('a', 'b')|('a', 'b')_0_b, EMIT_('a', 'b')|('a', 'b')_1_a): 0.0, (EMIT_('a', 'b')|('a', 'b')_0_b, ('b', 'a')|('b', 'a')): 0.0, (EMIT_('a', 'b')|('a', 'b')_0_b, ('a', 'a')|('a', 'a')): 0.0, (EMIT_('a', 'b')|('a', 'b')_0_b, EMIT_('b', 'b')|('b',)_0_b): 0.0, (EMIT_('a', 'b')|('a', 'b')_0_b, EMIT_('a', 'b')|('b',)_0_b): 0.0, (('BOS', 'b')|('b',), EMIT_('b', 'a')|('b', 'a')_1_b): 0.0, (('BOS', 'b')|('b',), ('b', 'a')|('a',)): 0.0, (('BOS', 'b')|('b',), ('b', 'b')|('b',)): 0.0, (('BOS', 'b')|('b',), ('a', 'b')|('a', 'b')): 0.0, (('BOS', 'b')|('b',), EMIT_('b', 'b')|('b', 'b')_0_b): 0.0, (('BOS', 'b')|('b',), EMIT_('b', 'a')|('a',)_0_a): 0.0, (('BOS', 'b')|('b',), EMIT_('BOS', 'b')|('b',)_0_b): 0.0, (('BOS', 'b')|('b',), EMIT_('a', 'a')|('a', 'a')_1_a): 0.0, (('BOS', 'b')|('b',), ('b', 'a')|()): 0.0, (('BOS', 'b')|('b',), ('a', 'b')|('b',)): 0.0, (('BOS', 'b')|('b',), ('BOS', 'BOS')|()): 0.0, (('BOS', 'b')|('b',), <KSHUFFLE_FINAL>): 0.0, (('BOS', 'b')|('b',), EMIT_('a', 'a')|('a',)_0_a): 0.0, (('BOS', 'b')|('b',), ('a', 'b')|()): 0.0, (('BOS', 'b')|('b',), ('BOS', 'a')|('a',)): 0.0, (('BOS', 'b')|('b',), ('b', 'b')|('b', 'b')): 0.11919, (('BOS', 'b')|('b',), ('a', 'a')|()): 0.0, (('BOS', 'b')|('b',), EMIT_('a', 'a')|('a', 'a')_0_a): 0.0, (('BOS', 'b')|('b',), ('b', 'b')|()): 0.0, (('BOS', 'b')|('b',), EMIT_('a', 'b')|('a', 'b')_0_b): 0.0, (('BOS', 'b')|('b',), ('BOS', 'b')|('b',)): 0.0, (('BOS', 'b')|('b',), EMIT_('BOS', 'a')|('a',)_0_a): 0.0, (('BOS', 'b')|('b',), EMIT_('b', 'b')|('b', 'b')_1_b): 0.0, (('BOS', 'b')|('b',), ('a', 'a')|('a',)): 0.0, (('BOS', 'b')|('b',), EMIT_('b', 'a')|('b', 'a')_0_a): 0.0, (('BOS', 'b')|('b',), EMIT_('a', 'b')|('a', 'b')_1_a): 0.0, (('BOS', 'b')|('b',), ('b', 'a')|('b', 'a')): 0.19041, (('BOS', 'b')|('b',), ('a', 'a')|('a', 'a')): 0.0, (('BOS', 'b')|('b',), EMIT_('b', 'b')|('b',)_0_b): 0.0, (('BOS', 'b')|('b',), EMIT_('a', 'b')|('b',)_0_b): 0.0, (EMIT_('BOS', 'a')|('a',)_0_a, EMIT_('b', 'a')|('b', 'a')_1_b): 0.0, (EMIT_('BOS', 'a')|('a',)_0_a, ('b', 'a')|('a',)): 0.0, (EMIT_('BOS', 'a')|('a',)_0_a, ('b', 'b')|('b',)): 0.0, (EMIT_('BOS', 'a')|('a',)_0_a, ('a', 'b')|('a', 'b')): 0.0, (EMIT_('BOS', 'a')|('a',)_0_a, EMIT_('b', 'b')|('b', 'b')_0_b): 0.0, (EMIT_('BOS', 'a')|('a',)_0_a, EMIT_('b', 'a')|('a',)_0_a): 0.0, (EMIT_('BOS', 'a')|('a',)_0_a, EMIT_('BOS', 'b')|('b',)_0_b): 0.0, (EMIT_('BOS', 'a')|('a',)_0_a, EMIT_('a', 'a')|('a', 'a')_1_a): 0.0, (EMIT_('BOS', 'a')|('a',)_0_a, ('b', 'a')|()): 0.0, (EMIT_('BOS', 'a')|('a',)_0_a, ('a', 'b')|('b',)): 0.0, (EMIT_('BOS', 'a')|('a',)_0_a, ('BOS', 'BOS')|()): 0.0, (EMIT_('BOS', 'a')|('a',)_0_a, <KSHUFFLE_FINAL>): 0.0, (EMIT_('BOS', 'a')|('a',)_0_a, EMIT_('a', 'a')|('a',)_0_a): 0.0, (EMIT_('BOS', 'a')|('a',)_0_a, ('a', 'b')|()): 0.0, (EMIT_('BOS', 'a')|('a',)_0_a, ('BOS', 'a')|('a',)): 0.0, (EMIT_('BOS', 'a')|('a',)_0_a, ('b', 'b')|('b', 'b')): 0.0, (EMIT_('BOS', 'a')|('a',)_0_a, ('a', 'a')|()): 0.0, (EMIT_('BOS', 'a')|('a',)_0_a, EMIT_('a', 'a')|('a', 'a')_0_a): 0.0, (EMIT_('BOS', 'a')|('a',)_0_a, ('b', 'b')|()): 0.0, (EMIT_('BOS', 'a')|('a',)_0_a, EMIT_('a', 'b')|('a', 'b')_0_b): 0.0, (EMIT_('BOS', 'a')|('a',)_0_a, ('BOS', 'b')|('b',)): 0.0, (EMIT_('BOS', 'a')|('a',)_0_a, EMIT_('BOS', 'a')|('a',)_0_a): 0.0, (EMIT_('BOS', 'a')|('a',)_0_a, EMIT_('b', 'b')|('b', 'b')_1_b): 0.0, (EMIT_('BOS', 'a')|('a',)_0_a, ('a', 'a')|('a',)): 0.0, (EMIT_('BOS', 'a')|('a',)_0_a, EMIT_('b', 'a')|('b', 'a')_0_a): 0.0, (EMIT_('BOS', 'a')|('a',)_0_a, EMIT_('a', 'b')|('a', 'b')_1_a): 0.0, (EMIT_('BOS', 'a')|('a',)_0_a, ('b', 'a')|('b', 'a')): 0.0, (EMIT_('BOS', 'a')|('a',)_0_a, ('a', 'a')|('a', 'a')): 0.0, (EMIT_('BOS', 'a')|('a',)_0_a, EMIT_('b', 'b')|('b',)_0_b): 0.0, (EMIT_('BOS', 'a')|('a',)_0_a, EMIT_('a', 'b')|('b',)_0_b): 0.0, (EMIT_('b', 'b')|('b', 'b')_1_b, EMIT_('b', 'a')|('b', 'a')_1_b): 0.0, (EMIT_('b', 'b')|('b', 'b')_1_b, ('b', 'a')|('a',)): 0.85956, (EMIT_('b', 'b')|('b', 'b')_1_b, ('b', 'b')|('b',)): 0.09529, (EMIT_('b', 'b')|('b', 'b')_1_b, ('a', 'b')|('a', 'b')): 0.1411, (EMIT_('b', 'b')|('b', 'b')_1_b, EMIT_('b', 'b')|('b', 'b')_0_b): 0.0, (EMIT_('b', 'b')|('b', 'b')_1_b, EMIT_('b', 'a')|('a',)_0_a): 0.0, (EMIT_('b', 'b')|('b', 'b')_1_b, EMIT_('BOS', 'b')|('b',)_0_b): 0.0, (EMIT_('b', 'b')|('b', 'b')_1_b, EMIT_('a', 'a')|('a', 'a')_1_a): 0.0, (EMIT_('b', 'b')|('b', 'b')_1_b, ('b', 'a')|()): 0.0, (EMIT_('b', 'b')|('b', 'b')_1_b, ('a', 'b')|('b',)): 0.0, (EMIT_('b', 'b')|('b', 'b')_1_b, ('BOS', 'BOS')|()): 0.0, (EMIT_('b', 'b')|('b', 'b')_1_b, <KSHUFFLE_FINAL>): 0.0, (EMIT_('b', 'b')|('b', 'b')_1_b, EMIT_('a', 'a')|('a',)_0_a): 0.0, (EMIT_('b', 'b')|('b', 'b')_1_b, ('a', 'b')|()): 0.0, (EMIT_('b', 'b')|('b', 'b')_1_b, ('BOS', 'a')|('a',)): 0.0, (EMIT_('b', 'b')|('b', 'b')_1_b, ('b', 'b')|('b', 'b')): 0.00908, (EMIT_('b', 'b')|('b', 'b')_1_b, ('a', 'a')|()): 0.0, (EMIT_('b', 'b')|('b', 'b')_1_b, EMIT_('a', 'a')|('a', 'a')_0_a): 0.0, (EMIT_('b', 'b')|('b', 'b')_1_b, ('b', 'b')|()): 1.0, (EMIT_('b', 'b')|('b', 'b')_1_b, EMIT_('a', 'b')|('a', 'b')_0_b): 0.0, (EMIT_('b', 'b')|('b', 'b')_1_b, ('BOS', 'b')|('b',)): 0.0, (EMIT_('b', 'b')|('b', 'b')_1_b, EMIT_('BOS', 'a')|('a',)_0_a): 0.0, (EMIT_('b', 'b')|('b', 'b')_1_b, EMIT_('b', 'b')|('b', 'b')_1_b): 0.0, (EMIT_('b', 'b')|('b', 'b')_1_b, ('a', 'a')|('a',)): 0.0, (EMIT_('b', 'b')|('b', 'b')_1_b, EMIT_('b', 'a')|('b', 'a')_0_a): 0.0, (EMIT_('b', 'b')|('b', 'b')_1_b, EMIT_('a', 'b')|('a', 'b')_1_a): 0.0, (EMIT_('b', 'b')|('b', 'b')_1_b, ('b', 'a')|('b', 'a')): 0.0819, (EMIT_('b', 'b')|('b', 'b')_1_b, ('a', 'a')|('a', 'a')): 0.05455, (EMIT_('b', 'b')|('b', 'b')_1_b, EMIT_('b', 'b')|('b',)_0_b): 0.0, (EMIT_('b', 'b')|('b', 'b')_1_b, EMIT_('a', 'b')|('b',)_0_b): 0.0, (('a', 'a')|('a',), EMIT_('b', 'a')|('b', 'a')_1_b): 0.0, (('a', 'a')|('a',), ('b', 'a')|('a',)): 0.0, (('a', 'a')|('a',), ('b', 'b')|('b',)): 0.0, (('a', 'a')|('a',), ('a', 'b')|('a', 'b')): 0.16208, (('a', 'a')|('a',), EMIT_('b', 'b')|('b', 'b')_0_b): 0.0, (('a', 'a')|('a',), EMIT_('b', 'a')|('a',)_0_a): 0.0, (('a', 'a')|('a',), EMIT_('BOS', 'b')|('b',)_0_b): 0.0, (('a', 'a')|('a',), EMIT_('a', 'a')|('a', 'a')_1_a): 0.0, (('a', 'a')|('a',), ('b', 'a')|()): 0.0, (('a', 'a')|('a',), ('a', 'b')|('b',)): 0.0, (('a', 'a')|('a',), ('BOS', 'BOS')|()): 0.0, (('a', 'a')|('a',), <KSHUFFLE_FINAL>): 0.0, (('a', 'a')|('a',), EMIT_('a', 'a')|('a',)_0_a): 0.0, (('a', 'a')|('a',), ('a', 'b')|()): 0.0, (('a', 'a')|('a',), ('BOS', 'a')|('a',)): 0.0, (('a', 'a')|('a',), ('b', 'b')|('b', 'b')): 0.0, (('a', 'a')|('a',), ('a', 'a')|()): 0.0, (('a', 'a')|('a',), EMIT_('a', 'a')|('a', 'a')_0_a): 0.0, (('a', 'a')|('a',), ('b', 'b')|()): 0.0, (('a', 'a')|('a',), EMIT_('a', 'b')|('a', 'b')_0_b): 0.0, (('a', 'a')|('a',), ('BOS', 'b')|('b',)): 0.0, (('a', 'a')|('a',), EMIT_('BOS', 'a')|('a',)_0_a): 0.0, (('a', 'a')|('a',), EMIT_('b', 'b')|('b', 'b')_1_b): 0.0, (('a', 'a')|('a',), ('a', 'a')|('a',)): 0.0, (('a', 'a')|('a',), EMIT_('b', 'a')|('b', 'a')_0_a): 0.0, (('a', 'a')|('a',), EMIT_('a', 'b')|('a', 'b')_1_a): 0.0, (('a', 'a')|('a',), ('b', 'a')|('b', 'a')): 0.0, (('a', 'a')|('a',), ('a', 'a')|('a', 'a')): 0.57932, (('a', 'a')|('a',), EMIT_('b', 'b')|('b',)_0_b): 0.0, (('a', 'a')|('a',), EMIT_('a', 'b')|('b',)_0_b): 0.0, (EMIT_('b', 'a')|('b', 'a')_0_a, EMIT_('b', 'a')|('b', 'a')_1_b): 0.0, (EMIT_('b', 'a')|('b', 'a')_0_a, ('b', 'a')|('a',)): 0.0, (EMIT_('b', 'a')|('b', 'a')_0_a, ('b', 'b')|('b',)): 0.0, (EMIT_('b', 'a')|('b', 'a')_0_a, ('a', 'b')|('a', 'b')): 0.0, (EMIT_('b', 'a')|('b', 'a')_0_a, EMIT_('b', 'b')|('b', 'b')_0_b): 0.0, (EMIT_('b', 'a')|('b', 'a')_0_a, EMIT_('b', 'a')|('a',)_0_a): 0.0, (EMIT_('b', 'a')|('b', 'a')_0_a, EMIT_('BOS', 'b')|('b',)_0_b): 0.0, (EMIT_('b', 'a')|('b', 'a')_0_a, EMIT_('a', 'a')|('a', 'a')_1_a): 0.0, (EMIT_('b', 'a')|('b', 'a')_0_a, ('b', 'a')|()): 0.0, (EMIT_('b', 'a')|('b', 'a')_0_a, ('a', 'b')|('b',)): 0.0, (EMIT_('b', 'a')|('b', 'a')_0_a, ('BOS', 'BOS')|()): 0.0, (EMIT_('b', 'a')|('b', 'a')_0_a, <KSHUFFLE_FINAL>): 0.0, (EMIT_('b', 'a')|('b', 'a')_0_a, EMIT_('a', 'a')|('a',)_0_a): 0.0, (EMIT_('b', 'a')|('b', 'a')_0_a, ('a', 'b')|()): 0.0, (EMIT_('b', 'a')|('b', 'a')_0_a, ('BOS', 'a')|('a',)): 0.0, (EMIT_('b', 'a')|('b', 'a')_0_a, ('b', 'b')|('b', 'b')): 0.0, (EMIT_('b', 'a')|('b', 'a')_0_a, ('a', 'a')|()): 0.0, (EMIT_('b', 'a')|('b', 'a')_0_a, EMIT_('a', 'a')|('a', 'a')_0_a): 0.0, (EMIT_('b', 'a')|('b', 'a')_0_a, ('b', 'b')|()): 0.0, (EMIT_('b', 'a')|('b', 'a')_0_a, EMIT_('a', 'b')|('a', 'b')_0_b): 0.0, (EMIT_('b', 'a')|('b', 'a')_0_a, ('BOS', 'b')|('b',)): 0.0, (EMIT_('b', 'a')|('b', 'a')_0_a, EMIT_('BOS', 'a')|('a',)_0_a): 0.0, (EMIT_('b', 'a')|('b', 'a')_0_a, EMIT_('b', 'b')|('b', 'b')_1_b): 0.0, (EMIT_('b', 'a')|('b', 'a')_0_a, ('a', 'a')|('a',)): 0.0, (EMIT_('b', 'a')|('b', 'a')_0_a, EMIT_('b', 'a')|('b', 'a')_0_a): 0.0, (EMIT_('b', 'a')|('b', 'a')_0_a, EMIT_('a', 'b')|('a', 'b')_1_a): 0.0, (EMIT_('b', 'a')|('b', 'a')_0_a, ('b', 'a')|('b', 'a')): 0.0, (EMIT_('b', 'a')|('b', 'a')_0_a, ('a', 'a')|('a', 'a')): 0.0, (EMIT_('b', 'a')|('b', 'a')_0_a, EMIT_('b', 'b')|('b',)_0_b): 0.0, (EMIT_('b', 'a')|('b', 'a')_0_a, EMIT_('a', 'b')|('b',)_0_b): 0.0, (EMIT_('a', 'b')|('a', 'b')_1_a, EMIT_('b', 'a')|('b', 'a')_1_b): 0.0, (EMIT_('a', 'b')|('a', 'b')_1_a, ('b', 'a')|('a',)): 0.67317, (EMIT_('a', 'b')|('a', 'b')_1_a, ('b', 'b')|('b',)): 0.04089, (EMIT_('a', 'b')|('a', 'b')_1_a, ('a', 'b')|('a', 'b')): 0.1105, (EMIT_('a', 'b')|('a', 'b')_1_a, EMIT_('b', 'b')|('b', 'b')_0_b): 0.0, (EMIT_('a', 'b')|('a', 'b')_1_a, EMIT_('b', 'a')|('a',)_0_a): 0.0, (EMIT_('a', 'b')|('a', 'b')_1_a, EMIT_('BOS', 'b')|('b',)_0_b): 0.0, (EMIT_('a', 'b')|('a', 'b')_1_a, EMIT_('a', 'a')|('a', 'a')_1_a): 0.0, (EMIT_('a', 'b')|('a', 'b')_1_a, ('b', 'a')|()): 0.0, (EMIT_('a', 'b')|('a', 'b')_1_a, ('a', 'b')|('b',)): 0.0, (EMIT_('a', 'b')|('a', 'b')_1_a, ('BOS', 'BOS')|()): 0.0, (EMIT_('a', 'b')|('a', 'b')_1_a, <KSHUFFLE_FINAL>): 0.0, (EMIT_('a', 'b')|('a', 'b')_1_a, EMIT_('a', 'a')|('a',)_0_a): 0.0, (EMIT_('a', 'b')|('a', 'b')_1_a, ('a', 'b')|()): 1.0, (EMIT_('a', 'b')|('a', 'b')_1_a, ('BOS', 'a')|('a',)): 0.0, (EMIT_('a', 'b')|('a', 'b')_1_a, ('b', 'b')|('b', 'b')): 0.0039, (EMIT_('a', 'b')|('a', 'b')_1_a, ('a', 'a')|()): 0.0, (EMIT_('a', 'b')|('a', 'b')_1_a, EMIT_('a', 'a')|('a', 'a')_0_a): 0.0, (EMIT_('a', 'b')|('a', 'b')_1_a, ('b', 'b')|()): 0.0, (EMIT_('a', 'b')|('a', 'b')_1_a, EMIT_('a', 'b')|('a', 'b')_0_b): 0.0, (EMIT_('a', 'b')|('a', 'b')_1_a, ('BOS', 'b')|('b',)): 0.0, (EMIT_('a', 'b')|('a', 'b')_1_a, EMIT_('BOS', 'a')|('a',)_0_a): 0.0, (EMIT_('a', 'b')|('a', 'b')_1_a, EMIT_('b', 'b')|('b', 'b')_1_b): 0.0, (EMIT_('a', 'b')|('a', 'b')_1_a, ('a', 'a')|('a',)): 0.0, (EMIT_('a', 'b')|('a', 'b')_1_a, EMIT_('b', 'a')|('b', 'a')_0_a): 0.0, (EMIT_('a', 'b')|('a', 'b')_1_a, EMIT_('a', 'b')|('a', 'b')_1_a): 0.0, (EMIT_('a', 'b')|('a', 'b')_1_a, ('b', 'a')|('b', 'a')): 0.03515, (EMIT_('a', 'b')|('a', 'b')_1_a, ('a', 'a')|('a', 'a')): 0.04272, (EMIT_('a', 'b')|('a', 'b')_1_a, EMIT_('b', 'b')|('b',)_0_b): 0.0, (EMIT_('a', 'b')|('a', 'b')_1_a, EMIT_('a', 'b')|('b',)_0_b): 0.0, (('b', 'a')|('b', 'a'), EMIT_('b', 'a')|('b', 'a')_1_b): 0.0, (('b', 'a')|('b', 'a'), ('b', 'a')|('a',)): 0.0, (('b', 'a')|('b', 'a'), ('b', 'b')|('b',)): 0.0, (('b', 'a')|('b', 'a'), ('a', 'b')|('a', 'b')): 0.0, (('b', 'a')|('b', 'a'), EMIT_('b', 'b')|('b', 'b')_0_b): 0.0, (('b', 'a')|('b', 'a'), EMIT_('b', 'a')|('a',)_0_a): 0.0, (('b', 'a')|('b', 'a'), EMIT_('BOS', 'b')|('b',)_0_b): 0.0, (('b', 'a')|('b', 'a'), EMIT_('a', 'a')|('a', 'a')_1_a): 0.0, (('b', 'a')|('b', 'a'), ('b', 'a')|()): 0.0, (('b', 'a')|('b', 'a'), ('a', 'b')|('b',)): 0.0, (('b', 'a')|('b', 'a'), ('BOS', 'BOS')|()): 0.0, (('b', 'a')|('b', 'a'), <KSHUFFLE_FINAL>): 0.0, (('b', 'a')|('b', 'a'), EMIT_('a', 'a')|('a',)_0_a): 0.0, (('b', 'a')|('b', 'a'), ('a', 'b')|()): 0.0, (('b', 'a')|('b', 'a'), ('BOS', 'a')|('a',)): 0.0, (('b', 'a')|('b', 'a'), ('b', 'b')|('b', 'b')): 0.0, (('b', 'a')|('b', 'a'), ('a', 'a')|()): 0.0, (('b', 'a')|('b', 'a'), EMIT_('a', 'a')|('a', 'a')_0_a): 0.0, (('b', 'a')|('b', 'a'), ('b', 'b')|()): 0.0, (('b', 'a')|('b', 'a'), EMIT_('a', 'b')|('a', 'b')_0_b): 0.0, (('b', 'a')|('b', 'a'), ('BOS', 'b')|('b',)): 0.0, (('b', 'a')|('b', 'a'), EMIT_('BOS', 'a')|('a',)_0_a): 0.0, (('b', 'a')|('b', 'a'), EMIT_('b', 'b')|('b', 'b')_1_b): 0.0, (('b', 'a')|('b', 'a'), ('a', 'a')|('a',)): 0.0, (('b', 'a')|('b', 'a'), EMIT_('b', 'a')|('b', 'a')_0_a): 0.0, (('b', 'a')|('b', 'a'), EMIT_('a', 'b')|('a', 'b')_1_a): 0.0, (('b', 'a')|('b', 'a'), ('b', 'a')|('b', 'a')): 0.0, (('b', 'a')|('b', 'a'), ('a', 'a')|('a', 'a')): 0.0, (('b', 'a')|('b', 'a'), EMIT_('b', 'b')|('b',)_0_b): 0.0, (('b', 'a')|('b', 'a'), EMIT_('a', 'b')|('b',)_0_b): 0.0, (('a', 'a')|('a', 'a'), EMIT_('b', 'a')|('b', 'a')_1_b): 0.0, (('a', 'a')|('a', 'a'), ('b', 'a')|('a',)): 0.0, (('a', 'a')|('a', 'a'), ('b', 'b')|('b',)): 0.0, (('a', 'a')|('a', 'a'), ('a', 'b')|('a', 'b')): 0.0, (('a', 'a')|('a', 'a'), EMIT_('b', 'b')|('b', 'b')_0_b): 0.0, (('a', 'a')|('a', 'a'), EMIT_('b', 'a')|('a',)_0_a): 0.0, (('a', 'a')|('a', 'a'), EMIT_('BOS', 'b')|('b',)_0_b): 0.0, (('a', 'a')|('a', 'a'), EMIT_('a', 'a')|('a', 'a')_1_a): 0.0, (('a', 'a')|('a', 'a'), ('b', 'a')|()): 0.0, (('a', 'a')|('a', 'a'), ('a', 'b')|('b',)): 0.0, (('a', 'a')|('a', 'a'), ('BOS', 'BOS')|()): 0.0, (('a', 'a')|('a', 'a'), <KSHUFFLE_FINAL>): 0.0, (('a', 'a')|('a', 'a'), EMIT_('a', 'a')|('a',)_0_a): 0.0, (('a', 'a')|('a', 'a'), ('a', 'b')|()): 0.0, (('a', 'a')|('a', 'a'), ('BOS', 'a')|('a',)): 0.0, (('a', 'a')|('a', 'a'), ('b', 'b')|('b', 'b')): 0.0, (('a', 'a')|('a', 'a'), ('a', 'a')|()): 0.0, (('a', 'a')|('a', 'a'), EMIT_('a', 'a')|('a', 'a')_0_a): 0.0, (('a', 'a')|('a', 'a'), ('b', 'b')|()): 0.0, (('a', 'a')|('a', 'a'), EMIT_('a', 'b')|('a', 'b')_0_b): 0.0, (('a', 'a')|('a', 'a'), ('BOS', 'b')|('b',)): 0.0, (('a', 'a')|('a', 'a'), EMIT_('BOS', 'a')|('a',)_0_a): 0.0, (('a', 'a')|('a', 'a'), EMIT_('b', 'b')|('b', 'b')_1_b): 0.0, (('a', 'a')|('a', 'a'), ('a', 'a')|('a',)): 0.0, (('a', 'a')|('a', 'a'), EMIT_('b', 'a')|('b', 'a')_0_a): 0.0, (('a', 'a')|('a', 'a'), EMIT_('a', 'b')|('a', 'b')_1_a): 0.0, (('a', 'a')|('a', 'a'), ('b', 'a')|('b', 'a')): 0.0, (('a', 'a')|('a', 'a'), ('a', 'a')|('a', 'a')): 0.0, (('a', 'a')|('a', 'a'), EMIT_('b', 'b')|('b',)_0_b): 0.0, (('a', 'a')|('a', 'a'), EMIT_('a', 'b')|('b',)_0_b): 0.0, (EMIT_('b', 'b')|('b',)_0_b, EMIT_('b', 'a')|('b', 'a')_1_b): 0.0, (EMIT_('b', 'b')|('b',)_0_b, ('b', 'a')|('a',)): 0.0, (EMIT_('b', 'b')|('b',)_0_b, ('b', 'b')|('b',)): 0.0, (EMIT_('b', 'b')|('b',)_0_b, ('a', 'b')|('a', 'b')): 0.0, (EMIT_('b', 'b')|('b',)_0_b, EMIT_('b', 'b')|('b', 'b')_0_b): 0.0, (EMIT_('b', 'b')|('b',)_0_b, EMIT_('b', 'a')|('a',)_0_a): 0.0, (EMIT_('b', 'b')|('b',)_0_b, EMIT_('BOS', 'b')|('b',)_0_b): 0.0, (EMIT_('b', 'b')|('b',)_0_b, EMIT_('a', 'a')|('a', 'a')_1_a): 0.0, (EMIT_('b', 'b')|('b',)_0_b, ('b', 'a')|()): 0.0, (EMIT_('b', 'b')|('b',)_0_b, ('a', 'b')|('b',)): 0.0, (EMIT_('b', 'b')|('b',)_0_b, ('BOS', 'BOS')|()): 0.0, (EMIT_('b', 'b')|('b',)_0_b, <KSHUFFLE_FINAL>): 0.0, (EMIT_('b', 'b')|('b',)_0_b, EMIT_('a', 'a')|('a',)_0_a): 0.0, (EMIT_('b', 'b')|('b',)_0_b, ('a', 'b')|()): 0.0, (EMIT_('b', 'b')|('b',)_0_b, ('BOS', 'a')|('a',)): 0.0, (EMIT_('b', 'b')|('b',)_0_b, ('b', 'b')|('b', 'b')): 0.0, (EMIT_('b', 'b')|('b',)_0_b, ('a', 'a')|()): 0.0, (EMIT_('b', 'b')|('b',)_0_b, EMIT_('a', 'a')|('a', 'a')_0_a): 0.0, (EMIT_('b', 'b')|('b',)_0_b, ('b', 'b')|()): 0.0, (EMIT_('b', 'b')|('b',)_0_b, EMIT_('a', 'b')|('a', 'b')_0_b): 0.0, (EMIT_('b', 'b')|('b',)_0_b, ('BOS', 'b')|('b',)): 0.0, (EMIT_('b', 'b')|('b',)_0_b, EMIT_('BOS', 'a')|('a',)_0_a): 0.0, (EMIT_('b', 'b')|('b',)_0_b, EMIT_('b', 'b')|('b', 'b')_1_b): 0.0, (EMIT_('b', 'b')|('b',)_0_b, ('a', 'a')|('a',)): 0.0, (EMIT_('b', 'b')|('b',)_0_b, EMIT_('b', 'a')|('b', 'a')_0_a): 0.0, (EMIT_('b', 'b')|('b',)_0_b, EMIT_('a', 'b')|('a', 'b')_1_a): 0.0, (EMIT_('b', 'b')|('b',)_0_b, ('b', 'a')|('b', 'a')): 0.0, (EMIT_('b', 'b')|('b',)_0_b, ('a', 'a')|('a', 'a')): 0.0, (EMIT_('b', 'b')|('b',)_0_b, EMIT_('b', 'b')|('b',)_0_b): 0.0, (EMIT_('b', 'b')|('b',)_0_b, EMIT_('a', 'b')|('b',)_0_b): 0.0, (EMIT_('a', 'b')|('b',)_0_b, EMIT_('b', 'a')|('b', 'a')_1_b): 0.0, (EMIT_('a', 'b')|('b',)_0_b, ('b', 'a')|('a',)): 0.0, (EMIT_('a', 'b')|('b',)_0_b, ('b', 'b')|('b',)): 0.0, (EMIT_('a', 'b')|('b',)_0_b, ('a', 'b')|('a', 'b')): 0.0, (EMIT_('a', 'b')|('b',)_0_b, EMIT_('b', 'b')|('b', 'b')_0_b): 0.0, (EMIT_('a', 'b')|('b',)_0_b, EMIT_('b', 'a')|('a',)_0_a): 0.0, (EMIT_('a', 'b')|('b',)_0_b, EMIT_('BOS', 'b')|('b',)_0_b): 0.0, (EMIT_('a', 'b')|('b',)_0_b, EMIT_('a', 'a')|('a', 'a')_1_a): 0.0, (EMIT_('a', 'b')|('b',)_0_b, ('b', 'a')|()): 0.0, (EMIT_('a', 'b')|('b',)_0_b, ('a', 'b')|('b',)): 0.0, (EMIT_('a', 'b')|('b',)_0_b, ('BOS', 'BOS')|()): 0.0, (EMIT_('a', 'b')|('b',)_0_b, <KSHUFFLE_FINAL>): 0.0, (EMIT_('a', 'b')|('b',)_0_b, EMIT_('a', 'a')|('a',)_0_a): 0.0, (EMIT_('a', 'b')|('b',)_0_b, ('a', 'b')|()): 0.0, (EMIT_('a', 'b')|('b',)_0_b, ('BOS', 'a')|('a',)): 0.0, (EMIT_('a', 'b')|('b',)_0_b, ('b', 'b')|('b', 'b')): 0.0, (EMIT_('a', 'b')|('b',)_0_b, ('a', 'a')|()): 0.0, (EMIT_('a', 'b')|('b',)_0_b, EMIT_('a', 'a')|('a', 'a')_0_a): 0.0, (EMIT_('a', 'b')|('b',)_0_b, ('b', 'b')|()): 0.0, (EMIT_('a', 'b')|('b',)_0_b, EMIT_('a', 'b')|('a', 'b')_0_b): 0.0, (EMIT_('a', 'b')|('b',)_0_b, ('BOS', 'b')|('b',)): 0.0, (EMIT_('a', 'b')|('b',)_0_b, EMIT_('BOS', 'a')|('a',)_0_a): 0.0, (EMIT_('a', 'b')|('b',)_0_b, EMIT_('b', 'b')|('b', 'b')_1_b): 0.0, (EMIT_('a', 'b')|('b',)_0_b, ('a', 'a')|('a',)): 0.0, (EMIT_('a', 'b')|('b',)_0_b, EMIT_('b', 'a')|('b', 'a')_0_a): 0.0, (EMIT_('a', 'b')|('b',)_0_b, EMIT_('a', 'b')|('a', 'b')_1_a): 0.0, (EMIT_('a', 'b')|('b',)_0_b, ('b', 'a')|('b', 'a')): 0.0, (EMIT_('a', 'b')|('b',)_0_b, ('a', 'a')|('a', 'a')): 0.0, (EMIT_('a', 'b')|('b',)_0_b, EMIT_('b', 'b')|('b',)_0_b): 0.0, (EMIT_('a', 'b')|('b',)_0_b, EMIT_('a', 'b')|('b',)_0_b): 0.0})\n",
      "After naive eps removal => entropy => 21.32919\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from math import isclose\n",
    "from __future__ import annotations\n",
    "\n",
    "import copy\n",
    "from collections import Counter\n",
    "from collections import defaultdict as dd\n",
    "from collections import deque\n",
    "from itertools import product\n",
    "from typing import Callable, Dict, Generator, List, Optional, Sequence, Set, Tuple, Type, Union\n",
    "\n",
    "import numpy as np\n",
    "from frozendict import frozendict\n",
    "\n",
    "import rayuela\n",
    "from rayuela.base.semiring import Boolean, ProductSemiring, Real, Semiring\n",
    "from rayuela.base.state import PairState, State\n",
    "from rayuela.base.symbol import Expr, Sym, ε, ε_1, ε_2, φ\n",
    "from rayuela.cfg.nonterminal import NT, S\n",
    "from rayuela.fsa.pathsum import Pathsum, Strategy\n",
    "from rayuela.fsa.fsa import FSA\n",
    "\n",
    "from rayuela.base.symbol import EOS, BOS, ε\n",
    "from rayuela.fsa.sampler import Sampler\n",
    "\n",
    "\n",
    "class RandomNGramModel:\n",
    "    \"\"\"\n",
    "    Builds a random n-gram model as a Weighted FSA (with Real semiring),\n",
    "    with internal BOS, EOS tokens not in the user's alphabet.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 alphabet,  # user-supplied normal symbols\n",
    "                 n=2,\n",
    "                 alpha=1.0):\n",
    "        \"\"\"\n",
    "        alphabet: list of normal symbols (no boundary tokens)\n",
    "        n: n-gram order\n",
    "        alpha: Dirichlet concentration\n",
    "        \"\"\"\n",
    "        self.alphabet = alphabet  # user symbols only\n",
    "        self.n = n\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.fsa = FSA(R=Real)\n",
    "        self.context2state = {}  # to store (n-1)-tuple -> State\n",
    "        self._build_ngram_fsa()\n",
    "\n",
    "    def _is_valid_context(self, ctx):\n",
    "        \"\"\"\n",
    "        If we want to prevent EOS in context\n",
    "        and not have BOS reappear after normal tokens:\n",
    "        \"\"\"\n",
    "        if EOS in ctx:\n",
    "            return False\n",
    "        saw_normal = False\n",
    "        for token in ctx:\n",
    "            if token == BOS:\n",
    "                if saw_normal:\n",
    "                    return False\n",
    "            else:\n",
    "                saw_normal = True\n",
    "        return True\n",
    "\n",
    "    def _build_ngram_fsa(self):\n",
    "        \"\"\"\n",
    "        1) define final absorbing state\n",
    "        2) define contexts: (n-1)-tuples from {BOS}+alphabet, skip EOS in context\n",
    "        3) sample dist over (alphabet + EOS), add arcs\n",
    "        \"\"\"\n",
    "        q_final = State(\"<<FINAL>>\")\n",
    "        self.fsa.add_state(q_final)\n",
    "        self.fsa.set_F(q_final, Real.one)\n",
    "\n",
    "        if self.n <= 1:\n",
    "            all_ctxs = [()]\n",
    "        else:\n",
    "            # possible context symbols\n",
    "            csyms = [BOS] + self.alphabet  # not EOS\n",
    "            raw = product(csyms, repeat=self.n-1)\n",
    "            all_ctxs = [r for r in raw if self._is_valid_context(r)]\n",
    "\n",
    "        # build states\n",
    "        for ctx in all_ctxs:\n",
    "            sname = str(ctx) if ctx else \"()\"\n",
    "            st = State(sname)\n",
    "            self.fsa.add_state(st)\n",
    "            self.context2state[ctx] = st\n",
    "\n",
    "        # start ctx\n",
    "        if self.n>1:\n",
    "            start_ctx = tuple([BOS]*(self.n-1))\n",
    "        else:\n",
    "            start_ctx = ()\n",
    "        if self._is_valid_context(start_ctx) and start_ctx not in self.context2state:\n",
    "            st0_ = State(str(start_ctx) if start_ctx else \"()\")\n",
    "            self.fsa.add_state(st0_)\n",
    "            self.context2state[start_ctx] = st0_\n",
    "\n",
    "        s0 = self.context2state.get(start_ctx, State(\"<INVALIDSTART>\"))\n",
    "        self.fsa.add_state(s0)\n",
    "        self.fsa.set_I(s0, Real.one)\n",
    "\n",
    "        # sample distributions\n",
    "        out_syms = list(self.alphabet) + [EOS]\n",
    "        from numpy.random import dirichlet\n",
    "\n",
    "        for ctx in all_ctxs:\n",
    "            dist = dirichlet([self.alpha]*len(out_syms))\n",
    "            s_from = self.context2state[ctx]\n",
    "            for i, pval in enumerate(dist):\n",
    "                if pval<1e-15:\n",
    "                    continue\n",
    "                sym = out_syms[i]\n",
    "                w = Real(pval)\n",
    "                if sym==EOS:\n",
    "                    # arc to final\n",
    "                    self.fsa.set_arc(s_from, sym, q_final, w)\n",
    "                else:\n",
    "                    if self.n>1:\n",
    "                        new_ctx = tuple(list(ctx[1:]) + [sym]) if len(ctx)==(self.n-1) else (sym,)\n",
    "                    else:\n",
    "                        new_ctx = ()\n",
    "\n",
    "                    if self._is_valid_context(new_ctx):\n",
    "                        if new_ctx not in self.context2state:\n",
    "                            stN = State(str(new_ctx) if new_ctx else \"()\")\n",
    "                            self.fsa.add_state(stN)\n",
    "                            self.context2state[new_ctx] = stN\n",
    "                        s_to = self.context2state[new_ctx]\n",
    "                        self.fsa.set_arc(s_from, sym, s_to, w)\n",
    "\n",
    "\n",
    "class KShuffleNgram:\n",
    "    \"\"\"\n",
    "    BFS-labeled approach: states=(ctx,buf).\n",
    "    => We store partially read block in 'buf'.\n",
    "    => If we must emit that block (full or leftover), we create a small chain\n",
    "       of ephemeral states, each responsible for a single symbol output.\n",
    "\n",
    "    That is \"one symbol per transition\" for each flush.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ngram_model: RandomNGramModel, k: int, perturbation_fnc):\n",
    "        self.ngram_model = ngram_model\n",
    "        self.k = k\n",
    "        self.perturbation_fnc = perturbation_fnc\n",
    "        self.R = Real\n",
    "\n",
    "        self.fsa = FSA(R=self.R)\n",
    "        self._build_kshuffle()\n",
    "\n",
    "    def _build_kshuffle(self):\n",
    "        base_fsa = self.ngram_model.fsa\n",
    "\n",
    "        # new final\n",
    "        q_final = State(\"<KSHUFFLE_FINAL>\")\n",
    "        self.fsa.add_state(q_final)\n",
    "        self.fsa.set_F(q_final, Real.one)\n",
    "\n",
    "        queue = deque()\n",
    "        visited = set()\n",
    "\n",
    "        if self.ngram_model.n>1:\n",
    "            start_ctx = tuple([BOS]*(self.ngram_model.n-1))\n",
    "        else:\n",
    "            start_ctx = ()\n",
    "\n",
    "        def ensure_state(ctx, buf):\n",
    "            sname = f\"{ctx}|{buf}\"\n",
    "            st = State(sname)\n",
    "            self.fsa.add_state(st)\n",
    "            return st\n",
    "\n",
    "        s0 = ensure_state(start_ctx, ())\n",
    "        self.fsa.set_I(s0, Real.one)\n",
    "        visited.add((start_ctx, ()))\n",
    "        queue.append((start_ctx, ()))\n",
    "\n",
    "        # final states in base_fsa\n",
    "        base_final = set()\n",
    "        for (qq,ww) in base_fsa.F:\n",
    "            if ww!=self.R.zero:\n",
    "                base_final.add(qq)\n",
    "\n",
    "        inv_map = {v:k for (k,v) in self.ngram_model.context2state.items()}\n",
    "\n",
    "        # gather arcs from base FSA for a given context\n",
    "        def arcs_for_ctx(ctx):\n",
    "            st_base = self.ngram_model.context2state.get(ctx,None)\n",
    "            if st_base is None:\n",
    "                return []\n",
    "            results=[]\n",
    "            for (a,j,w) in base_fsa.arcs(st_base, no_eps=True, nozero=True, reverse=False):\n",
    "                results.append((a,j,w))\n",
    "            return results\n",
    "\n",
    "        while queue:\n",
    "            (ctx, buf) = queue.popleft()\n",
    "            s_from = ensure_state(ctx, buf)\n",
    "\n",
    "            st_base = self.ngram_model.context2state.get(ctx, None)\n",
    "            base_is_final = (st_base in base_final) if st_base else False\n",
    "\n",
    "            # If base is final => leftover flush => ephemeral chain => final\n",
    "            if base_is_final:\n",
    "                leftover_list = list(buf)\n",
    "                pblock = self.perturbation_fnc(leftover_list)\n",
    "                self._emit_symbol_chain(s_from, pblock, q_final, EOSweight=Real.one)\n",
    "                continue\n",
    "\n",
    "            # If buffer<k => read from base arcs\n",
    "            if len(buf)<self.k:\n",
    "                A = arcs_for_ctx(ctx)\n",
    "                for (a,j,w) in A:\n",
    "                    if a==EOS:\n",
    "                        # partial leftover flush\n",
    "                        leftover_list = list(buf)\n",
    "                        pblock = self.perturbation_fnc(leftover_list)\n",
    "                        # print(\"Partial block:\", pblock)\n",
    "                        # print(f\"Context: {ctx}, Buffer: {buf}, Arc: {a}, Weight: {w}\")                        # ephemeral chain => final\n",
    "                        self._emit_symbol_chain(s_from, pblock, q_final, symbol=a, weight=w)\n",
    "                    else:\n",
    "                        symbol = str(a)\n",
    "                        new_ctx = inv_map.get(j,None)\n",
    "                        if new_ctx is None:\n",
    "                            continue\n",
    "                        new_buf = tuple(list(buf)+[symbol])\n",
    "                        if (new_ctx,new_buf) not in visited:\n",
    "                            visited.add((new_ctx,new_buf))\n",
    "                            queue.append((new_ctx,new_buf))\n",
    "                        s_to = ensure_state(new_ctx, new_buf)\n",
    "                        self.fsa.set_arc(s_from, ε, s_to, w)\n",
    "                continue\n",
    "\n",
    "            # else => buffer==k => full block flush\n",
    "            if len(buf)==self.k:\n",
    "                pblock = self.perturbation_fnc(list(buf))\n",
    "                # ephemeral chain => next BFS-labeled state = (ctx,())\n",
    "                next_state = ensure_state(ctx, ())\n",
    "                if (ctx,()) not in visited:\n",
    "                    visited.add((ctx,()))\n",
    "                    queue.append((ctx,()))\n",
    "                self._emit_symbol_chain(s_from, pblock, next_state, EOSweight=Real.one, eplabel=ε)\n",
    "                continue\n",
    "\n",
    "    def _emit_symbol_chain(self, s_from:State, syms:List[str], final_st:State,\n",
    "                           symbol: Sym = None, weight=None, EOSweight=None, eplabel=ε):\n",
    "        \"\"\"\n",
    "        Creates ephemeral chain from s_from for each symbol in 'syms' (one symbol per transition).\n",
    "        Then from the last ephemeral state => final_st with either the 'symbol' (like <EOS>) or eplabel.\n",
    "        'weight' is used for that final transition if provided, else Real.one.\n",
    "        'EOSweight' is used for ephemeral transitions if not provided, default Real.one\n",
    "        'eplabel' for the final transition if no symbol is left.\n",
    "\n",
    "        This ensures single symbol per transition PFSA for the flush.\n",
    "        \"\"\"\n",
    "        if EOSweight is None:\n",
    "            EOSweight = self.R.one\n",
    "        curr_st = s_from\n",
    "        # for each symbol => ephemeral state\n",
    "        for i, sym in enumerate(syms):\n",
    "            e_name = f\"EMIT_{s_from}_{i}_{sym}\"\n",
    "            e_st = State(e_name)\n",
    "            self.fsa.add_state(e_st)\n",
    "            # connect curr_st -sym-> e_st\n",
    "            self.fsa.set_arc(curr_st, Sym(sym), e_st, EOSweight)\n",
    "            curr_st = e_st\n",
    "\n",
    "        # now from curr_st => final_st\n",
    "        # if we have an actual 'symbol' to emit (like <EOS>):\n",
    "        if symbol is not None:\n",
    "            self.fsa.set_arc(curr_st, symbol, final_st, weight if weight else self.R.one)\n",
    "        else:\n",
    "            # else we do eplabel => final\n",
    "            self.fsa.set_arc(curr_st, eplabel, final_st, weight if weight else self.R.one)\n",
    "\n",
    "\n",
    "###################################################\n",
    "# 4) a naive epsremoval\n",
    "###################################################\n",
    "class Transformer:\n",
    "    @staticmethod\n",
    "    def partition(fsa, partition_symbol: Sym = ε) -> Tuple[FSA, FSA]:\n",
    "        \"\"\"Partition FSA into two\n",
    "        (one with arcs of the partition symbol and one with all others)\n",
    "\n",
    "        Args:\n",
    "            fsa (FSA): The input FSA\n",
    "            partition_symbol (Sym, optional): The symbol based on which to\n",
    "            partition the input FSA\n",
    "\n",
    "        Returns:\n",
    "            Tuple[FSA, FSA]: The FSA with non-partition symbol arcs\n",
    "                             and the FSA with only the partition symbol arcs\n",
    "        \"\"\"\n",
    "\n",
    "        E = fsa.spawn()\n",
    "        N = fsa.spawn(keep_init=True, keep_final=True)\n",
    "\n",
    "        for q in fsa.Q:\n",
    "            E.add_state(q)\n",
    "            N.add_state(q)\n",
    "\n",
    "        for i in fsa.Q:\n",
    "            for a, j, w in fsa.arcs(i):\n",
    "                if a == partition_symbol:\n",
    "                    E.add_arc(i, a, j, w)\n",
    "                else:\n",
    "                    N.add_arc(i, a, j, w)\n",
    "\n",
    "        return N, E\n",
    "\n",
    "    @staticmethod\n",
    "    def epsremoval_bebugged(fsa):\n",
    "        \"\"\"\n",
    "        naive approach => triple loop => overcounts arcs from each state\n",
    "        leading to bigger local arc sums => bigger local partial expansions => bigger entropy\n",
    "        \"\"\"\n",
    "        from itertools import product\n",
    "\n",
    "        N,E= Transformer.partition(fsa)\n",
    "        W= Pathsum(E).lehmann(zero=False)\n",
    "        print(W)\n",
    "\n",
    "        # triple loop => for each i-a->j in original no_eps arcs, for each k => i-a->k\n",
    "        for i in fsa.Q:\n",
    "            for a,j,w in fsa.arcs(i, no_eps=True):\n",
    "                for k in fsa.Q:\n",
    "                    neww= w * W[(j,k)]\n",
    "                    if neww.value>1e-15:\n",
    "                        N.add_arc(i,a,k,neww)\n",
    "        # fix initial => double loop\n",
    "        for i in fsa.Q:\n",
    "            for j in fsa.Q:\n",
    "                N.add_I(j, fsa.λ[i]* W[(i,j)])\n",
    "        return N\n",
    "\n",
    "\n",
    "###################################################\n",
    "# 5) Demo\n",
    "###################################################\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    user_alphabet= ['a','b']\n",
    "    rng_model= RandomNGramModel(alphabet=user_alphabet, n=3, alpha=0.4)\n",
    "    print(\"Base n-gram FSA states:\", rng_model.fsa.num_states)\n",
    "    base_ent= rng_model.fsa.entropy()\n",
    "    print(\"Base n-gram FSA entropy =>\", base_ent)\n",
    "\n",
    "    # define a simple block-perturbation function\n",
    "    def left_rotate(block):\n",
    "        if len(block)==0:\n",
    "            return block\n",
    "        return block[1:] + [block[0]]\n",
    "\n",
    "    # K-shuffle\n",
    "    kmodel= KShuffleNgram(rng_model, k=2, perturbation_fnc=left_rotate)\n",
    "    shuffle_ent= kmodel.fsa.entropy()\n",
    "    print(\"K-shuffle FSA states:\", kmodel.fsa.num_states)\n",
    "    print(\"K-shuffle FSA entropy =>\", shuffle_ent)\n",
    "\n",
    "    # Now the naive eps removal\n",
    "    bebugged_noeps= Transformer.epsremoval_bebugged(kmodel.fsa)\n",
    "    big_ent= bebugged_noeps.entropy()\n",
    "    print(\"After naive eps removal => entropy =>\", big_ent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-local entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 313\u001b[0m\n\u001b[1;32m    310\u001b[0m fsa\u001b[38;5;241m.\u001b[39madd_arc(s1, Sym(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m), s2, Real(\u001b[38;5;241m1.0\u001b[39m))\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# compute k=2 local entropy\u001b[39;00m\n\u001b[0;32m--> 313\u001b[0m val \u001b[38;5;241m=\u001b[39m \u001b[43mk_local_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfsa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2-local average entropy => \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 274\u001b[0m, in \u001b[0;36mk_local_entropy\u001b[0;34m(original_fsa, k)\u001b[0m\n\u001b[1;32m    271\u001b[0m kfsa \u001b[38;5;241m=\u001b[39m build_k_context_fsa(noeps, k)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;66;03m# run pathsum => allpairs => localEntropySemiring\u001b[39;00m\n\u001b[0;32m--> 274\u001b[0m ps \u001b[38;5;241m=\u001b[39m \u001b[43mPathsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkfsa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m W \u001b[38;5;241m=\u001b[39m ps\u001b[38;5;241m.\u001b[39mallpairs(strategy\u001b[38;5;241m=\u001b[39mStrategy\u001b[38;5;241m.\u001b[39mLEHMANN, zero\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# returns {(p,q): LocalEntropySemiring}\u001b[39;00m\n\u001b[1;32m    277\u001b[0m total_sp \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n",
      "File \u001b[0;32m/data1/agiats/Projects/impossible_inherent_entropy/.venv/src/rayuela/rayuela/fsa/pathsum.py:144\u001b[0m, in \u001b[0;36mPathsum.__init__\u001b[0;34m(self, fsa)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mI[q] \u001b[38;5;241m=\u001b[39m n\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# lift into the semiring\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlift\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data1/agiats/Projects/impossible_inherent_entropy/.venv/src/rayuela/rayuela/fsa/pathsum.py:167\u001b[0m, in \u001b[0;36mPathsum.lift\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m W \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mR\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfsa\u001b[38;5;241m.\u001b[39mQ:\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a, q, w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfsa\u001b[38;5;241m.\u001b[39marcs(p):\n\u001b[1;32m    168\u001b[0m         W[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mI[p], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mI[q]] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m w\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m W\n",
      "File \u001b[0;32m/data1/agiats/Projects/impossible_inherent_entropy/.venv/src/rayuela/rayuela/fsa/fsa.py:228\u001b[0m, in \u001b[0;36mFSA.arcs\u001b[0;34m(self, i, no_eps, nozero, reverse)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, w \u001b[38;5;129;01min\u001b[39;00m transitions\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 228\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mR\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m nozero:\n\u001b[1;32m    229\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m a, j, w\n",
      "Cell \u001b[0;32mIn[7], line 56\u001b[0m, in \u001b[0;36mSemiring.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# default eq for .value\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'value'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "from collections import defaultdict as dd\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "####################################################\n",
    "# A) The base Semiring class with the required methods\n",
    "####################################################\n",
    "class Semiring:\n",
    "    zero: \"Semiring\"\n",
    "    one: \"Semiring\"\n",
    "    idempotent = False\n",
    "\n",
    "    def __init__(self, value):\n",
    "        # We'll store the \"underlying numeric\" or \"structured\" value in .value\n",
    "        self.value = value\n",
    "\n",
    "    @classmethod\n",
    "    def zeros(cls, N, M):\n",
    "        # returns an NxM matrix with \"semiring.zero\" in each cell\n",
    "        mat = np.empty((N, M), dtype=object)\n",
    "        for i in range(N):\n",
    "            for j in range(M):\n",
    "                mat[i, j] = cls.zero\n",
    "        return mat\n",
    "\n",
    "    @classmethod\n",
    "    def chart(cls, default=None):\n",
    "        if default is None:\n",
    "            default = cls.zero\n",
    "        return dd(lambda: default)\n",
    "\n",
    "    @classmethod\n",
    "    def diag(cls, N):\n",
    "        # NxN with diagonal=cls.one, off-diag=cls.zero\n",
    "        mat = cls.zeros(N, N)\n",
    "        for i in range(N):\n",
    "            mat[i, i] = cls.one\n",
    "        return mat\n",
    "\n",
    "    @classmethod\n",
    "    @property\n",
    "    def is_field(self):\n",
    "        # e.g. Real semiring might set True\n",
    "        return False\n",
    "\n",
    "    def __add__(self, other):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        # default eq for .value\n",
    "        return self.value == other.value\n",
    "\n",
    "    def __hash__(self):\n",
    "        # must be hashable\n",
    "        return hash(self.value)\n",
    "\n",
    "    def star(self):\n",
    "        # if needed for star-closed\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "####################################################\n",
    "# B) Our LocalEntropySemiring that accumulates\n",
    "#    ( sumProb, sumProbEnt ) i.e. (p, p * H)\n",
    "####################################################\n",
    "class LocalEntropySemiring(Semiring):\n",
    "    \"\"\"\n",
    "    We store a pair: (sp, spe) = ( sumProb, sumProbTimesEntropy ).\n",
    "      sp  = total probability mass\n",
    "      spe = sum of (prob(path) * pathEntropy).\n",
    "\n",
    "    The operations:\n",
    "\n",
    "    1) add (+):\n",
    "       (p1, e1) + (p2, e2) = (p1+p2, e1+e2)\n",
    "\n",
    "    2) mul (×):\n",
    "       (p1, e1) x (p2, e2) = (p1*p2, e1*p2 + e2*p1)\n",
    "       => the usual \"expectation semiring\" formula.\n",
    "\n",
    "    The final ratio: average entropy = ( sumProbEnt / sumProb ).\n",
    "\n",
    "    We'll store them in .value as a tuple (sp, spe).\n",
    "    \"\"\"\n",
    "\n",
    "    idempotent = False\n",
    "\n",
    "    def __init__(self, pair):\n",
    "        # pair = (sp, spe)\n",
    "        super().__init__(pair)  # self.value = pair\n",
    "        # we can define convenient attributes:\n",
    "        self.sp = pair[0]\n",
    "        self.spe = pair[1]\n",
    "\n",
    "    def __add__(self, other):\n",
    "        # (p1, e1) + (p2, e2) => (p1+p2, e1+ e2)\n",
    "        return LocalEntropySemiring( (self.sp + other.sp, self.spe + other.spe) )\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        # (p1, e1) x (p2, e2) => (p1*p2, e1*p2 + e2*p1)\n",
    "        spNew = self.sp * other.sp\n",
    "        speNew = (self.spe * other.sp) + (other.spe * self.sp)\n",
    "        return LocalEntropySemiring( (spNew, speNew) )\n",
    "\n",
    "    def star(self):\n",
    "        raise NotImplementedError(\"No star in LocalEntropySemiring\")\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"LE({self.sp:.4g}, {self.spe:.4g})\"\n",
    "\n",
    "    @staticmethod\n",
    "    def make(prob: float):\n",
    "        \"\"\"\n",
    "        Creates a local-entropy semiring element for a single arc of probability p:\n",
    "         => ( p, p * (-log p) )\n",
    "        \"\"\"\n",
    "        if prob < 1e-15:\n",
    "            return LocalEntropySemiring((0.0, 0.0))\n",
    "        ent = prob * (-math.log(prob))\n",
    "        return LocalEntropySemiring((prob, ent))\n",
    "\n",
    "    #####################################################\n",
    "    # \"static\" semiring-wide methods: zero, one, etc.\n",
    "    #####################################################\n",
    "    @classmethod\n",
    "    def zero(cls):\n",
    "        # additive identity => (0.0, 0.0)\n",
    "        return cls((0.0, 0.0))\n",
    "\n",
    "    @classmethod\n",
    "    def one(cls):\n",
    "        # multiplicative identity => (1.0, 0.0)\n",
    "        return cls((1.0, 0.0))\n",
    "\n",
    "    @classmethod\n",
    "    def zeros(cls, N, M):\n",
    "        # NxM matrix of zero elements\n",
    "        mat = np.empty((N, M), dtype=object)\n",
    "        z = cls.zero()\n",
    "        for i in range(N):\n",
    "            for j in range(M):\n",
    "                mat[i, j] = z\n",
    "        return mat\n",
    "\n",
    "    @classmethod\n",
    "    def chart(cls, default=None):\n",
    "        if default is None:\n",
    "            default = cls.zero()\n",
    "        return dd(lambda: default)\n",
    "\n",
    "    @classmethod\n",
    "    def diag(cls, N):\n",
    "        mat = cls.zeros(N, N)\n",
    "        one = cls.one()\n",
    "        for i in range(N):\n",
    "            mat[i, i] = one\n",
    "        return mat\n",
    "\n",
    "    def value(self):\n",
    "        # returns the (sumProb, sumProbEnt) pair\n",
    "        return (self.sp, self.spe)\n",
    "\n",
    "\n",
    "####################################################\n",
    "# C) Building a \"k-context FSA\" in localEnt semiring\n",
    "####################################################\n",
    "def build_k_context_fsa(noeps_fsa, k: int):\n",
    "    \"\"\"\n",
    "    from a no-eps FSA (with arcs that presumably sum to 1 from each state),\n",
    "    produce a new FSA in \"LocalEntropySemiring\". states = ( oldQ, (k-1)-context ).\n",
    "    arcs => define prob = w.value / sumOut => semiring => (p, p*-log p).\n",
    "    \"\"\"\n",
    "    from rayuela.fsa.fsa import FSA\n",
    "    from rayuela.base.symbol import Sym\n",
    "    from rayuela.base.state import State\n",
    "\n",
    "    KFSA = FSA(R=LocalEntropySemiring)\n",
    "\n",
    "    # gather adjacency\n",
    "    from collections import defaultdict, deque\n",
    "    adjacency = defaultdict(list)\n",
    "    outSum = {}\n",
    "\n",
    "    for q in noeps_fsa.Q:\n",
    "        arcsq = list(noeps_fsa.arcs(q))\n",
    "        s = 0.0\n",
    "        for aSym, rSt, w in arcsq:\n",
    "            s += w.value\n",
    "        s += noeps_fsa.ρ[q].value\n",
    "        outSum[q] = s\n",
    "        adjacency[q] = arcsq\n",
    "\n",
    "    newStateDict = {}\n",
    "    def ensure_state(q, buf):\n",
    "        key = (q, tuple(buf))\n",
    "        if key not in newStateDict:\n",
    "            st = State(str(key))\n",
    "            KFSA.add_state(st)\n",
    "            newStateDict[key] = st\n",
    "        return newStateDict[key]\n",
    "\n",
    "    queue = deque()\n",
    "    visited = set()\n",
    "\n",
    "    # define initial states\n",
    "    for q, wInit in noeps_fsa.I:\n",
    "        prob = wInit.value\n",
    "        ctx0 = [\"<BOS>\"]*(k-1) if k>1 else []\n",
    "        stNew = ensure_state(q, ctx0)\n",
    "        if prob>1e-15:\n",
    "            # localEnt = (prob, prob*-log(prob))\n",
    "            wEl = LocalEntropySemiring.make(prob)\n",
    "            KFSA.set_I(stNew, wEl)\n",
    "        queue.append((q, tuple(ctx0)))\n",
    "        visited.add((q, tuple(ctx0)))\n",
    "\n",
    "    while queue:\n",
    "        (oldQ, buf) = queue.popleft()\n",
    "        stFrom = newStateDict[(oldQ, buf)]\n",
    "        # final?\n",
    "        fval = noeps_fsa.ρ[oldQ].value\n",
    "        if fval>1e-15:\n",
    "            fEl = LocalEntropySemiring.make(fval)\n",
    "            KFSA.add_F(stFrom, fEl)\n",
    "\n",
    "        # gather arcs\n",
    "        s = outSum[oldQ]\n",
    "        if s<1e-15:\n",
    "            continue\n",
    "        for (aSym, rSt, w) in adjacency[oldQ]:\n",
    "            arcProb = w.value/s\n",
    "            if arcProb<1e-15:\n",
    "                continue\n",
    "            # shift buffer\n",
    "            newBuf = list(buf)[1:] + [aSym.value] if k>1 else []\n",
    "            stTo = ensure_state(rSt, newBuf)\n",
    "\n",
    "            arcWeight = LocalEntropySemiring.make(arcProb)\n",
    "            KFSA.set_arc(stFrom, aSym, stTo, arcWeight)\n",
    "\n",
    "            if (rSt, tuple(newBuf)) not in visited:\n",
    "                visited.add((rSt, tuple(newBuf)))\n",
    "                queue.append((rSt, tuple(newBuf)))\n",
    "\n",
    "    return KFSA\n",
    "\n",
    "\n",
    "########################################################\n",
    "# D) The actual k_local_entropy function\n",
    "########################################################\n",
    "\n",
    "def k_local_entropy(original_fsa, k: int):\n",
    "    \"\"\"\n",
    "    1) eps-removal => single symbol arcs\n",
    "    2) build k-context fsa in localEntropySemiring\n",
    "    3) run pathsum(Strategy.LEHMANN) => get allpairs => sum init->final => ratio => average local ent\n",
    "    \"\"\"\n",
    "    from rayuela.fsa.transformer import Transformer\n",
    "    from rayuela.fsa.pathsum import Pathsum, Strategy\n",
    "\n",
    "    # remove eps arcs\n",
    "    noeps = Transformer.epsremoval(original_fsa)\n",
    "    # optionally push/normalize => omitted here\n",
    "\n",
    "    # build k-fsa\n",
    "    kfsa = build_k_context_fsa(noeps, k)\n",
    "\n",
    "    # run pathsum => allpairs => localEntropySemiring\n",
    "    ps = Pathsum(kfsa)\n",
    "    W = ps.allpairs(strategy=Strategy.LEHMANN, zero=True)  # returns {(p,q): LocalEntropySemiring}\n",
    "\n",
    "    total_sp = 0.0\n",
    "    total_spe = 0.0\n",
    "\n",
    "    for (p, wInit) in kfsa.I:     # wInit is LocalEntropySemiring\n",
    "        for (q, wFinal) in kfsa.F:\n",
    "            if (p,q) in W:\n",
    "                outPQ = (wInit * W[(p,q)]) * wFinal\n",
    "                total_sp += outPQ.sp\n",
    "                total_spe += outPQ.spe\n",
    "\n",
    "    if total_sp<1e-15:\n",
    "        return 0.0\n",
    "    return total_spe / total_sp\n",
    "\n",
    "\n",
    "########################################################\n",
    "# E) Minimal Demo\n",
    "########################################################\n",
    "if __name__==\"__main__\":\n",
    "    from rayuela.fsa.fsa import FSA\n",
    "    from rayuela.base.state import State\n",
    "    from rayuela.base.symbol import Sym, ε\n",
    "    from rayuela.base.semiring import Real\n",
    "\n",
    "    # make small PFSA with an eps arc\n",
    "    fsa = FSA(R=Real)\n",
    "    s0, s1, s2 = State(0), State(1), State(2)\n",
    "    fsa.set_I(s0, Real(1.0))\n",
    "    fsa.set_F(s2, Real(1.0))\n",
    "\n",
    "    # arcs:\n",
    "    fsa.add_arc(s0, ε, s1, Real(0.3))      # eps\n",
    "    fsa.add_arc(s0, Sym(\"a\"), s0, Real(0.5))\n",
    "    fsa.add_arc(s1, Sym(\"b\"), s2, Real(1.0))\n",
    "\n",
    "    # compute k=2 local entropy\n",
    "    val = k_local_entropy(fsa, k=2)\n",
    "    print(f\"2-local average entropy => {val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
