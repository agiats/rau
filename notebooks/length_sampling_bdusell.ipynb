{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCFG (White and Cotterell, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from src.length_sampling.sampler import construct_pcfg_sampler\n",
    "from src.length_sampling.grammars.pcfg import Grammar\n",
    "from src.length_sampling.grammars.cfg import Nonterminal\n",
    "from src.length_sampling.util import group_by, get_random_generator_and_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = Nonterminal(\"S\")\n",
    "pcfg = Grammar.from_file(\n",
    "    file_path=\"../data_gen/base-grammar_eos.gr\", start=start, normalize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = construct_pcfg_sampler(pcfg)\n",
    "generator, random_seed = get_random_generator_and_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_with_length_constraint(sampler, generator, valid_lengths, sample_size):\n",
    "    samples = []\n",
    "    while len(samples) < sample_size:\n",
    "        length = generator.choice(valid_lengths)\n",
    "        samples.append(list(sampler.sample(length, generator)))\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_with_length_constraint' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m valid_lengths \u001b[38;5;241m=\u001b[39m sampler\u001b[38;5;241m.\u001b[39mvalid_lengths(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[43msample_with_length_constraint\u001b[49m(sampler, generator, valid_lengths, \u001b[38;5;241m100\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_with_length_constraint' is not defined"
     ]
    }
   ],
   "source": [
    "valid_lengths = sampler.valid_lengths(10, 50)\n",
    "samples = sample_with_length_constraint(sampler, generator, valid_lengths, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate log probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import gzip\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from src.length_sampling.sampler import construct_pcfg_sampler\n",
    "from src.length_sampling.grammars.pcfg import Grammar\n",
    "from src.length_sampling.grammars.cfg import Nonterminal\n",
    "from src.length_sampling.util import group_by, get_random_generator_and_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = Nonterminal(\"S\")\n",
    "pcfg = Grammar.from_file(\n",
    "    file_path=\"../data_gen/base-grammar_eos_zipf.gr\", start=start, normalize=True\n",
    ")\n",
    "sampler = construct_pcfg_sampler(pcfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # output\n",
    "# with gzip.open(args.output_path, \"wt\", encoding=\"utf-8\") as f:\n",
    "#     sentence_counts.write_csv(f)\n",
    "import json\n",
    "\n",
    "with gzip.open(\n",
    "    \"/cluster/home/tsomeya/projects/impossible_inherent_entropy/results/length_sampling/100M_samples_eos_zipf_min1_max20/probabilities_split_1_of_10.json.gz\",\n",
    "    \"rt\",\n",
    "    encoding=\"utf-8\",\n",
    ") as f:\n",
    "    probabilities = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'baniticians sub pi sub spectifies da onstigipates sa kurcheda rel baniticians sub maksizeda sa crail [eos]',\n",
       " 'count': 1,\n",
       " 'true_log_prob': -43.88993971696075,\n",
       " 'true_prob': 8.686430912790711e-20}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(\n",
    "    \"/cluster/home/tsomeya/projects/impossible_inherent_entropy/results/length_sampling/100M_samples_eos_zipf_min1_max20/sample_counts.gz\",\n",
    "    \"rt\",\n",
    "    encoding=\"utf-8\",\n",
    ") as f:\n",
    "    probabilities = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
