{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Information Playground\n",
    "\n",
    "This notebook explores predictive information (excess entropy) calculations for PFSAs.\n",
    "\n",
    "Predictive information E = I[X<t : X≥t] measures the mutual information between the past and future of a stochastic process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import random\n",
    "import json\n",
    "from math import ceil\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.printoptions(precision=3)\n",
    "\n",
    "from src.pfsa.fsa_generator import random_dpfsa, random_pfsa, geometric_sum_pfsa, random_ngram\n",
    "from src.pfsa.fsa import PFSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the predictive information module\n",
    "from src.pfsa.predictive_information import (\n",
    "    calculate_predictive_information,\n",
    "    calculate_predictive_information_with_convergence,\n",
    "    plot_entropy_convergence,\n",
    "    plot_entropy_rate_comparison,\n",
    "    analyze_predictive_information_across_parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a Sample PFSA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a sample PFSA\n",
    "A = random_dpfsa(\n",
    "    4,\n",
    "    4,\n",
    "    conditions=[lambda A: 10 < A.mean_length < 80],\n",
    "    mean_length=20,\n",
    "    topology_seed=2,\n",
    "    weight_seed=2,\n",
    ")\n",
    "\n",
    "print(f\"Generated PFSA with {A.n_states} states and {A.n_symbols} symbols\")\n",
    "print(f\"Mean length: {A.mean_length:.2f}\")\n",
    "print(f\"Next symbol entropy: {A.next_symbol_entropy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Predictive Information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate predictive information with detailed convergence analysis\n",
    "E, h_values, h_asymptotic, converged_at = calculate_predictive_information_with_convergence(\n",
    "    A, max_n=8, tol=1e-5, window=3\n",
    ")\n",
    "\n",
    "print(f\"Predictive Information E = {E:.4f}\")\n",
    "print(f\"Asymptotic entropy rate h = {h_asymptotic:.4f}\")\n",
    "print(f\"next_symbol_entropy = {A.next_symbol_entropy:.4f}\")\n",
    "print(f\"Are they equal? {np.isclose(h_asymptotic, A.next_symbol_entropy)}\")\n",
    "\n",
    "if converged_at:\n",
    "    print(f\"\\nConverged at n = {converged_at}\")\n",
    "else:\n",
    "    print(\"\\nDid not converge within max_n iterations\")\n",
    "\n",
    "print(f\"\\nEntropy values (starting from h_2):\")\n",
    "for i, h_n in enumerate(h_values[:10], 2):\n",
    "    print(f\"h_{i} = {h_n:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how the entropy rates converge to next_symbol_entropy\n",
    "print(\"Convergence analysis:\")\n",
    "print(f\"True asymptotic rate (next_symbol_entropy): {A.next_symbol_entropy:.6f}\")\n",
    "print(\"\\nn  | h_n       | h_n - h_asymptotic\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "for i, h_n in enumerate(h_values[:15], 2):\n",
    "    diff = h_n - A.next_symbol_entropy\n",
    "    print(f\"{i:2} | {h_n:.6f} | {diff:+.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the convergence (note: x-axis now starts from n=2)\n",
    "plot_entropy_convergence(h_values, h_asymptotic, E, converged_at,\n",
    "                        title=\"Convergence of n-gram Entropy Rates to Stationary Entropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Multiple PFSAs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's generate multiple PFSAs and compare their convergence behavior\n",
    "pfsa_configs = [\n",
    "    (3, 3, \"3 states, 3 symbols\"),\n",
    "    (4, 4, \"4 states, 4 symbols\"),\n",
    "    (5, 5, \"5 states, 5 symbols\"),\n",
    "    (6, 4, \"6 states, 4 symbols\"),\n",
    "]\n",
    "\n",
    "pfsa_list = []\n",
    "labels = []\n",
    "\n",
    "for n_states, n_symbols, label in pfsa_configs:\n",
    "    pfsa = random_dpfsa(\n",
    "        n_states,\n",
    "        n_symbols,\n",
    "        conditions=[lambda A: 10 < A.mean_length < 30],\n",
    "        mean_length=20,\n",
    "        topology_seed=2,\n",
    "        weight_seed=np.random.randint(0, 10000),\n",
    "    )\n",
    "    pfsa_list.append(pfsa)\n",
    "    labels.append(label)\n",
    "\n",
    "# Compare their entropy rate convergence\n",
    "plot_entropy_rate_comparison(pfsa_list, labels, max_n=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze predictive information across different parameter settings\n",
    "n_states_list = [3, 4, 5, 6]\n",
    "n_symbols_list = [3, 4, 5, 6]\n",
    "\n",
    "results = analyze_predictive_information_across_parameters(\n",
    "    n_states_list,\n",
    "    n_symbols_list,\n",
    "    n_samples=5,  # 5 samples per configuration\n",
    "    max_n=8,\n",
    "    plot_heatmap=True\n",
    ")\n",
    "\n",
    "# Display results table\n",
    "print(\"\\nPredictive Information Summary:\")\n",
    "print(\"States | Symbols | E (mean ± std) | h (mean ± std)\")\n",
    "print(\"-\" * 60)\n",
    "for r in results:\n",
    "    print(f\"{r['n_states']:6} | {r['n_symbols']:7} | \"\n",
    "          f\"{r['predictive_info_mean']:5.3f} ± {r['predictive_info_std']:5.3f} | \"\n",
    "          f\"{r['entropy_rate_mean']:5.3f} ± {r['entropy_rate_std']:5.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate next_symbol_entropy vs local_entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's investigate the relationship between different entropy measures\n",
    "print(\"Entropy measures comparison:\")\n",
    "print(f\"next_symbol_entropy: {A.next_symbol_entropy:.6f}\")\n",
    "print(f\"entropy / (mean_length + 1): {A.entropy / (A.mean_length + 1):.6f}\")\n",
    "\n",
    "# Calculate local entropies\n",
    "local_entropies = []\n",
    "for m in range(1, 10):\n",
    "    if m == 1:\n",
    "        # For m=1, this would be the unconditional entropy\n",
    "        # Let's compute it manually\n",
    "        # This should be the entropy of the first symbol distribution\n",
    "        h1 = 0.0\n",
    "        for y in range(A.n_symbols):\n",
    "            p_y = sum(A.λ[q] * A.Ts[y][q].sum() for q in range(A.n_states))\n",
    "            if p_y > 0:\n",
    "                h1 -= p_y * np.log2(p_y)\n",
    "        # Add terminal probability\n",
    "        p_term = sum(A.λ[q] * A.ρ[q] for q in range(A.n_states))\n",
    "        if p_term > 0:\n",
    "            h1 -= p_term * np.log2(p_term)\n",
    "        local_entropies.append(h1)\n",
    "    else:\n",
    "        local_entropies.append(A.local_entropy(m))\n",
    "\n",
    "print(\"\\nLocal entropies:\")\n",
    "for i, h in enumerate(local_entropies, 1):\n",
    "    print(f\"h_{i} = {h:.6f}\")\n",
    "\n",
    "# Check if they're decreasing\n",
    "print(\"\\nAre they decreasing?\")\n",
    "for i in range(1, len(local_entropies)):\n",
    "    diff = local_entropies[i] - local_entropies[i-1]\n",
    "    print(f\"h_{i+1} - h_{i} = {diff:+.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compute more local entropies to see where they converge\n",
    "extended_local_entropies = []\n",
    "for m in range(2, 8):\n",
    "    h_m = A.local_entropy(m)\n",
    "    extended_local_entropies.append(h_m)\n",
    "\n",
    "# Plot to visualize the convergence\n",
    "plt.figure(figsize=(10, 6))\n",
    "m_values = range(2, len(extended_local_entropies) + 2)\n",
    "plt.plot(m_values, extended_local_entropies, 'b-o', label='h_m (local entropy)', markersize=5)\n",
    "plt.axhline(y=A.next_symbol_entropy, color='r', linestyle='--',\n",
    "            label=f'next_symbol_entropy = {A.next_symbol_entropy:.4f}')\n",
    "\n",
    "# Show the last few values to see what they converge to\n",
    "asymptotic_estimate = np.mean(extended_local_entropies[-5:])\n",
    "plt.axhline(y=asymptotic_estimate, color='g', linestyle=':',\n",
    "            label=f'Estimated limit = {asymptotic_estimate:.4f}')\n",
    "\n",
    "plt.xlabel('m (context length)')\n",
    "plt.ylabel('Entropy rate (bits)')\n",
    "plt.title('Local Entropy vs Context Length')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"next_symbol_entropy: {A.next_symbol_entropy:.6f}\")\n",
    "print(f\"Last 5 local entropies: {[f'{h:.6f}' for h in extended_local_entropies[-5:]]}\")\n",
    "print(f\"Their mean (estimated limit): {asymptotic_estimate:.6f}\")\n",
    "print(f\"Difference: {asymptotic_estimate - A.next_symbol_entropy:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Multiple PFSAs: next_symbol_entropy vs local_entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test multiple PFSAs to compare next_symbol_entropy with local_entropy convergence\n",
    "n_tests = 10\n",
    "max_n = 8  # Keep it modest since local_entropy is slow\n",
    "\n",
    "results = []\n",
    "\n",
    "for test_id in range(n_tests):\n",
    "    print(f\"\\nTest {test_id + 1}/{n_tests}:\")\n",
    "\n",
    "    # Generate random PFSA\n",
    "    pfsa = random_dpfsa(\n",
    "        n_states=np.random.randint(3, 6),\n",
    "        n_symbols=np.random.randint(3, 6),\n",
    "        conditions=[lambda A: 10 < A.mean_length < 40],\n",
    "        mean_length=20,\n",
    "        topology_seed=2,\n",
    "        weight_seed=np.random.randint(0, 10000),\n",
    "    )\n",
    "\n",
    "    # Get next_symbol_entropy\n",
    "    nse = pfsa.next_symbol_entropy\n",
    "\n",
    "    # Calculate a few local entropies\n",
    "    local_entropies = []\n",
    "    for m in [2, 4, 6, 8]:\n",
    "        h_m = pfsa.local_entropy(m=m)\n",
    "        local_entropies.append((m, h_m))\n",
    "\n",
    "    # Get the last value as asymptotic estimate\n",
    "    h_asymptotic = local_entropies[-1][1]\n",
    "\n",
    "    result = {\n",
    "        'test_id': test_id,\n",
    "        'n_states': pfsa.n_states,\n",
    "        'n_symbols': pfsa.n_symbols,\n",
    "        'next_symbol_entropy': nse,\n",
    "        'h_10': h_asymptotic,\n",
    "        'difference': nse - h_asymptotic,\n",
    "        'local_entropies': local_entropies\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "    print(f\"  States: {pfsa.n_states}, Symbols: {pfsa.n_symbols}\")\n",
    "    print(f\"  next_symbol_entropy: {nse:.6f}\")\n",
    "    print(f\"  h_10 (local_entropy): {h_asymptotic:.6f}\")\n",
    "    print(f\"  Difference (NSE - h_10): {nse - h_asymptotic:+.6f}\")\n",
    "\n",
    "    if nse < h_asymptotic:\n",
    "        print(\"  ⚠️  next_symbol_entropy < local_entropy!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY:\")\n",
    "differences = [r['difference'] for r in results]\n",
    "print(f\"Average difference (NSE - h_∞): {np.mean(differences):+.6f}\")\n",
    "print(f\"Std deviation: {np.std(differences):.6f}\")\n",
    "print(f\"Cases where NSE < h_∞: {sum(1 for d in differences if d < 0)}/{len(differences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the relationship between next_symbol_entropy and local_entropy\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot 1: Scatter plot of NSE vs h_10\n",
    "nse_values = [r['next_symbol_entropy'] for r in results]\n",
    "h10_values = [r['h_10'] for r in results]\n",
    "\n",
    "ax1.scatter(nse_values, h10_values, s=100, alpha=0.7)\n",
    "ax1.plot([0, max(nse_values + h10_values)], [0, max(nse_values + h10_values)],\n",
    "         'r--', label='y=x (equal values)')\n",
    "ax1.set_xlabel('next_symbol_entropy')\n",
    "ax1.set_ylabel('h_10 (local_entropy at m=10)')\n",
    "ax1.set_title('Stationary Entropy vs Infix-based Entropy')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Distribution of differences\n",
    "differences = [r['difference'] for r in results]\n",
    "ax2.hist(differences, bins=10, edgecolor='black', alpha=0.7)\n",
    "ax2.axvline(x=0, color='r', linestyle='--', label='Zero difference')\n",
    "ax2.set_xlabel('Difference (NSE - h_10)')\n",
    "ax2.set_ylabel('Count')\n",
    "ax2.set_title('Distribution of Differences')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show cases where NSE < h_10\n",
    "print(\"\\nCases where next_symbol_entropy < local_entropy:\")\n",
    "for r in results:\n",
    "    if r['difference'] < 0:\n",
    "        print(f\"  Test {r['test_id']+1}: {r['n_states']} states, {r['n_symbols']} symbols\")\n",
    "        print(f\"    NSE = {r['next_symbol_entropy']:.6f}, h_10 = {r['h_10']:.6f}\")\n",
    "        print(f\"    Difference = {r['difference']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the magnitude of differences\n",
    "all_differences = [r['difference'] for r in results]\n",
    "abs_differences = [abs(d) for d in all_differences]\n",
    "\n",
    "print(\"Analysis of |NSE - h_10| differences:\")\n",
    "print(f\"Mean absolute difference: {np.mean(abs_differences):.6f} bits\")\n",
    "print(f\"Max absolute difference: {np.max(abs_differences):.6f} bits\")\n",
    "print(f\"Min absolute difference: {np.min(abs_differences):.6f} bits\")\n",
    "print(f\"Median absolute difference: {np.median(abs_differences):.6f} bits\")\n",
    "\n",
    "# What percentage are within various thresholds?\n",
    "thresholds = [0.001, 0.01, 0.02, 0.05, 0.1]\n",
    "print(\"\\nPercentage within threshold:\")\n",
    "for t in thresholds:\n",
    "    pct = sum(1 for d in abs_differences if d < t) / len(abs_differences) * 100\n",
    "    print(f\"  < {t:.3f} bits: {pct:.1f}%\")\n",
    "\n",
    "# Visualize on a finer scale\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(all_differences, bins=20, edgecolor='black', alpha=0.7)\n",
    "plt.axvline(x=0, color='r', linestyle='--', linewidth=2, label='Zero difference')\n",
    "plt.xlabel('Difference (NSE - h_10) in bits')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Differences (Fine Scale)')\n",
    "plt.xlim(-0.05, 0.05)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nConclusion: next_symbol_entropy and local_entropy(10) are remarkably close!\")\n",
    "print(\"The small differences suggest that for these PFSAs:\")\n",
    "print(\"- The infix distribution is very similar to the stationary distribution\")\n",
    "print(\"- Both measures give essentially the same entropy rate\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
